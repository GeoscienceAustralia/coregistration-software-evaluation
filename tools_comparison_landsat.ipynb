{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c1a601",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "import getpass\n",
    "\n",
    "# from landsatxplore.earthexplorer import EarthExplorer\n",
    "import tarfile\n",
    "import boto3\n",
    "from arosics import COREG, COREG_LOCAL\n",
    "from subprocess import run\n",
    "import shlex\n",
    "\n",
    "keep_original_band_scenes = False\n",
    "one_per_month = True\n",
    "dir_suffix = \"\"\n",
    "if (dir_suffix != \"\") and (not dir_suffix.endswith(\"/\")):\n",
    "    dir_suffix = dir_suffix + \"/\"\n",
    "\n",
    "aws_session = rasterio.session.AWSSession(boto3.Session(), requester_pays=True)\n",
    "# aws_session = rasterio.session.AWSSession(boto3.Session())\n",
    "\n",
    "query_and_process = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3fff2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "wa_bbox = resize_bbox(\n",
    "    read_kml_polygon(\"data/inputs_old/LANDSAT_8_127111/WA.kml\")[1], 0.1\n",
    ")\n",
    "aoi_polys = kml_to_poly(\"data/inputs_old/aois.kml\").geoms\n",
    "\n",
    "bbox_list = [\n",
    "    [67.45, -72.55, 67.55, -72.45],  # Amery bed rock\n",
    "    [69.2, -68.1, 69.4, -67.9],  # Amery top\n",
    "    [wa_bbox.left, wa_bbox.bottom, wa_bbox.right, wa_bbox.top],  # WA sand dunes\n",
    "    *[list(p.bounds) for p in aoi_polys],  # AOI polygons\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a4d94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "platform = \"LANDSAT_8\"\n",
    "r_channel = \"red\"\n",
    "g_channel = \"green\"\n",
    "b_channel = \"blue\"\n",
    "\n",
    "aoi_index = 0\n",
    "\n",
    "if query_and_process:\n",
    "    query = get_search_query(\n",
    "        bbox_list[aoi_index],\n",
    "        # start_date=\"\",\n",
    "        start_date=\"2014-01-01T00:00:00\",\n",
    "        end_date=\"2016-01-01T00:00:00\",\n",
    "        platform=platform,\n",
    "    )\n",
    "\n",
    "    server_url = \"https://landsatlook.usgs.gov/stac-server/search\"\n",
    "    features = query_stac_server(query, server_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c472208",
   "metadata": {},
   "outputs": [],
   "source": [
    "if query_and_process:\n",
    "    scene_dict, scene_list = find_scenes_dict(\n",
    "        features,\n",
    "        one_per_month=True,\n",
    "        # start_end_years=[2009, 2010],\n",
    "        acceptance_list=[\"red\", \"green\", \"blue\"],\n",
    "    )\n",
    "    path_rows = list(scene_dict.keys())[1:2]\n",
    "    print(path_rows)\n",
    "    dates = [list(scene_dict[pr].keys()) for pr in path_rows]\n",
    "    print(dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa47f4a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sn = combine_scene_dicts([scene_dict['126111'], scene_dict['127111']])\n",
    "# sn_closest_pair = get_pair_dict(sn, \"closest\")\n",
    "# sn_farthest_pair = get_pair_dict(sn, \"farthest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eceb15b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_row = \"127111\"\n",
    "# closest_pair = get_pair_dict(scene_dict[path_row], \"closest\")\n",
    "# farthest_pair = get_pair_dict(scene_dict[path_row], \"farthest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2433b3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "if query_and_process:\n",
    "    path_row_idx = path_rows.index(path_row)\n",
    "    date = dates[path_row_idx][0]\n",
    "\n",
    "    r_url = scene_dict[path_row][date][0][r_channel]\n",
    "    g_url = scene_dict[path_row][date][0][g_channel]\n",
    "    b_url = scene_dict[path_row][date][0][b_channel]\n",
    "\n",
    "    r_aws = scene_dict[path_row][date][0][r_channel + \"_alternate\"]\n",
    "    g_aws = scene_dict[path_row][date][0][g_channel + \"_alternate\"]\n",
    "    b_aws = scene_dict[path_row][date][0][b_channel + \"_alternate\"]\n",
    "\n",
    "    r_band_suffix = os.path.splitext(os.path.basename(r_url))[0].split(\"_\")[-1]\n",
    "    g_band_suffix = os.path.splitext(os.path.basename(g_url))[0].split(\"_\")[-1]\n",
    "    b_band_suffix = os.path.splitext(os.path.basename(b_url))[0].split(\"_\")[-1]\n",
    "\n",
    "    for pr in path_rows:\n",
    "        counter = 1\n",
    "        true_color_dir = f\"data/inputs/{dir_suffix}{platform}_{pr}/true_color\"\n",
    "        os.makedirs(true_color_dir, exist_ok=True)\n",
    "\n",
    "        true_color_ds_dir = f\"data/inputs/{dir_suffix}{platform}_{pr}/true_color_ds\"\n",
    "        os.makedirs(true_color_ds_dir, exist_ok=True)\n",
    "\n",
    "        pr_dict = scene_dict[pr]\n",
    "        closest_pair = get_pair_dict(pr_dict, \"closest\")\n",
    "        farthest_pair = get_pair_dict(pr_dict, \"farthest\")\n",
    "\n",
    "        pr_date_list = closest_pair + [farthest_pair[1]]\n",
    "        for el in pr_date_list:\n",
    "            print(\n",
    "                f\"Now downloading and processing pairs for {el['scene_name']} and path_row: {pr}, scene {counter} from total of 3.\",\n",
    "                end=\"\\r\",\n",
    "            )\n",
    "            counter += 1\n",
    "            r_url = el[r_channel + \"_alternate\"]\n",
    "            g_url = el[g_channel + \"_alternate\"]\n",
    "            b_url = el[b_channel + \"_alternate\"]\n",
    "            output_dir = (\n",
    "                f\"data/inputs/{dir_suffix}{platform}_{pr}/Originals/{el['scene_name']}\"\n",
    "            )\n",
    "            os.makedirs(output_dir, exist_ok=True)\n",
    "            r_output = os.path.join(output_dir, os.path.basename(r_url))\n",
    "            g_output = os.path.join(output_dir, os.path.basename(g_url))\n",
    "            b_output = os.path.join(output_dir, os.path.basename(b_url))\n",
    "            r_img, r_meta = stream_scene_from_aws(r_url, aws_session)\n",
    "            g_img, g_meta = stream_scene_from_aws(g_url, aws_session)\n",
    "            b_img, b_meta = stream_scene_from_aws(b_url, aws_session)\n",
    "\n",
    "            imgs = [r_img, g_img, b_img]\n",
    "            outputs = [r_output, g_output, b_output]\n",
    "            metas = [r_meta, g_meta, b_meta]\n",
    "            for i, img in enumerate(imgs):\n",
    "                with rasterio.open(outputs[i], \"w\", **metas[i][\"profile\"]) as ds:\n",
    "                    ds.write(img[0, :, :], 1)\n",
    "\n",
    "            files = glob.glob(f\"{output_dir}/**\")\n",
    "            r_band = list(filter(lambda f: f.endswith(f\"_{r_band_suffix}.TIF\"), files))[\n",
    "                0\n",
    "            ]\n",
    "            g_band = list(filter(lambda f: f.endswith(f\"_{g_band_suffix}.TIF\"), files))[\n",
    "                0\n",
    "            ]\n",
    "            b_band = list(filter(lambda f: f.endswith(f\"_{b_band_suffix}.TIF\"), files))[\n",
    "                0\n",
    "            ]\n",
    "            true_bands = [r_band, g_band, b_band]\n",
    "            tc_file = (\n",
    "                f\"{os.path.join(true_color_dir, os.path.basename(output_dir))}_TC.TIF\"\n",
    "            )\n",
    "            tc_file_ds = os.path.join(true_color_ds_dir, os.path.basename(tc_file))\n",
    "            make_true_color_scene(true_bands, tc_file, gray_scale=True, averaging=True)\n",
    "            downsample_dataset(tc_file, 0.2, tc_file_ds)\n",
    "\n",
    "            el[\"local_path\"] = tc_file\n",
    "            el[\"local_path_ds\"] = tc_file_ds\n",
    "\n",
    "            if not keep_original_band_scenes:\n",
    "                shutil.rmtree(\n",
    "                    f\"data/inputs/{dir_suffix}{platform}_{pr}/Originals\",\n",
    "                    ignore_errors=True,\n",
    "                )\n",
    "\n",
    "        cols = [\"Reference\", \"Closest_target\", \"Farthest_target\"]\n",
    "        df = pd.DataFrame(\n",
    "            {\n",
    "                cols[i]: [\n",
    "                    el[\"local_path\"],\n",
    "                    el[\"local_path_ds\"],\n",
    "                ]\n",
    "                for i, el in enumerate(pr_date_list)\n",
    "            },\n",
    "            columns=cols,\n",
    "        )\n",
    "        df.to_csv(\n",
    "            f\"data/inputs/{dir_suffix}{platform}_{pr}/pairs.csv\",\n",
    "            index=False,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d35b556",
   "metadata": {},
   "outputs": [],
   "source": [
    "scene_df = pd.read_csv(f\"data/inputs/{dir_suffix}{platform}_{path_row}/pairs.csv\")\n",
    "ref_image = scene_df[\"Reference\"][0]\n",
    "tgt_images = [\n",
    "    scene_df[\"Closest_target\"][0],\n",
    "    scene_df[\"Farthest_target\"][0],\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d8da42",
   "metadata": {},
   "source": [
    "#### Co_Register"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca444c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = f\"data/outputs/{dir_suffix}{platform}_{path_row}/Co_Register\"\n",
    "_, shifts = co_register(\n",
    "    ref_image,\n",
    "    tgt_images,\n",
    "    output_path=output_path,\n",
    "    return_shifted_images=True,\n",
    "    use_overlap=True,\n",
    "    phase_corr_filter=True,\n",
    "    # band_number=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1cef64f",
   "metadata": {},
   "source": [
    "#### AROSICS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1b57c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tgt_images_copy = tgt_images.copy()\n",
    "output_dir = f\"data/outputs/{dir_suffix}{platform}_{path_row}/AROSICS/Aligned\"\n",
    "local_outputs = [\n",
    "    os.path.join(\n",
    "        output_dir,\n",
    "        os.path.basename(tgt),\n",
    "    )\n",
    "    for tgt in tgt_images_copy\n",
    "]\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "processed_output_images = []\n",
    "print(f\"Reference image: {ref_image}\")\n",
    "for i, tgt_image in enumerate(tgt_images_copy):\n",
    "    print(f\"Coregistering {tgt_image}\")\n",
    "    coreg_local = COREG_LOCAL(\n",
    "        im_ref=ref_image,\n",
    "        im_tgt=tgt_image,\n",
    "        grid_res=250,\n",
    "        # max_points=200,\n",
    "        path_out=local_outputs[i],\n",
    "        fmt_out=\"GTIFF\",\n",
    "        # v=True,\n",
    "        nodata=(0.0, 0.0),\n",
    "        # r_b4match=2,\n",
    "        # s_b4match=2,\n",
    "        align_grids=True,\n",
    "        # max_iter=10,\n",
    "        # max_shift=10,\n",
    "        # CPUs=8,\n",
    "        ignore_errors=True,\n",
    "        min_reliability=30,\n",
    "    )\n",
    "    res = coreg_local.correct_shifts()\n",
    "    if not coreg_local.success:\n",
    "        print(\n",
    "            f\"Coregistration not successfull for {tgt_image}. Removing the corresponding output: {local_outputs[i]}\"\n",
    "        )\n",
    "        if os.path.isfile(local_outputs[i]):\n",
    "            os.remove(local_outputs[i])\n",
    "    else:\n",
    "        processed_output_images.append(local_outputs[i])\n",
    "\n",
    "\n",
    "generate_results_from_raw_inputs(\n",
    "    ref_image,\n",
    "    processed_output_images,\n",
    "    output_dir=f\"data/outputs/{dir_suffix}{platform}_{path_row}/AROSICS\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fde9d27",
   "metadata": {},
   "source": [
    "#### Karios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff5f9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "tgt_images_copy = tgt_images.copy()\n",
    "output_dir = f\"data/outputs/{dir_suffix}{platform}_{path_row}/Karios\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "temp_dir = os.path.join(output_dir, \"temp\")\n",
    "os.makedirs(temp_dir, exist_ok=True)\n",
    "ref_profile = rasterio.open(ref_image).profile\n",
    "tgt_profiles = [rasterio.open(t).profile for t in tgt_images_copy]\n",
    "for i, tgt_profile in enumerate(tgt_profiles):\n",
    "    downsample = False\n",
    "    if tgt_profile[\"height\"] != ref_profile[\"height\"]:\n",
    "        print(\n",
    "            f\"Target image {tgt_images_copy[i]} has different height than reference image {ref_image}\"\n",
    "        )\n",
    "        downsample = True\n",
    "    if tgt_profile[\"width\"] != ref_profile[\"width\"]:\n",
    "        print(\n",
    "            f\"Target image {tgt_images_copy[i]} has different width than reference image {ref_image}\"\n",
    "        )\n",
    "        downsample = True\n",
    "    if downsample:\n",
    "        downsample_dataset(\n",
    "            tgt_images_copy[i],\n",
    "            force_shape=(ref_profile[\"height\"], ref_profile[\"width\"]),\n",
    "            output_file=f\"data/outputs/{dir_suffix}{platform}_{path_row}/Karios/temp/{os.path.basename(tgt_images_copy[i])}\",\n",
    "        )\n",
    "        tgt_images_copy[i] = (\n",
    "            f\"data/outputs/{dir_suffix}{platform}_{path_row}/Karios/temp/{os.path.basename(tgt_images_copy[i])}\"\n",
    "        )\n",
    "\n",
    "\n",
    "log_file = f\"data/outputs/{dir_suffix}{platform}_{path_row}/Karios/karios.log\"\n",
    "if os.path.isfile(log_file):\n",
    "    os.remove(log_file)\n",
    "for i, tgt_image in enumerate(tgt_images_copy):\n",
    "    try:\n",
    "        cmd = f\"python /home/ubuntu/Coreg/karios/karios/karios.py --out {output_dir} --log-file-path {log_file} {tgt_image} {ref_image}\"\n",
    "        print(f\"Running {cmd}\")\n",
    "        run(shlex.split(cmd))\n",
    "    except Exception as e:\n",
    "        print(f\"Error running karios for {tgt_image}: {e}\")\n",
    "        continue\n",
    "\n",
    "shutil.rmtree(temp_dir, ignore_errors=True)\n",
    "tgt_images_copy = tgt_images.copy()\n",
    "process_ids = {}\n",
    "for i, tgt in enumerate(tgt_images_copy):\n",
    "    process_ids[os.path.basename(tgt)] = i\n",
    "pattern = \"_T\\\\d+_SR_TC.TIF\"\n",
    "scene_names = []\n",
    "shifts = []\n",
    "with open(log_file, \"r\") as f:\n",
    "    for line in f:\n",
    "        if bool(re.search(pattern, line)):\n",
    "            scene_basename = os.path.basename(line.strip().split(\" \")[-1])\n",
    "            for tgt_image in tgt_images_copy:\n",
    "                if (tgt_image.endswith(scene_basename)) and (\"DX/DY(KLT) MEAN\" in line):\n",
    "                    scene_names.append(tgt_image)\n",
    "                    splits = line.strip().split(\" \")\n",
    "                    shifts.append([float(splits[-3]), float(splits[-1])])\n",
    "                    break\n",
    "\n",
    "shifts_dict = {}\n",
    "for f, sh in zip(scene_names, shifts):\n",
    "    shifts_dict[f] = sh\n",
    "\n",
    "print(shifts_dict)\n",
    "\n",
    "output_dir = f\"data/outputs/{dir_suffix}{platform}_{path_row}/Karios/Aligned\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "processed_output_images = []\n",
    "for key in list(shifts_dict.keys()):\n",
    "    output_path = os.path.join(output_dir, os.path.basename(key))\n",
    "    shift_x, shift_y = shifts_dict[key]\n",
    "    tgt_aligned = warp_affine_dataset(\n",
    "        key, output_path, translation_x=shift_x, translation_y=shift_y\n",
    "    )\n",
    "    processed_output_images.append(output_path)\n",
    "\n",
    "\n",
    "generate_results_from_raw_inputs(\n",
    "    ref_image,\n",
    "    processed_output_images,\n",
    "    output_dir=f\"data/outputs/{dir_suffix}{platform}_{path_row}/KARIOS\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf7c3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e44a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "tgt_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a923648",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_time = datetime.strptime(os.path.basename(ref_image).split(\"_\")[3], \"%Y%m%d\")\n",
    "tgt_times = [\n",
    "    datetime.strptime(os.path.basename(tgt).split(\"_\")[3], \"%Y%m%d\")\n",
    "    for tgt in tgt_images\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f987ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "[(tgt_time - ref_time).days for tgt_time in tgt_times]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ebd937e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import rasterio as rio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f3b6065",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
