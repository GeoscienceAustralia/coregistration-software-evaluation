{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c1a601",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "from utils import _get_band_suffixes\n",
    "import boto3\n",
    "import pickle\n",
    "import random\n",
    "\n",
    "aws_session = rasterio.session.AWSSession(boto3.Session(), requester_pays=True)\n",
    "\n",
    "dir_suffix = \"\"\n",
    "\n",
    "aoi_index = 6  # 13 and 6\n",
    "\n",
    "keep_original_band_scenes = False\n",
    "one_per_month = False\n",
    "remove_duplicate_times = True\n",
    "query_and_process = True\n",
    "\n",
    "combined_path_rows = False\n",
    "alternate_pairs = False\n",
    "\n",
    "scan_big_shifts = True\n",
    "\n",
    "if not combined_path_rows:\n",
    "    alternate_pairs = False\n",
    "\n",
    "platform = [\"LANDSAT_4\", \"LANDSAT_5\"]\n",
    "\n",
    "reference_month = \"01\"\n",
    "reference_month_1 = \"01\"\n",
    "reference_month_2 = \"01\"\n",
    "\n",
    "enhance_image = True\n",
    "\n",
    "bands = [\"red\", \"green\", \"blue\"]  # \"swir16\"]\n",
    "\n",
    "subdir = \"rgb_enhanced\"\n",
    "\n",
    "id_filter = \"T2\"\n",
    "if \"_SR\" in id_filter:\n",
    "    collections = [\"landsat-c2l2-sr\"]\n",
    "    dir_suffix = \"L2\" + dir_suffix\n",
    "else:\n",
    "    collections = [\"landsat-c2l1\"]\n",
    "    dir_suffix = \"L1\" + dir_suffix\n",
    "dir_suffix = dir_suffix + id_filter.replace(\"_SR\", \"\").replace(\"_\", \"\")\n",
    "\n",
    "\n",
    "outputs_folder = f\"outputs_coreg_spatial/outputs_RGB_enhanced\"\n",
    "\n",
    "force_reprocess = False\n",
    "\n",
    "filename_suffix = \"PROC\"\n",
    "\n",
    "inputs_dir = \"inputs_coreg_spatial\"\n",
    "\n",
    "if (dir_suffix != \"\") and (not dir_suffix.endswith(\"/\")):\n",
    "    dir_suffix = dir_suffix + \"/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3fff2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "wa_bbox = resize_bbox(BoundingBox(*kml_to_poly(\"data/inputs_old/WA.kml\").bounds), 0.1)\n",
    "aoi_polys = kml_to_poly(\"data/inputs_old/aois.kml\").geoms\n",
    "white_island_bbox = read_kml_polygon(\"data/inputs_old/White_island.kml\")[1]\n",
    "inland_bbox = read_kml_polygon(\"data/inputs_old/inland3.kml\")[1]\n",
    "\n",
    "# AOI 5 and 6 L1T2 have visible shifts in their series. AOI 6 co_register with dist_thresh 30\n",
    "bbox_list = [\n",
    "    [67.45, -72.55, 67.55, -72.45],  # Amery bed rock\n",
    "    [69.2, -68.1, 69.4, -67.9],  # Amery top, There are no T1 products for this AOI\n",
    "    wa_bbox,  # WA sand dunes, L4-5 L1T2 co-reg only works for fist target with dist thresh = 50 and min dist thresh = 10 and directional filtering on\n",
    "    *[list(p.bounds) for p in aoi_polys],  # AOI polygons\n",
    "    list(\n",
    "        resize_bbox(BoundingBox(*kml_to_poly(\"data/inputs_old/TAS.kml\").bounds), 0.1)\n",
    "    ),  # TAS\n",
    "    [152.12, -28.37, 154.4, -26.48],  # QLD\n",
    "    white_island_bbox,  # White Island\n",
    "    inland_bbox,  # inland site\n",
    "]\n",
    "\n",
    "print(\"Using AOI index:\", aoi_index)\n",
    "print(\"Using AOI bbox:\")\n",
    "print([np.round(bb, 2).tolist() for bb in bbox_list[aoi_index]])\n",
    "\n",
    "query_platform = platform\n",
    "if type(platform) is list:\n",
    "    platform = (\n",
    "        platform[0].split(\"_\")[0] + \"_\" + \"_\".join(platform).replace(\"LANDSAT_\", \"\")\n",
    "    )\n",
    "    print(\"Using platform:\", platform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a4d94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if query_and_process:\n",
    "    query = get_search_query(\n",
    "        bbox_list[aoi_index],\n",
    "        # start_date=\"2008-12-31T00:00:00\",\n",
    "        start_date=\"1985-01-01T00:00:00\",\n",
    "        end_date=\"2012-12-31T00:00:00\",\n",
    "        platform=query_platform,\n",
    "        collection_category=None,\n",
    "        collections=collections,\n",
    "        cloud_cover=25,\n",
    "        extra_query=None,\n",
    "    )\n",
    "\n",
    "    print(\"Search query:\", query)\n",
    "\n",
    "    server_url = \"https://landsatlook.usgs.gov/stac-server/search\"\n",
    "    features = query_stac_server(query, server_url, id_filter=id_filter)\n",
    "    print(len(features), \"features found\")\n",
    "\n",
    "    if len(features) < 12:\n",
    "        print(f\"Not enough features found: {len(features)}, skipping AOI {aoi_index}\")\n",
    "    # else:\n",
    "    #     os.makedirs(f\"data/{inputs_dir}/features/{platform}\", exist_ok=True)\n",
    "    #     with open(\n",
    "    #         f\"data/{inputs_dir}/features/{platform}/\" + str(aoi_index) + \".pkl\", \"wb\"\n",
    "    #     ) as f:\n",
    "    #         pickle.dump(features, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c472208",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if not query_and_process:\n",
    "#     with open(f\"data/inputs/features/{platform}/\" + str(aoi_index) + \".pkl\", \"rb\") as f:\n",
    "#         features = pickle.load(f)\n",
    "\n",
    "if query_and_process:\n",
    "    scene_dict, scene_list = find_scenes_dict(\n",
    "        features,\n",
    "        one_per_month=one_per_month,\n",
    "        # start_end_years=[2009, 2010],\n",
    "        acceptance_list=bands + [\"thumbnail\"],\n",
    "        remove_duplicate_times=remove_duplicate_times,\n",
    "        duplicate_idx=1,\n",
    "    )\n",
    "    path_rows = list(scene_dict.keys())\n",
    "    if len(path_rows) == 0:\n",
    "        raise ValueError(\"No scenes found, cannot continue\")\n",
    "    print(path_rows)\n",
    "    dates = [list(scene_dict[pr].keys()) for pr in path_rows]\n",
    "    date_len = [len(d) for d in dates]\n",
    "\n",
    "    path_row = path_rows[np.argmax(date_len)]\n",
    "    diffs = [abs(int(pr) - int(path_row)) for pr in path_rows]\n",
    "    up = path_rows[np.argmax(diffs)]\n",
    "    pr_list = [path_row, up]\n",
    "\n",
    "    print(path_row)\n",
    "    print(pr_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa29fd11",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_row_list = [\n",
    "    (path_row, len([s for s in scene_list if path_row in s[\"scene_name\"]]))\n",
    "    for path_row in path_rows\n",
    "]\n",
    "pd.DataFrame(path_row_list, columns=[\"path_row\", \"count\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2433b3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "for pr in path_rows:\n",
    "    output_dir = f\"data/{inputs_dir}/{dir_suffix}{platform}_{pr}\"\n",
    "    data_dict = scene_dict[pr].copy()\n",
    "    pr_date_list = flatten([scene_dict[pr][k] for k in scene_dict[pr].keys()])\n",
    "    if query_and_process:\n",
    "        process_dir = f\"{output_dir}/{subdir}\"\n",
    "        process_ds_dir = f\"{output_dir}/{subdir}_ds\"\n",
    "        bands_suffixes = _get_band_suffixes(data_dict, bands[0:3])\n",
    "        download_and_process_series(\n",
    "            pr_date_list,\n",
    "            bands,\n",
    "            bands_suffixes,\n",
    "            output_dir,\n",
    "            process_dir,\n",
    "            process_ds_dir,\n",
    "            aws_session,\n",
    "            keep_original_band_scenes,\n",
    "            gray_scale=True,\n",
    "            averaging=True,\n",
    "            stretch_contrast=enhance_image,\n",
    "            force_reprocess=force_reprocess,\n",
    "            filename_suffix=filename_suffix,\n",
    "            preserve_depth=True,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040a3291",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_list = []\n",
    "tgt_list = []\n",
    "pr_list = []\n",
    "for pr in path_rows:\n",
    "    input_dir = f\"data/{inputs_dir}/{dir_suffix}{platform}_{pr}\"\n",
    "    pr_date_list = sorted(glob.glob(input_dir + f\"/{subdir}/**\"))\n",
    "    ref_image = pr_date_list[0]\n",
    "    tgt_images = pr_date_list[1:]\n",
    "\n",
    "    if len(tgt_images) < 1:\n",
    "        print(f\"Not enough target images for path_row {pr}, skipping\")\n",
    "        continue\n",
    "    ref_list.append(ref_image)\n",
    "    tgt_list.append(tgt_images)\n",
    "    pr_list.append(pr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1708b5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_list_copy = ref_list.copy()\n",
    "overlaps_per_ref = [ref_list_copy[0]]\n",
    "ref = ref_list_copy[0]\n",
    "ref_list_copy.pop(0)\n",
    "while len(ref_list_copy) > 0:\n",
    "    overlap_areas = []\n",
    "    for tgt in ref_list_copy:\n",
    "        try:\n",
    "            area = box(*find_overlap(ref, tgt)[0]).area / 1000000\n",
    "            overlap_areas.append(area)\n",
    "        except Exception:\n",
    "            overlap_areas.append(0.0)\n",
    "    ref = ref_list_copy[np.argmax(overlap_areas)]\n",
    "    ref_list_copy.pop(np.argmax(overlap_areas))\n",
    "    overlaps_per_ref.append(ref)\n",
    "\n",
    "overlap_dir_name = f\"data/{outputs_folder}/{dir_suffix}refs_{platform}/\" + \"_\".join(\n",
    "    [ref.split(\"/\")[3].split(\"_\")[3] for ref in overlaps_per_ref]\n",
    ")\n",
    "os.makedirs(overlap_dir_name, exist_ok=True)\n",
    "\n",
    "ref_sortperm = [\n",
    "    [os.path.basename(ref) for ref in ref_list].index(ref)\n",
    "    for ref in [os.path.basename(ref) for ref in overlaps_per_ref]\n",
    "]\n",
    "tgt_list = [tgt_list[i] for i in ref_sortperm]\n",
    "pr_list = [pr_list[i] for i in ref_sortperm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "379e4eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# methods = [\"Co_Register\", \"KARIOS\", \"AROSICS\"]\n",
    "methods = [\"AROSICS\"]\n",
    "for method in methods:\n",
    "    print(f\"\\n=== Using method: {method} ===\\n\")\n",
    "    print(\"Processing reference-target chain.\")\n",
    "    print(\"Co-registering references. Thef first reference image is fixed.\")\n",
    "    ordered_refs = overlaps_per_ref.copy()\n",
    "    for i in range(len(ordered_refs) - 1):\n",
    "        ref_id = i\n",
    "        tgt_id = i + 1\n",
    "        output_dir = f\"data/{outputs_folder}/{dir_suffix}refs_{platform}_{overlaps_per_ref[ref_id].split('/')[3].split('_')[3]}_{overlaps_per_ref[tgt_id].split('/')[3].split('_')[3]}/{method}{'_bigShifts' if scan_big_shifts else ''}\"\n",
    "        shifts, target_ids = coreg(\n",
    "            ordered_refs[ref_id],\n",
    "            [ordered_refs[tgt_id]],\n",
    "            output_dir,\n",
    "            method=method,\n",
    "        )\n",
    "        ordered_refs[tgt_id] = (\n",
    "            f\"{output_dir}/Aligned/{os.path.basename(overlaps_per_ref[tgt_id])}\"\n",
    "        )\n",
    "        print(f\"\\n{method} shifts:\")\n",
    "        if method == \"KARIOS\":\n",
    "            for i, shift in enumerate(shifts):\n",
    "                print(\n",
    "                    f\"Target {target_ids[i]}: {tuple([np.round(el, 3).tolist() for el in shifts[shift]])} pixels\"\n",
    "                )\n",
    "        else:\n",
    "            for i, shift in enumerate(shifts):\n",
    "                print(\n",
    "                    f\"Target {target_ids[i]}: {tuple([np.round(el.tolist(), 3).tolist() for el in shift])} pixels\"\n",
    "                )\n",
    "    for i, file in enumerate(ordered_refs):\n",
    "        if not os.path.exists(file):\n",
    "            print(f\"{i}: MISSING FILE {file}\")\n",
    "            ordered_refs[i] = overlaps_per_ref[i]\n",
    "\n",
    "    make_difference_gif(\n",
    "        ordered_refs, overlap_dir_name + f\"/{method}.gif\", mosaic_scenes=True\n",
    "    )\n",
    "\n",
    "    print(\n",
    "        \"\\nCo-registering targets for each pathrow to their corresponding references.\\n\"\n",
    "    )\n",
    "    for i, pr in enumerate(pr_list):\n",
    "        output_dir = f\"data/{outputs_folder}/{dir_suffix}{platform}_{pr}/{method}{'_bigShifts' if scan_big_shifts else ''}\"\n",
    "        kwargs = {\"method\": method}\n",
    "        if method == \"AROSICS\":\n",
    "            kwargs[\"max_shift\"] = 200 if scan_big_shifts else 5\n",
    "        elif method == \"KARIOS\":\n",
    "            kwargs[\"scan_big_shifts\"] = scan_big_shifts\n",
    "        elif method == \"Co_Register\":\n",
    "            kwargs[\"big_shifts_mode\"] = scan_big_shifts\n",
    "        print(\n",
    "            f\"Co-registering targets for pathrow {pr} against reference {ordered_refs[i]}\"\n",
    "        )\n",
    "        shifts, target_ids = coreg(\n",
    "            ordered_refs[i],\n",
    "            tgt_list[i],\n",
    "            output_dir,\n",
    "            **kwargs,\n",
    "        )\n",
    "        print(f\"\\n{method} shifts:\")\n",
    "        if method == \"KARIOS\":\n",
    "            for i, shift in enumerate(shifts):\n",
    "                print(\n",
    "                    f\"Target {target_ids[i]}: {tuple([np.round(el, 3).tolist() for el in shifts[shift]])} pixels\"\n",
    "                )\n",
    "        else:\n",
    "            for i, shift in enumerate(shifts):\n",
    "                print(\n",
    "                    f\"Target {target_ids[i]}: {tuple([np.round(el.tolist(), 3).tolist() for el in shift])} pixels\"\n",
    "                )\n",
    "    print(f\"\\n=== Finished using method: {method} ===\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c506d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_difference_gif(overlaps_per_ref, overlap_dir_name + \"/raw.gif\", mosaic_scenes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8987e897",
   "metadata": {},
   "outputs": [],
   "source": [
    "for pr in pr_list:\n",
    "    root_output = f\"data/{outputs_folder}/{dir_suffix}{platform}_{pr}\"\n",
    "\n",
    "    combine_comparison_results(\n",
    "        root_output,\n",
    "        \"bigShifts\" if scan_big_shifts else None,\n",
    "        coreg_methods=methods,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc773c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
