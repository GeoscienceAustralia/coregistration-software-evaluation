{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c1a601",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "from utils import _get_band_suffixes\n",
    "import boto3\n",
    "import pickle\n",
    "import random\n",
    "\n",
    "aws_session = rasterio.session.AWSSession(boto3.Session(), requester_pays=True)\n",
    "\n",
    "dir_suffix = \"\"\n",
    "\n",
    "aoi_index = 13\n",
    "\n",
    "keep_original_band_scenes = False\n",
    "one_per_month = False\n",
    "remove_duplicate_times = True\n",
    "query_and_process = True\n",
    "\n",
    "combined_path_rows = False\n",
    "alternate_pairs = False\n",
    "\n",
    "scan_big_shifts = True\n",
    "\n",
    "if not combined_path_rows:\n",
    "    alternate_pairs = False\n",
    "\n",
    "platform = [\"LANDSAT_4\", \"LANDSAT_5\"]\n",
    "\n",
    "reference_month = \"01\"\n",
    "reference_month_1 = \"01\"\n",
    "reference_month_2 = \"01\"\n",
    "\n",
    "enhance_image = True\n",
    "\n",
    "bands = [\"red\", \"green\", \"blue\"]  # \"swir16\"]\n",
    "\n",
    "subdir = \"rgb_enhanced\"\n",
    "\n",
    "id_filter = \"T2\"\n",
    "if \"_SR\" in id_filter:\n",
    "    collections = [\"landsat-c2l2-sr\"]\n",
    "    dir_suffix = \"L2\" + dir_suffix\n",
    "else:\n",
    "    collections = [\"landsat-c2l1\"]\n",
    "    dir_suffix = \"L1\" + dir_suffix\n",
    "dir_suffix = dir_suffix + id_filter.replace(\"_SR\", \"\").replace(\"_\", \"\")\n",
    "\n",
    "\n",
    "outputs_folder = f\"outputs_coreg_spatial/outputs_RGB_enhanced\"\n",
    "\n",
    "force_reprocess = False\n",
    "\n",
    "filename_suffix = \"PROC\"\n",
    "\n",
    "inputs_dir = \"inputs_coreg_spatial\"\n",
    "\n",
    "if (dir_suffix != \"\") and (not dir_suffix.endswith(\"/\")):\n",
    "    dir_suffix = dir_suffix + \"/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3fff2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "wa_bbox = resize_bbox(BoundingBox(*kml_to_poly(\"data/inputs_old/WA.kml\").bounds), 0.1)\n",
    "aoi_polys = kml_to_poly(\"data/inputs_old/aois.kml\").geoms\n",
    "white_island_bbox = read_kml_polygon(\"data/inputs_old/White_island.kml\")[1]\n",
    "inland_bbox = read_kml_polygon(\"data/inputs_old/inland3.kml\")[1]\n",
    "\n",
    "# AOI 5 and 6 L1T2 have visible shifts in their series. AOI 6 co_register with dist_thresh 30\n",
    "bbox_list = [\n",
    "    [67.45, -72.55, 67.55, -72.45],  # Amery bed rock\n",
    "    [69.2, -68.1, 69.4, -67.9],  # Amery top, There are no T1 products for this AOI\n",
    "    wa_bbox,  # WA sand dunes, L4-5 L1T2 co-reg only works for fist target with dist thresh = 50 and min dist thresh = 10 and directional filtering on\n",
    "    *[list(p.bounds) for p in aoi_polys],  # AOI polygons\n",
    "    list(\n",
    "        resize_bbox(BoundingBox(*kml_to_poly(\"data/inputs_old/TAS.kml\").bounds), 0.1)\n",
    "    ),  # TAS\n",
    "    [152.12, -28.37, 154.4, -26.48],  # QLD\n",
    "    white_island_bbox,  # White Island\n",
    "    inland_bbox,  # inland site\n",
    "]\n",
    "\n",
    "print(\"Using AOI index:\", aoi_index)\n",
    "print(\"Using AOI bbox:\")\n",
    "print([np.round(bb, 2).tolist() for bb in bbox_list[aoi_index]])\n",
    "\n",
    "query_platform = platform\n",
    "if type(platform) is list:\n",
    "    platform = (\n",
    "        platform[0].split(\"_\")[0] + \"_\" + \"_\".join(platform).replace(\"LANDSAT_\", \"\")\n",
    "    )\n",
    "    print(\"Using platform:\", platform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a4d94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if query_and_process:\n",
    "    query = get_search_query(\n",
    "        bbox_list[aoi_index],\n",
    "        # start_date=\"2008-12-31T00:00:00\",\n",
    "        start_date=\"1985-01-01T00:00:00\",\n",
    "        end_date=\"2012-12-31T00:00:00\",\n",
    "        platform=query_platform,\n",
    "        collection_category=None,\n",
    "        collections=collections,\n",
    "        cloud_cover=5,\n",
    "        extra_query=None,\n",
    "    )\n",
    "\n",
    "    print(\"Search query:\", query)\n",
    "\n",
    "    server_url = \"https://landsatlook.usgs.gov/stac-server/search\"\n",
    "    features = query_stac_server(query, server_url, id_filter=id_filter)\n",
    "    print(len(features), \"features found\")\n",
    "\n",
    "    if len(features) < 12 and not force_path_row:\n",
    "        print(f\"Not enough features found: {len(features)}, skipping AOI {aoi_index}\")\n",
    "    # else:\n",
    "    #     os.makedirs(f\"data/{inputs_dir}/features/{platform}\", exist_ok=True)\n",
    "    #     with open(\n",
    "    #         f\"data/{inputs_dir}/features/{platform}/\" + str(aoi_index) + \".pkl\", \"wb\"\n",
    "    #     ) as f:\n",
    "    #         pickle.dump(features, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c472208",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if not query_and_process:\n",
    "#     with open(f\"data/inputs/features/{platform}/\" + str(aoi_index) + \".pkl\", \"rb\") as f:\n",
    "#         features = pickle.load(f)\n",
    "\n",
    "if query_and_process:\n",
    "    scene_dict, scene_list = find_scenes_dict(\n",
    "        features,\n",
    "        one_per_month=one_per_month,\n",
    "        # start_end_years=[2009, 2010],\n",
    "        acceptance_list=bands + [\"thumbnail\"],\n",
    "        remove_duplicate_times=remove_duplicate_times,\n",
    "        duplicate_idx=1,\n",
    "    )\n",
    "    path_rows = list(scene_dict.keys())\n",
    "    if len(path_rows) == 0:\n",
    "        raise ValueError(\"No scenes found, cannot continue\")\n",
    "    print(path_rows)\n",
    "    dates = [list(scene_dict[pr].keys()) for pr in path_rows]\n",
    "    date_len = [len(d) for d in dates]\n",
    "\n",
    "    path_row = path_rows[np.argmax(date_len)]\n",
    "    diffs = [abs(int(pr) - int(path_row)) for pr in path_rows]\n",
    "    up = path_rows[np.argmax(diffs)]\n",
    "    pr_list = [path_row, up]\n",
    "\n",
    "    print(path_row)\n",
    "    print(pr_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa29fd11",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_row_list = [\n",
    "    (path_row, len([s for s in scene_list if path_row in s[\"scene_name\"]]))\n",
    "    for path_row in path_rows\n",
    "]\n",
    "pd.DataFrame(path_row_list, columns=[\"path_row\", \"count\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0027a8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if query_and_process:\n",
    "    if len(features) > 25:\n",
    "        random.seed(42)\n",
    "        features = random.sample(features, 25)\n",
    "        print(\"Randomly sampled 25 features for download\")\n",
    "\n",
    "    _, full_scene_list = find_scenes_dict(\n",
    "        features,\n",
    "        one_per_month=False,\n",
    "        # start_end_years=[2009, 2010],\n",
    "        acceptance_list=bands + [\"thumbnail\"],\n",
    "        remove_duplicate_times=False,\n",
    "        duplicate_idx=1,\n",
    "    )\n",
    "    i = 0\n",
    "    shutil.rmtree(\"temp_data\", ignore_errors=True)\n",
    "    os.makedirs(\"temp_data\", exist_ok=True)\n",
    "    s3_list = [s[\"thumbnail_alternate\"] for s in full_scene_list]\n",
    "    outputs = []\n",
    "    for url in s3_list:\n",
    "        outputs.append(f\"temp_data/{os.path.basename(url)}\")\n",
    "    bucket = \"usgs-landsat\"\n",
    "    download_files(bucket, s3_list, outputs, -1, is_async_download=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eceb15b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if query_and_process:\n",
    "    for pr in path_rows:\n",
    "        data_dict = scene_dict[pr].copy()\n",
    "        closest_pair = get_pair_dict(\n",
    "            data_dict, \"closest\", reference_month=reference_month\n",
    "        )\n",
    "        farthest_pair = get_pair_dict(\n",
    "            data_dict, \"farthest\", reference_month=reference_month\n",
    "        )\n",
    "\n",
    "        print(\"Closest pair:\")\n",
    "        print(closest_pair[0])\n",
    "        print(closest_pair[1])\n",
    "        print(\"Farthest pair:\")\n",
    "        print(farthest_pair[0])\n",
    "        print(farthest_pair[1])\n",
    "\n",
    "        s3_list = [\n",
    "            closest_pair[0][\"thumbnail_alternate\"],\n",
    "            closest_pair[1][\"thumbnail_alternate\"],\n",
    "            farthest_pair[1][\"thumbnail_alternate\"],\n",
    "        ]\n",
    "        outputs = []\n",
    "        for url in s3_list:\n",
    "            outputs.append(\n",
    "                f\"data/{inputs_dir}/thumbnails/{dir_suffix}{platform}_{path_row}/{os.path.basename(url)}\"\n",
    "            )\n",
    "\n",
    "        bucket = \"usgs-landsat\"\n",
    "        download_files(bucket, s3_list, outputs, -1, is_async_download=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2433b3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "for pr in path_rows:\n",
    "    output_dir = f\"data/{inputs_dir}/{dir_suffix}{platform}_{pr}\"\n",
    "    data_dict = scene_dict[pr].copy()\n",
    "    pr_date_list = flatten([scene_dict[pr][k] for k in scene_dict[pr].keys()])\n",
    "    if query_and_process:\n",
    "        process_dir = f\"{output_dir}/{subdir}\"\n",
    "        process_ds_dir = f\"{output_dir}/{subdir}_ds\"\n",
    "        bands_suffixes = _get_band_suffixes(data_dict, bands[0:3])\n",
    "        download_and_process_series(\n",
    "            pr_date_list,\n",
    "            bands,\n",
    "            bands_suffixes,\n",
    "            output_dir,\n",
    "            process_dir,\n",
    "            process_ds_dir,\n",
    "            aws_session,\n",
    "            keep_original_band_scenes,\n",
    "            gray_scale=True,\n",
    "            averaging=True,\n",
    "            stretch_contrast=enhance_image,\n",
    "            force_reprocess=force_reprocess,\n",
    "            filename_suffix=filename_suffix,\n",
    "            preserve_depth=True,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e3cd18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, axes = plt.subplots(1, 3, figsize=(20, 5))\n",
    "# im0 = rasterio.open(str(ref_image).replace(subdir, f\"{subdir}_ds\"))\n",
    "# im1 = rasterio.open(str(tgt_images[0]).replace(subdir, f\"{subdir}_ds\"))\n",
    "# im2 = rasterio.open(str(tgt_images[1]).replace(subdir, f\"{subdir}_ds\"))\n",
    "# show(im0, ax=axes[0], cmap=\"gray\", title=os.path.basename(ref_image))\n",
    "# show(im1, ax=axes[1], cmap=\"gray\", title=os.path.basename(tgt_images[0]))\n",
    "# show(im2, ax=axes[2], cmap=\"gray\", title=os.path.basename(tgt_images[1]))\n",
    "# plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07023508",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, axes = plt.subplots(1, 3, figsize=(20, 5))\n",
    "# im0 = rasterio.open(str(ref_image_edge).replace(subdir, f\"{subdir}_ds\"))\n",
    "# im1 = rasterio.open(str(tgt_images_edge[0]).replace(subdir, f\"{subdir}_ds\"))\n",
    "# im2 = rasterio.open(str(tgt_images_edge[1]).replace(subdir, f\"{subdir}_ds\"))\n",
    "# show(im0, ax=axes[0], cmap=\"gray\", title=os.path.basename(ref_image_edge))\n",
    "# show(im1, ax=axes[1], cmap=\"gray\", title=os.path.basename(tgt_images_edge[0]))\n",
    "# show(im2, ax=axes[2], cmap=\"gray\", title=os.path.basename(tgt_images_edge[1]))\n",
    "# plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040a3291",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_list = []\n",
    "tgt_list = []\n",
    "pr_list = []\n",
    "for pr in path_rows:\n",
    "    input_dir = f\"data/{inputs_dir}/{dir_suffix}{platform}_{pr}\"\n",
    "    pr_date_list = sorted(glob.glob(input_dir + f\"/{subdir}/**\"))\n",
    "    ref_image = pr_date_list[0]\n",
    "    tgt_images = pr_date_list[1:]\n",
    "\n",
    "    if len(tgt_images) < 1:\n",
    "        print(f\"Not enough target images for path_row {pr}, skipping\")\n",
    "        continue\n",
    "    ref_list.append(ref_image)\n",
    "    tgt_list.append(tgt_images)\n",
    "    pr_list.append(pr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ec9892",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mosaic_data = make_mosaic(ref_list, return_warps=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d8da42",
   "metadata": {},
   "source": [
    "#### Co_Register"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca444c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, pr in enumerate(pr_list):\n",
    "    output_dir = f\"data/{outputs_folder}/{dir_suffix}{platform}_{pr}/Co_Register{'_bigShifts' if scan_big_shifts else ''}\"\n",
    "    shifts, target_ids = coreg(\n",
    "        ref_list[i],\n",
    "        tgt_list[i],\n",
    "        output_dir,\n",
    "        # phase_corr_filter=False,\n",
    "        # phase_corr_signal_thresh=0.3,\n",
    "        # phase_corr_valid_num_points=1,\n",
    "        # of_dist_thresh=15,\n",
    "        # band_number=2,\n",
    "        method=\"Co_Register\",\n",
    "        # directional_filtering=True,\n",
    "        # no_ransac=True,\n",
    "        # lower_of_dist_thresh=10,\n",
    "        # shift_method=\"median\",\n",
    "        big_shifts_mode=scan_big_shifts,\n",
    "        # rethrow_error=True,\n",
    "        # big_shifts_corr_win_size=(512, 512),\n",
    "    )\n",
    "    print(\"\\nCo-register shifts:\")\n",
    "    for i, shift in enumerate(shifts):\n",
    "        print(\n",
    "            f\"Target {target_ids[i]}: {tuple([np.round(el.tolist(), 3).tolist() for el in shift])} pixels\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fde9d27",
   "metadata": {},
   "source": [
    "#### Karios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff5f9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, pr in enumerate(pr_list):\n",
    "    output_dir = f\"data/{outputs_folder}/{dir_suffix}{platform}_{pr}/Karios{'_bigShifts' if scan_big_shifts else ''}\"\n",
    "    shifts, target_ids = coreg(\n",
    "        ref_list[i],\n",
    "        tgt_list[i],\n",
    "        output_dir,\n",
    "        method=\"Karios\",\n",
    "        scan_big_shifts=scan_big_shifts,\n",
    "    )\n",
    "    print(\"\\nKarios shifts:\")\n",
    "    for i, shift in enumerate(shifts):\n",
    "        print(\n",
    "            f\"Target {target_ids[i]}: {tuple([np.round(el, 3).tolist() for el in shifts[shift]])} pixels\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1cef64f",
   "metadata": {},
   "source": [
    "#### AROSICS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1b57c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, pr in enumerate(pr_list):\n",
    "    output_dir = f\"data/{outputs_folder}/{dir_suffix}{platform}_{pr}/AROSICS{'_bigShifts' if scan_big_shifts else ''}\"\n",
    "    shifts, target_ids = coreg(\n",
    "        ref_list[i],\n",
    "        tgt_list[i],\n",
    "        output_dir,\n",
    "        method=\"AROSICS\",\n",
    "        max_shift=200 if scan_big_shifts else 5,\n",
    "    )\n",
    "    print(\"\\nAROSICS shifts:\")\n",
    "    for i, shift in enumerate(shifts):\n",
    "        print(\n",
    "            f\"Target {target_ids[i]}: {tuple([np.round(el.tolist(), 3).tolist() for el in shift])} pixels\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8987e897",
   "metadata": {},
   "outputs": [],
   "source": [
    "for pr in pr_list:\n",
    "    root_output = f\"data/{outputs_folder}/{dir_suffix}{platform}_{pr}\"\n",
    "\n",
    "    combine_comparison_results(\n",
    "        root_output,\n",
    "        \"bigShifts\" if scan_big_shifts else None,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc773c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
