{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c1a601",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "import boto3\n",
    "import pickle\n",
    "\n",
    "# aws_session = rasterio.session.AWSSession(boto3.Session(), requester_pays=True)\n",
    "aws_session = rasterio.session.AWSSession(boto3.Session())\n",
    "dir_suffix = \"\"\n",
    "if (dir_suffix != \"\") and (not dir_suffix.endswith(\"/\")):\n",
    "    dir_suffix = dir_suffix + \"/\"\n",
    "\n",
    "# skip aoi numbers: 8, 9, 10, 18\n",
    "# did 14\n",
    "aoi_index = 0\n",
    "\n",
    "keep_original_band_scenes = False\n",
    "one_per_month = True\n",
    "query_and_process = True\n",
    "\n",
    "force_path_row = True\n",
    "forced_pr = \"48DXL\"\n",
    "\n",
    "if force_path_row:\n",
    "    one_per_month = False\n",
    "\n",
    "combined_path_rows = False\n",
    "aletrnate_pairs = False\n",
    "\n",
    "if not combined_path_rows:\n",
    "    aletrnate_pairs = False\n",
    "\n",
    "platform = \"SENTINEL-2\"\n",
    "collections = [\"SENTINEL-2\"]\n",
    "pystac_collections = [\"sentinel-2-l2a\"]\n",
    "\n",
    "reference_month = \"01\"\n",
    "reference_month_1 = \"01\"\n",
    "reference_month_2 = \"01\"\n",
    "\n",
    "enhance_image = False\n",
    "\n",
    "use_pystac = True\n",
    "\n",
    "bands = [\"red\", \"green\", \"blue\"]\n",
    "\n",
    "subdir = \"true_color\"\n",
    "\n",
    "forced_ids = None\n",
    "\n",
    "force_reprocess = False\n",
    "\n",
    "outputs_folder = \"outputs_RGB\"\n",
    "\n",
    "reference_band_number = 3\n",
    "\n",
    "filename_suffix = \"TC\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3fff2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "wa_bbox = resize_bbox(\n",
    "    read_kml_polygon(\"data/inputs_old/LANDSAT_8_127111/WA.kml\")[1], 0.1\n",
    ")\n",
    "aoi_polys = kml_to_poly(\"data/inputs_old/aois.kml\").geoms\n",
    "\n",
    "bbox_list = [\n",
    "    [67.45, -72.55, 67.55, -72.45],  # Amery bed rock\n",
    "    [69.2, -68.1, 69.4, -67.9],  # Amery top\n",
    "    [wa_bbox.left, wa_bbox.bottom, wa_bbox.right, wa_bbox.top],  # WA sand dunes\n",
    "    *[list(p.bounds) for p in aoi_polys],  # AOI polygons\n",
    "]\n",
    "\n",
    "print([np.round(bb, 2).tolist() for bb in bbox_list[aoi_index]])\n",
    "\n",
    "if type(platform) is list:\n",
    "    platform = (\n",
    "        platform[0].split(\"_\")[0] + \"_\" + \"_\".join(platform).replace(\"SENTINEL_\", \"\")\n",
    "    )\n",
    "    print(\"Using platform:\", platform)\n",
    "\n",
    "if force_path_row:\n",
    "    if forced_ids is not None:\n",
    "        extra_query = {\"ids\": forced_ids}\n",
    "        print(\"Using extra query:\", extra_query)\n",
    "    else:\n",
    "        scene_df_file = f\"data/inputs/{dir_suffix}{platform}_{forced_pr}/pairs.csv\"\n",
    "        if os.path.exists(scene_df_file):\n",
    "            scene_df = pd.read_csv(scene_df_file)\n",
    "            scene_ids = [\n",
    "                os.path.basename(s).replace(\"_TC.tif\", \"\").replace(\"_PROC.tif\", \"\")\n",
    "                for s in scene_df.iloc[0, :].tolist()\n",
    "            ]\n",
    "            extra_query = {\"ids\": scene_ids}\n",
    "            print(\"Using extra query:\", extra_query)\n",
    "        else:\n",
    "            extra_query = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a4d94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if query_and_process:\n",
    "    query = get_search_query(\n",
    "        bbox_list[aoi_index],\n",
    "        collections=collections,\n",
    "        start_date=\"2016-01-01T00:00:00\",\n",
    "        end_date=\"2021-01-01T00:00:00\",\n",
    "        is_landsat=False,\n",
    "        extra_query=extra_query if force_path_row else None,\n",
    "    )\n",
    "\n",
    "    if force_path_row:\n",
    "        del query[\"bbox\"]\n",
    "\n",
    "    if use_pystac:\n",
    "        query[\"collections\"] = pystac_collections\n",
    "        del query[\"page\"]\n",
    "        server_url = \"https://earth-search.aws.element84.com/v1\"\n",
    "    else:\n",
    "        server_url = \"https://catalogue.dataspace.copernicus.eu/stac/search?\"\n",
    "\n",
    "    features = query_stac_server(query, server_url, pystac=use_pystac)\n",
    "    print(len(features), \"features found\")\n",
    "\n",
    "    if len(features) < 12 and not force_path_row:\n",
    "        print(f\"Not enough features found: {len(features)}, skipping AOI {aoi_index}\")\n",
    "    else:\n",
    "        os.makedirs(f\"data/inputs/features/{platform}\", exist_ok=True)\n",
    "        with open(\n",
    "            f\"data/inputs/features/{platform}/\" + str(aoi_index) + \".pkl\", \"wb\"\n",
    "        ) as f:\n",
    "            pickle.dump(features, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c472208",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not query_and_process:\n",
    "    with open(f\"data/inputs/features/{platform}/\" + str(aoi_index) + \".pkl\", \"rb\") as f:\n",
    "        features = pickle.load(f)\n",
    "\n",
    "if query_and_process:\n",
    "    scene_dict, scene_list = find_scenes_dict(\n",
    "        features,\n",
    "        one_per_month=one_per_month,\n",
    "        # start_end_years=[2009, 2010],\n",
    "        acceptance_list=bands + [\"thumbnail\"],\n",
    "        remove_duplicate_times=True,\n",
    "        duplicate_idx=1,\n",
    "    )\n",
    "    path_rows = list(scene_dict.keys())\n",
    "    dates = [list(scene_dict[pr].keys()) for pr in path_rows]\n",
    "    date_len = [len(d) for d in dates]\n",
    "    print([path_rows[i] for i in np.argsort(date_len)[::-1]])\n",
    "\n",
    "    path_row = path_rows[np.argmax(date_len)]\n",
    "    p_indexes = [path_rows.index(pr) for pr in path_rows]\n",
    "    diffs = [abs(path_rows.index(path_row) - pi) for pi in p_indexes]\n",
    "    up = path_rows[np.argmax(diffs)]\n",
    "    pr_list = [path_row, up]\n",
    "\n",
    "    print(path_row)\n",
    "    print(pr_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb619baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pr_list = ['106106', '102107']\n",
    "# path_row = \"48DXL\"\n",
    "# reference_month = \"01\"\n",
    "# aletrnate_pairs = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c28595",
   "metadata": {},
   "outputs": [],
   "source": [
    "pr = None\n",
    "if force_path_row:\n",
    "    assert forced_pr is not None, \"Forced path row must be provided\"\n",
    "    if query_and_process:\n",
    "        if len(forced_pr.split(\"_\")) > 1:\n",
    "            sn = combine_scene_dicts([scene_dict[pr] for pr in forced_pr.split(\"_\")])\n",
    "            data_dict = sn.copy()\n",
    "        else:\n",
    "            data_dict = scene_dict[forced_pr].copy()\n",
    "    pr = forced_pr\n",
    "else:\n",
    "    if combined_path_rows:\n",
    "        if query_and_process:\n",
    "            sn = combine_scene_dicts([scene_dict[pr] for pr in pr_list])\n",
    "            data_dict = sn.copy()\n",
    "        pr = \"_\".join(pr_list)\n",
    "    else:\n",
    "        if query_and_process:\n",
    "            data_dict = scene_dict[path_row].copy()\n",
    "        pr = path_row\n",
    "print(pr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eceb15b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if query_and_process:\n",
    "    if aletrnate_pairs:\n",
    "        closest_pair = get_pair_dict_alternate(\n",
    "            scene_dict[pr_list[0]],\n",
    "            scene_dict[pr_list[1]],\n",
    "            \"closest\",\n",
    "            reference_month_1=reference_month_1,\n",
    "            reference_month_2=reference_month_2,\n",
    "        )\n",
    "        farthest_pair = get_pair_dict_alternate(\n",
    "            scene_dict[pr_list[0]],\n",
    "            scene_dict[pr_list[1]],\n",
    "            \"farthest\",\n",
    "            reference_month_1=reference_month_1,\n",
    "            reference_month_2=reference_month_2,\n",
    "        )\n",
    "    else:\n",
    "        closest_pair = get_pair_dict(\n",
    "            data_dict, \"closest\", reference_month=reference_month\n",
    "        )\n",
    "        farthest_pair = get_pair_dict(\n",
    "            data_dict, \"farthest\", reference_month=reference_month\n",
    "        )\n",
    "\n",
    "    print(\"Closest pair:\")\n",
    "    print(closest_pair[0])\n",
    "    print(closest_pair[1])\n",
    "    print(\"Farthest pair:\")\n",
    "    print(farthest_pair[0])\n",
    "    print(farthest_pair[1])\n",
    "\n",
    "    s3_list = [\n",
    "        closest_pair[0][\"thumbnail_alternate\"],\n",
    "        closest_pair[1][\"thumbnail_alternate\"],\n",
    "        farthest_pair[1][\"thumbnail_alternate\"],\n",
    "    ]\n",
    "    outputs = []\n",
    "    for id, url in enumerate(s3_list):\n",
    "        outputs.append(\n",
    "            f\"data/inputs/thumbnails/{dir_suffix}{platform}_{path_row}/{url.split('/')[-2]}.jpg\"\n",
    "        )\n",
    "\n",
    "    bucket = \"sentinel-cogs\"\n",
    "    download_files(bucket, s3_list, outputs, -1, is_async_download=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a0d7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if query_and_process:\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "    im0 = plt.imread(outputs[0])\n",
    "    im1 = plt.imread(outputs[1])\n",
    "    im2 = plt.imread(outputs[2])\n",
    "    axes[0].imshow(im0)\n",
    "    axes[1].imshow(im1)\n",
    "    axes[2].imshow(im2)\n",
    "    axes[0].set_title(os.path.basename(outputs[0]).replace(\"_thumb_small.jpeg\", \"\"))\n",
    "    axes[1].set_title(os.path.basename(outputs[1]).replace(\"_thumb_small.jpeg\", \"\"))\n",
    "    axes[2].set_title(os.path.basename(outputs[2]).replace(\"_thumb_small.jpeg\", \"\"))\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2433b3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = f\"data/inputs/{dir_suffix}{platform}_{pr}\"\n",
    "if query_and_process:\n",
    "    download_and_process_pairs(\n",
    "        (\n",
    "            [scene_dict[pr_list[0]], scene_dict[pr_list[1]]]\n",
    "            if aletrnate_pairs\n",
    "            else data_dict\n",
    "        ),\n",
    "        bands,\n",
    "        output_dir,\n",
    "        aws_session,\n",
    "        keep_original_band_scenes,\n",
    "        reference_month=(\n",
    "            [reference_month_1, reference_month_2]\n",
    "            if aletrnate_pairs\n",
    "            else reference_month\n",
    "        ),\n",
    "        gray_scale=True,\n",
    "        averaging=True,\n",
    "        subdir=subdir,\n",
    "        stretch_contrast=enhance_image,\n",
    "        force_reprocess=force_reprocess,\n",
    "        reference_band_number=reference_band_number,\n",
    "        filename_suffix=filename_suffix,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d35b556",
   "metadata": {},
   "outputs": [],
   "source": [
    "scene_df = pd.read_csv(f\"data/inputs/{dir_suffix}{platform}_{pr}/pairs.csv\")\n",
    "ref_image = scene_df[\"Reference\"][0]\n",
    "tgt_images = [\n",
    "    scene_df[\"Closest_target\"][0],\n",
    "    scene_df[\"Farthest_target\"][0],\n",
    "]\n",
    "print(\"Reference image:\", ref_image)\n",
    "print(\"Closest target image:\", tgt_images[0])\n",
    "print(\"Farthest target image:\", tgt_images[1])\n",
    "\n",
    "ref_time = datetime.strptime(os.path.basename(ref_image).split(\"_\")[2], \"%Y%m%d\")\n",
    "tgt_times = [\n",
    "    datetime.strptime(os.path.basename(tgt).split(\"_\")[2], \"%Y%m%d\")\n",
    "    for tgt in tgt_images\n",
    "]\n",
    "print(\"Time differences:\", [(tgt_time - ref_time).days for tgt_time in tgt_times])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b14488",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(20, 5))\n",
    "im0 = rasterio.open(str(ref_image).replace(subdir, f\"{subdir}_ds\"))\n",
    "im1 = rasterio.open(str(tgt_images[0]).replace(subdir, f\"{subdir}_ds\"))\n",
    "im2 = rasterio.open(str(tgt_images[1]).replace(subdir, f\"{subdir}_ds\"))\n",
    "show(im0, ax=axes[0], cmap=\"gray\", title=os.path.basename(ref_image))\n",
    "show(im1, ax=axes[1], cmap=\"gray\", title=os.path.basename(tgt_images[0]))\n",
    "show(im2, ax=axes[2], cmap=\"gray\", title=os.path.basename(tgt_images[1]))\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4aa057",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = f\"data/inputs/{dir_suffix}{platform}_{pr}_edge_detection\"\n",
    "process_existing_outputs(\n",
    "    [ref_image] + tgt_images,\n",
    "    output_dir,\n",
    "    edge_detection=True,\n",
    "    edge_detection_mode=\"canny\",\n",
    "    subdir=subdir,\n",
    "    force_reprocess=force_reprocess,\n",
    ")\n",
    "\n",
    "scene_df = pd.read_csv(\n",
    "    f\"data/inputs/{dir_suffix}{platform}_{pr}_edge_detection/pairs.csv\"\n",
    ")\n",
    "ref_image_edge = scene_df[\"Reference\"][0]\n",
    "tgt_images_edge = [\n",
    "    scene_df[\"Closest_target\"][0],\n",
    "    scene_df[\"Farthest_target\"][0],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "041aefd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(20, 5))\n",
    "im0 = rasterio.open(str(ref_image_edge).replace(subdir, f\"{subdir}_ds\"))\n",
    "im1 = rasterio.open(str(tgt_images_edge[0]).replace(subdir, f\"{subdir}_ds\"))\n",
    "im2 = rasterio.open(str(tgt_images_edge[1]).replace(subdir, f\"{subdir}_ds\"))\n",
    "show(im0, ax=axes[0], cmap=\"gray\", title=os.path.basename(ref_image_edge))\n",
    "show(im1, ax=axes[1], cmap=\"gray\", title=os.path.basename(tgt_images_edge[0]))\n",
    "show(im2, ax=axes[2], cmap=\"gray\", title=os.path.basename(tgt_images_edge[1]))\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d8da42",
   "metadata": {},
   "source": [
    "#### Co_Register"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e57c099",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_overlap = not (\n",
    "    rasterio.open(ref_image).transform\n",
    "    == rasterio.open(tgt_images[0]).transform\n",
    "    == rasterio.open(tgt_images[1]).transform\n",
    ")\n",
    "print(\"Using overlap:\", use_overlap)\n",
    "print()\n",
    "output_path = f\"data/{outputs_folder}/{dir_suffix}{platform}_{pr}/Co_Register\"\n",
    "\n",
    "_, shifts, target_ids = co_register(\n",
    "    ref_image,\n",
    "    tgt_images,\n",
    "    output_path=output_path,\n",
    "    return_shifted_images=True,\n",
    "    use_overlap=use_overlap,\n",
    "    # phase_corr_filter=False,\n",
    "    # phase_corr_valid_num_points=1,\n",
    "    # of_dist_thresh=10,\n",
    "    # band_number=2,\n",
    ")\n",
    "\n",
    "failed_tagets = [i for i in range(len(tgt_images)) if i not in target_ids]\n",
    "default_params = [True] * len(tgt_images)\n",
    "for i in failed_tagets:\n",
    "    default_params[i] = False\n",
    "\n",
    "if len(failed_tagets) > 0:\n",
    "    print(\"Failed to co-register targets:\", failed_tagets)\n",
    "    print(\"Re-running co-registration with Laplacian filter for failed targets\")\n",
    "    print(end=\"\\r\")\n",
    "\n",
    "    shutil.rmtree(output_path, ignore_errors=True)\n",
    "    laplacian_filter = True\n",
    "    laplacian_for_targets_ids = failed_tagets\n",
    "\n",
    "    output_path += \"_lpc\"\n",
    "\n",
    "    _, shifts, target_ids = co_register(\n",
    "        ref_image,\n",
    "        tgt_images,\n",
    "        output_path=output_path,\n",
    "        return_shifted_images=True,\n",
    "        use_overlap=use_overlap,\n",
    "        # phase_corr_filter=False,\n",
    "        # phase_corr_valid_num_points=1,\n",
    "        # of_dist_thresh=10,\n",
    "        # band_number=2,\n",
    "        laplacian_kernel_size=5,\n",
    "        laplacian_for_targets_ids=laplacian_for_targets_ids,\n",
    "    )\n",
    "\n",
    "print(\"\\nCo-register shifts:\")\n",
    "for i, shift in enumerate(shifts):\n",
    "    print(\n",
    "        f\"Target {target_ids[i]}: {tuple([np.round(el.tolist(), 3).tolist() for el in shift])} pixels\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fde9d27",
   "metadata": {},
   "source": [
    "#### Karios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff5f9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = f\"data/{outputs_folder}/{dir_suffix}{platform}_{pr}/Karios\"\n",
    "karios_executable = \"/home/ubuntu/Coreg/karios/karios/karios.py\"\n",
    "shift_dict, target_ids = karios(\n",
    "    ref_image,\n",
    "    tgt_images,\n",
    "    output_dir,\n",
    "    karios_executable,\n",
    ")\n",
    "print(\"\\nKarios shifts:\")\n",
    "for i, shift in enumerate(shift_dict):\n",
    "    print(\n",
    "        f\"Target {target_ids[i]}: {tuple([np.round(el, 3).tolist() for el in shift_dict[shift]])} pixels\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1cef64f",
   "metadata": {},
   "source": [
    "#### AROSICS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1b57c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = f\"data/{outputs_folder}/{dir_suffix}{platform}_{pr}/AROSICS\"\n",
    "shifts, target_ids = arosics(\n",
    "    ref_image,\n",
    "    tgt_images,\n",
    "    output_dir,\n",
    ")\n",
    "print(\"\\nAROSICS shifts:\")\n",
    "for i, shift in enumerate(shifts):\n",
    "    print(\n",
    "        f\"Target {target_ids[i]}: {tuple([np.round(el.tolist(), 3).tolist() for el in shift])} pixels\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a026db6a",
   "metadata": {},
   "source": [
    "#### AROSICS EDGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188eff14",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = f\"data/{outputs_folder}/{dir_suffix}{platform}_{pr}/AROSICS_edge\"\n",
    "shifts, target_ids = arosics(\n",
    "    ref_image_edge,\n",
    "    tgt_images_edge,\n",
    "    output_dir,\n",
    "    existing_ref_image=ref_image,\n",
    "    existing_tgt_images=tgt_images,\n",
    ")\n",
    "print(\"\\nAROSICS shifts:\")\n",
    "for i, shift in enumerate(shifts):\n",
    "    print(\n",
    "        f\"Target {target_ids[i]}: {tuple([np.round(el.tolist(), 3).tolist() for el in shift])} pixels\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3306410d",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_output = f\"data/{outputs_folder}/{dir_suffix}{platform}_{pr}\"\n",
    "\n",
    "combine_comparison_results(root_output, default_params)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
