{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042e4ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from geom_median.numpy import compute_geometric_median as gm\n",
    "import numpy as np\n",
    "from utils import *\n",
    "import dask\n",
    "import dask.distributed\n",
    "import xarray as xr\n",
    "import rioxarray as rxr\n",
    "from hdstats import nangeomedian_pcm\n",
    "import geopandas as gpd\n",
    "from odc.algo import (\n",
    "    enum_to_bool,\n",
    "    geomedian_with_mads,\n",
    "    erase_bad,\n",
    "    mask_cleanup,\n",
    "    keep_good_only,\n",
    ")\n",
    "from odc.geo import BoundingBox\n",
    "from odc.geo.xr import assign_crs\n",
    "from odc.io.cgroups import get_cpu_quota\n",
    "from odc.stac import configure_rio, stac_load\n",
    "import logging\n",
    "from functools import reduce\n",
    "from matplotlib.gridspec import GridSpec\n",
    "\n",
    "\"dask: 1 worker 32 threads, gmed: 1 worker\"\n",
    "\"dask: 1 workers, 32 threads, gmed: 30 workers\"\n",
    "\"dask: 30 workers 1 thread, gmed: 1 worker\"\n",
    "\"dask: 30 workers 1 thread, gmed: 30 workers\"\n",
    "\"dask: 30 workers 32 threads, gmed: 1 worker\"\n",
    "\"dask: 30 workers 32 threads, gmed: 30 workers\"\n",
    "\n",
    "\n",
    "dask_n_workers = 1  # os.cpu_count() - 2\n",
    "threads_per_worker = os.cpu_count()\n",
    "gmed_n_workers = 1  # os.cpu_count() - 2\n",
    "\n",
    "shutil.rmtree(\"temp_dask_dir\", ignore_errors=True)\n",
    "os.makedirs(\"temp_dask_dir\", exist_ok=True)\n",
    "\n",
    "# Increase connection and TCP timeouts\n",
    "dask.config.set({\"distributed.comm.timeouts.connect\": \"60s\"})\n",
    "dask.config.set({\"distributed.comm.timeouts.tcp\": \"300s\"})\n",
    "\n",
    "# Increase nanny timeouts (for worker management)\n",
    "dask.config.set({\"distributed.nanny.timeouts.startup\": \"300s\"})\n",
    "dask.config.set({\"distributed.nanny.timeouts.connect\": \"300s\"})\n",
    "dask.config.set({\"distributed.nanny.timeouts.terminate\": \"300s\"})\n",
    "\n",
    "client = dask.distributed.Client(\n",
    "    n_workers=dask_n_workers,\n",
    "    threads_per_worker=threads_per_worker,\n",
    "    local_directory=\"temp_dask_dir\",\n",
    ")\n",
    "\n",
    "display(client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c02548ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "MISSION = \"LANDSAT-8\"  # \"LANDSAT-8\" or \"SENTINEL-2\"\n",
    "\n",
    "if MISSION in [\"LANDSAT-8\", \"LANDSAT-9\", \"LANDSAT-4-5\"]:\n",
    "    aws_session = rasterio.session.AWSSession(boto3.Session(), requester_pays=True)\n",
    "    configure_rio(cloud_defaults=True, aws={\"requester_pays\": True}, client=client)\n",
    "else:\n",
    "    aws_session = rasterio.session.AWSSession(boto3.Session())\n",
    "    configure_rio(cloud_defaults=True, aws={\"aws_unsigned\": True}, client=client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb44a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "wa_bbox = resize_bbox(BoundingBox(*kml_to_poly(\"data/inputs_old/WA.kml\").bounds), 0.1)\n",
    "tas_bbox = resize_bbox(BoundingBox(*kml_to_poly(\"data/inputs_old/TAS.kml\").bounds), 0.1)\n",
    "mount_box = resize_bbox(\n",
    "    BoundingBox(*kml_to_poly(\"data/inputs_old/geo1.kml\").bounds), 0.1\n",
    ")\n",
    "amery_rock = [67.45, -72.55, 67.55, -72.45]\n",
    "amery_shelf = [73.47, -69.66, 74.71, -69.22]\n",
    "hillary_coast = BoundingBox(*kml_to_poly(\"data/inputs_old/hillary.kml\").bounds)\n",
    "flincher_shelf = [-46, -84, -36, -74]\n",
    "inland_ice = [126.0, -90, 136, -80]\n",
    "\n",
    "bbox_list = [\n",
    "    wa_bbox,\n",
    "    amery_rock,\n",
    "    mount_box,\n",
    "    tas_bbox,\n",
    "    amery_shelf,\n",
    "    hillary_coast,\n",
    "    flincher_shelf,\n",
    "    inland_ice,\n",
    "]\n",
    "\n",
    "aoi_dict = {\n",
    "    str(wa_bbox): \"WA\",\n",
    "    str(tas_bbox): \"TAS\",\n",
    "    str(mount_box): \"MOUNT\",\n",
    "    str(amery_rock): \"AMERY_ROCK\",\n",
    "    str(amery_shelf): \"AMERY_SHELF\",\n",
    "    str(hillary_coast): \"HILLARY_COAST\",\n",
    "    str(flincher_shelf): \"FLINCHER_SHELF\",\n",
    "    str(inland_ice): \"INLAND_ICE\",\n",
    "}\n",
    "\n",
    "# Flincher and Amery shelves are high velocity ice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a24f9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_factor = 10.0\n",
    "max_cloud_cover = 5\n",
    "min_scenes_per_id = 10\n",
    "\n",
    "aoi_index = 6\n",
    "bbox = bbox_list[aoi_index]\n",
    "AOI = aoi_dict[str(bbox)]\n",
    "masking_band = [\"scl\"]\n",
    "if MISSION == \"SENTINEL-1\":\n",
    "    if AOI == \"TAS\":\n",
    "        bands = [\"VH\", \"VV\"]\n",
    "    else:\n",
    "        bands = [\"HH\"]\n",
    "else:\n",
    "    bands = [\"red\", \"green\", \"blue\"]\n",
    "mask_filters = [(\"opening\", 10), (\"dilation\", 1)]\n",
    "# crs = \"EPSG:3031\"\n",
    "resolution = 100 if MISSION in [\"SENTINEL-1\", \"SENTINEL-2\"] else 200\n",
    "output_suffix = \"manual_loader\"\n",
    "file_name_suffix = \"odc_stac\"  # odc\n",
    "aoi_suffix = \"_LARGE_L1_All\"\n",
    "\n",
    "AOI = AOI + aoi_suffix if aoi_suffix else AOI\n",
    "use_all_items = False\n",
    "\n",
    "if \"_LARGE\" in aoi_suffix:\n",
    "    if AOI.replace(aoi_suffix, \"\") in [\"AMERY_ROCK\", \"AMERY_SHELF\"]:\n",
    "        bbox = resize_bbox(BoundingBox(*bbox), scale_factor)\n",
    "    elif AOI.replace(aoi_suffix, \"\") in [\"INLAND_ICE\", \"FLINCHER_SHELF\"]:\n",
    "        pass\n",
    "    else:\n",
    "        bbox = resize_bbox(bbox, scale_factor)\n",
    "print(AOI, bbox, bands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dbcccdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_bands = (\n",
    "    masking_band if MISSION == \"SENTINEL-2\" else None\n",
    ")  # Only for Sentinel-2, Landsat-8 does not have SCL band\n",
    "output_dir = f\"data/inputs/{MISSION}_{AOI}\"\n",
    "process_dir = f\"{output_dir}/true_colour\"\n",
    "process_ds_dir = f\"{output_dir}/true_colour_ds\"\n",
    "ds_dir = f\"{output_dir}/downsampled\"\n",
    "items_file = f\"{output_dir}/items.json\"\n",
    "items_exist = os.path.exists(items_file)\n",
    "print(items_file)\n",
    "items_exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "706573f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_all_items and not items_exist:\n",
    "    items_files = glob.glob(f\"{output_dir}/items*.json\")\n",
    "    items_files = [f for f in items_files if f\"{output_dir}/items.json\" not in f]\n",
    "    if len(items_files) > 0:\n",
    "        items_list = [pystac.ItemCollection.from_file(f) for f in items_files]\n",
    "        items = reduce(lambda x, y: x + y, items_list)\n",
    "        items_exist = True\n",
    "        items.save_object(f\"{output_dir}/items.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6566af8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not items_exist:\n",
    "    if MISSION == \"SENTINEL-2\":\n",
    "        query = get_search_query(\n",
    "            bbox,\n",
    "            collections=[\"sentinel-2-l2a\"],\n",
    "            start_date=\"2016-01-01T00:00:00\",\n",
    "            end_date=\"2021-01-01T00:00:00\",\n",
    "            pystac_query=True,\n",
    "        )\n",
    "        use_pystac = True\n",
    "        server_url = \"https://earth-search.aws.element84.com/v1\"\n",
    "    elif MISSION == \"SENTINEL-1\":\n",
    "        query = get_search_query(\n",
    "            bbox,\n",
    "            collections=[\"ga_s1_iw_vv_vh_c0\", \"ga_s1_iw_hh_c0\"],\n",
    "            start_date=\"2016-01-01T00:00:00\",\n",
    "            end_date=\"2021-01-01T00:00:00\",\n",
    "            pystac_query=True,\n",
    "        )\n",
    "        use_pystac = True\n",
    "        server_url = \"https://explorer.dev.dea.ga.gov.au/stac\"\n",
    "    elif MISSION == \"LANDSAT-8\":\n",
    "        query = get_search_query(\n",
    "            bbox,\n",
    "            start_date=\"2013-01-01T00:00:00\",\n",
    "            end_date=\"2017-01-01T00:00:00\",\n",
    "            platform=[\"LANDSAT_8\"],\n",
    "            collection_category=None,\n",
    "            collections=None,\n",
    "            cloud_cover=5,\n",
    "        )\n",
    "        use_pystac = False\n",
    "        server_url = \"https://landsatlook.usgs.gov/stac-server/search\"\n",
    "    elif MISSION == \"LANDSAT-4-5\":\n",
    "        query = get_search_query(\n",
    "            bbox,\n",
    "            start_date=\"1985-01-01T00:00:00\",\n",
    "            end_date=\"2010-12-30T00:00:00\",\n",
    "            platform=[\"LANDSAT_4\", \"LANDSAT_5\"],\n",
    "            collection_category=None,\n",
    "            collections=None,\n",
    "            cloud_cover=5,\n",
    "        )\n",
    "        use_pystac = False\n",
    "        server_url = \"https://landsatlook.usgs.gov/stac-server/search\"\n",
    "\n",
    "    display(query)\n",
    "    items = query_stac_server(\n",
    "        query,\n",
    "        server_url,\n",
    "        use_pystac=use_pystac,\n",
    "        max_cloud_cover=max_cloud_cover if MISSION != \"SENTINEL-1\" else None,\n",
    "    )\n",
    "    print(f\"Found {len(items)} items.\")\n",
    "\n",
    "    if len(items) > 0:\n",
    "        scene_dict, scene_list = find_scenes_dict(\n",
    "            items,\n",
    "            one_per_month=False if MISSION == \"LANDSAT-4-5\" else True,\n",
    "            acceptance_list=bands + [\"thumbnail\"],\n",
    "            remove_duplicate_times=False if MISSION == \"LANDSAT-4-5\" else True,\n",
    "            duplicate_idx=1,\n",
    "            min_scenes_per_id=min_scenes_per_id,\n",
    "            id_filter=\"L1GT\" if MISSION in [\"LANDSAT-8\", \"LANDSAT-9\"] else None,\n",
    "        )\n",
    "        pd.DataFrame(scene_list).to_csv(\n",
    "            f\"data/inputs/{MISSION}_{AOI}_scenes.csv\", index=False\n",
    "        )\n",
    "        path_rows = list(scene_dict.keys())\n",
    "        print(\"Found IDs: \", path_rows)\n",
    "\n",
    "        path_row_list = [\n",
    "            (i, path_row, len(scene_dict[path_row]))\n",
    "            for i, path_row in enumerate(path_rows)\n",
    "        ]\n",
    "        pd.DataFrame(path_row_list, columns=[\"index\", \"path_row\", \"count\"]).to_csv(\n",
    "            f\"data/inputs/{MISSION}_{AOI}_scene_counts.csv\", index=False\n",
    "        )\n",
    "        print(\"Found scene counts: \", path_row_list)\n",
    "        print(\"Found scenes counts after filtering: \", len(scene_list))\n",
    "\n",
    "        items = pystac.ItemCollection(items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c67251d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_row_list = pd.read_csv(f\"data/inputs/{MISSION}_{AOI}_scene_counts.csv\")\n",
    "print(\"Found scene counts: \\n\", path_row_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f304328",
   "metadata": {},
   "outputs": [],
   "source": [
    "tile_id = \"\"\n",
    "items_file = f\"{output_dir}/items.json\"\n",
    "full_items_file = items_file\n",
    "items_file = f\"{output_dir}/items{'_' + tile_id if tile_id else ''}.json\"\n",
    "items_exist = os.path.exists(items_file)\n",
    "\n",
    "if use_all_items:\n",
    "    tile_id = \"\"\n",
    "    items_file = full_items_file\n",
    "condition = tile_id if tile_id != \"\" else \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9842a61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not items_exist:\n",
    "    if use_all_items or tile_id != \"\":\n",
    "        items = pystac.ItemCollection.from_file(full_items_file)\n",
    "    scenes = pd.read_csv(f\"data/inputs/{MISSION}_{AOI}_scenes.csv\")\n",
    "    scene_list = scenes.to_dict(\"records\")\n",
    "    bands_suffixes = get_band_suffixes(scene_list[0], bands)\n",
    "    print(len(scene_list), \"scenes found in the CSV file.\")\n",
    "    scene_names = [\n",
    "        scene[\"scene_name\"] for scene in scene_list if condition in scene[\"scene_name\"]\n",
    "    ]\n",
    "    scene_ids = None\n",
    "    if MISSION not in [\"SENTINEL-1\", \"SENTINEL-2\"]:\n",
    "        scene_ids = [\n",
    "            scene[\"scene_id\"] for scene in scene_list if condition in scene[\"scene_id\"]\n",
    "        ]\n",
    "\n",
    "    gdf = gpd.GeoDataFrame.from_features(items, \"epsg:4326\")\n",
    "    if MISSION == \"SENTINEL-2\":\n",
    "        id_col = \"earthsearch:s3_path\"\n",
    "    elif MISSION == \"SENTINEL-1\":\n",
    "        id_col = \"title\"\n",
    "    elif MISSION == \"LANDSAT-8\":\n",
    "        id_col = \"landsat:scene_id\"\n",
    "    else:\n",
    "        id_col = \"landsat:scene_id\"\n",
    "    item_names = list(gdf[id_col].apply(lambda x: x.split(\"/\")[-1]))\n",
    "    checklist = scene_names if MISSION in [\"SENTINEL-1\", \"SENTINEL-2\"] else scene_ids\n",
    "    idx = [item_names.index(i) for i in checklist]\n",
    "    gdf = gdf.iloc[idx].reset_index(drop=True)\n",
    "    print(len(gdf), \"items found in the GeoDataFrame.\")\n",
    "\n",
    "    # gdf.explore()\n",
    "    # print(len(scene_list), \"scenes found in the CSV file.\")\n",
    "    if MISSION == \"SENTINEL-2\":\n",
    "        idx = [i for i in range(len(items.items)) if items.items[i].id in scene_names]\n",
    "        scene_list = [\n",
    "            scene for scene in scene_list if scene[\"scene_name\"] in scene_names\n",
    "        ]\n",
    "    elif MISSION == \"SENTINEL-1\":\n",
    "        idx = [\n",
    "            i\n",
    "            for i in range(len(items.items))\n",
    "            if items.items[i].properties[\"title\"] in scene_names\n",
    "        ]\n",
    "        scene_list = [\n",
    "            scene for scene in scene_list if scene[\"scene_name\"] in scene_names\n",
    "        ]\n",
    "    else:\n",
    "        idx = [\n",
    "            i\n",
    "            for i in range(len(items.items))\n",
    "            if (\n",
    "                items.items[i].properties[\"landsat:scene_id\"] in scene_ids\n",
    "                and items.items[i].id in scene_names\n",
    "            )\n",
    "        ]\n",
    "        scene_list = [\n",
    "            scene\n",
    "            for scene in scene_list\n",
    "            if (scene[\"scene_name\"] in scene_names and scene[\"scene_id\"] in scene_ids)\n",
    "        ]\n",
    "    new_items = [items.items[i] for i in idx]\n",
    "    items.items = new_items\n",
    "    items.save_object(f\"{output_dir}/items{'_' + tile_id if tile_id else ''}.json\")\n",
    "else:\n",
    "    items = pystac.ItemCollection.from_file(items_file)\n",
    "    scene_list = []\n",
    "    features = items.to_dict()[\"features\"]\n",
    "    for feature in features:\n",
    "        s = {}\n",
    "        for b in bands:\n",
    "            if b in feature[\"assets\"]:\n",
    "                s[b] = feature[\"assets\"][b][\"href\"]\n",
    "                s[b + \"_alternate\"] = (\n",
    "                    s[b]\n",
    "                    if MISSION in [\"SENTINEL-1\", \"SENTINEL-2\"]\n",
    "                    else feature[\"assets\"][b][\"alternate\"][\"s3\"][\"href\"]\n",
    "                )\n",
    "        s[\"scene_name\"] = (\n",
    "            feature[\"properties\"][\"title\"] if MISSION == \"SENTINEL-1\" else feature[\"id\"]\n",
    "        )\n",
    "        scene_list.append(s)\n",
    "    bands_suffixes = get_band_suffixes(scene_list[0], bands)\n",
    "    print(f\"Loaded {len(items.items)} items from {items_file}.\")\n",
    "# items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42144b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_dir = process_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae67bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ext = \"tif\" if MISSION in [\"SENTINEL-1\", \"SENTINEL-2\"] else \"TIF\"\n",
    "scene_files = [\n",
    "    f\"{os.path.basename(os.path.dirname(scene[bands[0]]))}.{ext}\"\n",
    "    for scene in scene_list\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0831b0f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, meta = stream_scene(\n",
    "    (\n",
    "        items[0].assets[bands[0]].href\n",
    "        if MISSION in [\"SENTINEL-1\", \"SENTINEL-2\"]\n",
    "        else items[0].assets[bands[0]].to_dict()[\"alternate\"][\"s3\"][\"href\"]\n",
    "    ),\n",
    "    aws_session,\n",
    "    metadata_only=True,\n",
    ")\n",
    "resolution_ratio = [\n",
    "    meta[\"profile\"][\"transform\"].a / resolution,\n",
    "    -meta[\"profile\"][\"transform\"].e / resolution,\n",
    "]\n",
    "dtype = meta[\"profile\"][\"dtype\"]\n",
    "nodata = meta[\"profile\"][\"nodata\"]\n",
    "print(f\"Resolution ratio: {resolution_ratio}\")\n",
    "print(f\"Data type: {dtype}\")\n",
    "print(f\"Nodata value: {nodata}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a28a9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if MISSION == \"LANDSAT-8\":\n",
    "    patch_url = lambda x: x.replace(\n",
    "        \"https://landsatlook.usgs.gov/data\", \"s3://usgs-landsat\"\n",
    "    )\n",
    "else:\n",
    "    patch_url = None\n",
    "\n",
    "ds_stac = stac_load(\n",
    "    items,\n",
    "    bands=bands,\n",
    "    chunks={},  # {\"x\": 500, \"y\": 500}, # {\"x\": 500, \"y\": 500},\n",
    "    resolution=resolution,\n",
    "    bbox=bbox,\n",
    "    patch_url=patch_url,\n",
    "    groupby=\"id\",\n",
    "    dtype=dtype,\n",
    "    nodata=nodata,\n",
    "    preserve_original_order=True,\n",
    "    # crs=3031,\n",
    ")\n",
    "ds_stac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe9b43c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ext = \"tif\" if MISSION in [\"SENTINEL-1\", \"SENTINEL-2\"] else \"TIF\"\n",
    "# os.makedirs(images_dir, exist_ok=True)\n",
    "# for i in range(len(ds_stac.time)):\n",
    "#     out_file = os.path.join(\n",
    "#         images_dir,\n",
    "#         f\"{os.path.basename(os.path.dirname(items[i].assets[bands[0]].href))}.{ext}\",\n",
    "#     )\n",
    "#     if os.path.exists(out_file):\n",
    "#         print(f\"File {out_file} already exists. Skipping...\")\n",
    "#         continue\n",
    "#     print(f\"Saving file {out_file} {i + 1} of {len(ds_stac.time)}...\", end=\"\\r\")\n",
    "#     ds_stac.isel(time=i).rio.to_raster(out_file)\n",
    "# ds_stac = ds_stac.where(ds_stac > 0, np.float32(np.nan))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46be2e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if MISSION == \"SENTINEL-1\":\n",
    "#     process_existing_outputs(\n",
    "#         glob.glob(f\"{images_dir}/**\"),\n",
    "#         output_dir,\n",
    "#         scale_factor=1.0,\n",
    "#         preserve_depth=True,  # True if you want to preserve the depth of the original dataset\n",
    "#         min_max_scaling=False,  # True if you want to apply min-max scaling\n",
    "#         stretch_contrast=True,\n",
    "#         gamma=0.5,\n",
    "#         three_channel=True,\n",
    "#         remove_nans=True,\n",
    "#         num_cpu=-1,\n",
    "#         write_pairs=False,\n",
    "#         subdir=\"true_colour_ds\",\n",
    "#         file_name_suffix=\"\",\n",
    "#     )\n",
    "#     images_dir = process_ds_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a6501b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# originals = glob.glob(f\"{images_dir}/**\")\n",
    "# originals = [f for f in originals if condition in f]\n",
    "# print(len(originals), \"original scenes found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2bfd462",
   "metadata": {},
   "outputs": [],
   "source": [
    "gmed_file_odc_stac = f\"data/inputs/{MISSION}_{AOI}/geometric_median{'_' + tile_id if tile_id else ''}_odc_stac_{output_suffix}{'_full' if use_all_items else ''}.tif\"\n",
    "# gmed_file_odc = f\"data/inputs/{MISSION}_{AOI}/geometric_median{'_' + tile_id if tile_id else ''}_odc_{output_suffix}{'_full' if use_all_items else ''}.tif\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cce39e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_stac = ds_stac.where(ds_stac > 0, np.float32(np.nan))\n",
    "ds_stac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ee642a",
   "metadata": {},
   "outputs": [],
   "source": [
    "gmed_odc_stac = geomedian_with_mads(\n",
    "    ds_stac,\n",
    "    reshape_strategy=\"yxbt\",  #'yxbt' if data is larger than RAM\n",
    "    compute_mads=False,  # True if you want triple MADs\n",
    "    num_threads=gmed_n_workers,\n",
    ")\n",
    "gmed_odc_stac = gmed_odc_stac.rio.write_crs(f\"epsg:{ds_stac.rio.crs.to_epsg()}\")\n",
    "\n",
    "if os.path.exists(gmed_file_odc_stac):\n",
    "    os.remove(gmed_file_odc_stac)\n",
    "\n",
    "if MISSION == \"SENTINEL-1\":\n",
    "    gmed_odc_stac_img = gmed_odc_stac[bands[:3]].to_array().to_numpy()\n",
    "    gmed_odc_stac_img = np.nan_to_num(gmed_odc_stac_img, nan=0)\n",
    "    gmed_odc_stac_img = apply_gamma(gmed_odc_stac_img, stretch_hist=True).astype(\n",
    "        \"uint8\"\n",
    "    )\n",
    "\n",
    "    profile = rasterio.open(\n",
    "        [\n",
    "            f\n",
    "            for f in glob.glob(images_dir + f\"/*.{ext}\")\n",
    "            if os.path.basename(f) in scene_files\n",
    "        ][0]\n",
    "    ).profile\n",
    "    profile[\"count\"] = len(bands)\n",
    "    # profile[\"transform\"] = gmed_odc_stac.rio.transform()\n",
    "\n",
    "    with rasterio.open(gmed_file_odc_stac, \"w\", **profile) as dst:\n",
    "        for i in range(profile[\"count\"]):\n",
    "            dst.write(gmed_odc_stac_img[i, :, :], i + 1)\n",
    "else:\n",
    "    (gmed_odc_stac[bands[:3]] / 255).clip(0, 255).astype(\"uint8\").rio.to_raster(\n",
    "        gmed_file_odc_stac\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac1121c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"dask: 1 worker 32 threads, gmed: 1 worker, time: 2 mins and 18 secs\"\n",
    "\n",
    "\"dask: 1 workers, 32 threads, gmed: 30 workers, time: 2 mins and 10 secs\" \"✅\"\n",
    "\"dask: 30 workers 1 thread, gmed: 1 worker, time: 1 mins and 32 secs\"\n",
    "\"dask: 30 workers 1 thread, gmed: 30 workers, time: 1 mins and 30 secs\" \"✅\"\n",
    "\"dask: 30 workers 32 threads, gmed: 1 worker, time: 1 mins and 33 secs\"\n",
    "\"dask: 30 workers 32 threads, gmed: 30 workers, time: 1 mins and 30 secs\"\n",
    "\n",
    "\"with chunks (500, 500)\"\n",
    "\"dask: 1 worker 32 threads, gmed: 1 worker, time: 2 mins and 5 secs\"\n",
    "\"dask: 1 workers, 32 threads, gmed: 30 workers, time: 2 mins and 3 secs\"\n",
    "\"dask: 30 workers 1 thread, gmed: 1 worker, time: 1 mins and 53 secs\"\n",
    "\"dask: 30 workers 1 thread, gmed: 30 workers, time: 1 mins and 46 secs\"\n",
    "\"dask: 30 workers 32 threads, gmed: 1 worker, FAILED\"\n",
    "\"dask: 30 workers 32 threads, gmed: 30 workers, FAILED\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a4942b",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name_suffix = \"odc_stac\"  # odc\n",
    "plt.figure(figsize=(10, 10))\n",
    "geo_img = flip_img(rasterio.open(gmed_file_odc_stac).read()).astype(\"uint8\")\n",
    "plt.imshow(geo_img / geo_img.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d02a0618",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ext = \"tif\" if MISSION in [\"SENTINEL-1\", \"SENTINEL-2\"] else \"TIF\"\n",
    "# img_shapes = [\n",
    "#     (rasterio.open(f).count, rasterio.open(f).height, rasterio.open(f).width)\n",
    "#     for f in glob.glob(images_dir + f\"/*.{ext}\")\n",
    "#     if os.path.basename(f) in scene_files\n",
    "# ]\n",
    "# print(len(img_shapes), \"images found in the downsampled directory.\")\n",
    "\n",
    "# transforms = [\n",
    "#     rasterio.open(f).transform\n",
    "#     for f in glob.glob(images_dir + f\"/*.{ext}\")\n",
    "#     if os.path.basename(f) in scene_files\n",
    "# ]\n",
    "\n",
    "# shape_diffs = np.abs(np.diff(img_shapes, axis=0))\n",
    "# transform_diffs = np.abs(np.diff(transforms, axis=0))\n",
    "\n",
    "# shape_condition = np.any(shape_diffs != np.array([0, 0, 0]))\n",
    "# origin_condition = np.any(transform_diffs != np.zeros(9))\n",
    "# shape_condition, origin_condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ba8551",
   "metadata": {},
   "outputs": [],
   "source": [
    "# universal_masking = True\n",
    "# cluster_masks = True  # True if (MISSION == \"SENTINEL-2\") or (use_all_items) else False\n",
    "# force_warping = True\n",
    "\n",
    "# print(force_warping, shape_condition or origin_condition or force_warping)\n",
    "\n",
    "# if force_warping or shape_condition or origin_condition or MISSION == \"SENTINEL-2\":\n",
    "#     print(\"Images have different shapes, warping them to the same shape.\")\n",
    "#     warps_dir = f\"{output_dir}/warped/\"\n",
    "#     if force_warping:\n",
    "#         shutil.rmtree(warps_dir, ignore_errors=True)\n",
    "#     os.makedirs(warps_dir, exist_ok=True)\n",
    "#     imgs_list = [\n",
    "#         f\n",
    "#         for f in glob.glob(images_dir + f\"/*.{ext}\")\n",
    "#         if os.path.basename(f) in scene_files\n",
    "#     ]\n",
    "#     mosaic, warps, profiles = make_mosaic(\n",
    "#         imgs_list,\n",
    "#         return_warps=True,\n",
    "#         return_profile_only=True,\n",
    "#         output_type=\"uint16\",\n",
    "#         universal_masking=universal_masking,\n",
    "#         cluster_masks=cluster_masks,\n",
    "#         nodata=0,\n",
    "#         no_affine=True,\n",
    "#     )\n",
    "#     if universal_masking:\n",
    "#         # masks = warps[1]\n",
    "#         warps = warps[0]\n",
    "#     for i, warp in enumerate(warps):\n",
    "#         warp_path = os.path.join(warps_dir, os.path.basename(imgs_list[i]))\n",
    "#         if not os.path.exists(warp_path):\n",
    "#             with rasterio.open(warp_path, \"w\", **profiles[1]) as warp_ds:\n",
    "#                 for i in range(3):\n",
    "#                     warp_ds.write(warp[:, :, i], i + 1)\n",
    "#     images_dir = warps_dir\n",
    "#     # warps = [np.moveaxis(warp, -1, 0) for warp in warps]\n",
    "\n",
    "# plt.imshow(mosaic / mosaic.max())\n",
    "# mosaic = None\n",
    "# warps = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd23a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(images_dir)\n",
    "# ext = \"tif\" if MISSION in [\"SENTINEL-1\", \"SENTINEL-2\"] else \"TIF\"\n",
    "# if MISSION == \"SENTINEL-1\":\n",
    "#     time_idx = 4\n",
    "# elif MISSION == \"SENTINEL-2\":\n",
    "#     time_idx = 2\n",
    "# else:\n",
    "#     time_idx = 3\n",
    "# times = [\n",
    "#     datetime.strptime(os.path.basename(f).split(\"_\")[time_idx][0:8], \"%Y%m%d\")\n",
    "#     for f in glob.glob(images_dir + f\"/*.{ext}\")\n",
    "#     if os.path.basename(f) in scene_files\n",
    "# ]\n",
    "# files = [\n",
    "#     f for f in glob.glob(images_dir + f\"/*.{ext}\") if os.path.basename(f) in scene_files\n",
    "# ]\n",
    "\n",
    "# crs = meta[\n",
    "#     \"crs\"\n",
    "# ].to_epsg()  # int(crs.split(\":\")[1])  # Extract EPSG code from CRS string\n",
    "# ds = create_dataset_from_files(\n",
    "#     files,\n",
    "#     times,\n",
    "#     crs,\n",
    "#     bands,\n",
    "#     chunks={\"x\": 500, \"y\": 500},\n",
    "# )\n",
    "# ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b012784f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gmed_odc = geomedian_with_mads(\n",
    "#     ds,\n",
    "#     reshape_strategy=\"yxbt\",  #'yxbt' if data is larger than RAM\n",
    "#     compute_mads=False,  # True if you want triple MADs\n",
    "# )\n",
    "# gmed_odc = gmed_odc.rio.write_crs(f\"epsg:{crs}\")\n",
    "# gmed_odc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0588ce49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if os.path.exists(gmed_file_odc):\n",
    "#     os.remove(gmed_file_odc)\n",
    "# if MISSION == \"SENTINEL-1\":\n",
    "#     gmed_odc[bands[:3]].astype(\"uint8\").rio.to_raster(gmed_file_odc)\n",
    "# else:\n",
    "#     (gmed_odc[bands[:3]] / 255).clip(0, 255).astype(\"uint8\").rio.to_raster(\n",
    "#         gmed_file_odc\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "068bc10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# enhance = True\n",
    "# # gm_outputs = [gmed_file_pcm, gmed_file_gm, gmed_file_odc, gmed_file_odc_stac]\n",
    "\n",
    "# gm_outputs = [gmed_file_odc] if file_name_suffix == \"odc\" else [gmed_file_odc_stac]\n",
    "\n",
    "# imgs_files = [\n",
    "#     f for f in glob.glob(images_dir + f\"/*.{ext}\") if os.path.basename(f) in scene_files\n",
    "# ][:4]\n",
    "\n",
    "# imgs = [rasterio.open(f).read() for f in imgs_files]\n",
    "\n",
    "# img_samples = imgs\n",
    "# to_plot = []\n",
    "# if MISSION == \"SENTINEL-1\":\n",
    "#     for img in img_samples:\n",
    "#         img[2, :, :] = (\n",
    "#             0  # ((img[1, :, :] + img[0, :, :]) / 2).astype(\"uint8\")  # Create a 3-channel image\n",
    "#         )\n",
    "#         img = flip_img(img).astype(\"uint8\")\n",
    "#         to_plot.append(img)\n",
    "# else:\n",
    "#     for img in img_samples:\n",
    "#         img = np.clip(flip_img(img) / 255, 0, 255).astype(\"uint8\")\n",
    "#         to_plot.append(img)\n",
    "\n",
    "# gm_imgs = [flip_img(rasterio.open(f).read()).astype(\"uint8\") for f in gm_outputs]\n",
    "\n",
    "# for img in gm_imgs:\n",
    "#     out_img = np.zeros((img.shape[0], img.shape[1], 3), dtype=\"uint8\")\n",
    "#     for i in range(img.shape[2]):\n",
    "#         out_img[:, :, i] = img[:, :, i]\n",
    "#     to_plot.append(out_img)\n",
    "\n",
    "# if enhance:\n",
    "#     # to_plot = [apply_gamma(img, stretch_hist=True) for img in to_plot]\n",
    "#     to_plot = [img / img.max() for img in to_plot]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b5723de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
