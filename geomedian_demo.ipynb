{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042e4ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from utils import *\n",
    "import dask\n",
    "import dask.distributed\n",
    "import geopandas as gpd\n",
    "from odc.algo import geomedian_with_mads\n",
    "from odc.geo import BoundingBox\n",
    "from odc.stac import configure_rio, stac_load\n",
    "from functools import reduce\n",
    "from matplotlib.gridspec import GridSpec\n",
    "\n",
    "dask_n_workers = 1  # os.cpu_count() - 2\n",
    "threads_per_worker = os.cpu_count()\n",
    "gmed_n_workers = 1  # os.cpu_count() - 2\n",
    "\n",
    "shutil.rmtree(\"temp_dask_dir\", ignore_errors=True)\n",
    "os.makedirs(\"temp_dask_dir\", exist_ok=True)\n",
    "\n",
    "# Increase connection and TCP timeouts\n",
    "dask.config.set({\"distributed.comm.timeouts.connect\": \"60s\"})\n",
    "dask.config.set({\"distributed.comm.timeouts.tcp\": \"300s\"})\n",
    "\n",
    "# Increase nanny timeouts (for worker management)\n",
    "dask.config.set({\"distributed.nanny.timeouts.startup\": \"300s\"})\n",
    "dask.config.set({\"distributed.nanny.timeouts.connect\": \"300s\"})\n",
    "dask.config.set({\"distributed.nanny.timeouts.terminate\": \"300s\"})\n",
    "\n",
    "client = dask.distributed.Client(\n",
    "    n_workers=dask_n_workers,\n",
    "    threads_per_worker=threads_per_worker,\n",
    "    local_directory=\"temp_dask_dir\",\n",
    ")\n",
    "\n",
    "display(client)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad42b75c",
   "metadata": {},
   "source": [
    "Specifying Mission and configuring AWS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c02548ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "aws_session = rasterio.session.AWSSession(boto3.Session(), requester_pays=True)\n",
    "configure_rio(cloud_defaults=True, aws={\"requester_pays\": True}, client=client)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e7a715",
   "metadata": {},
   "source": [
    "Runtime params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a24f9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "MISSION = \"LANDSAT-8\"\n",
    "max_cloud_cover = 5\n",
    "min_scenes_per_id = 10\n",
    "amery_rock = [67.45, -72.55, 67.55, -72.45]\n",
    "AOI = \"AMERY_ROCK_DEMO\"\n",
    "bands = [\"red\", \"green\", \"blue\"]\n",
    "resolution = 200\n",
    "band_scale = np.float32(2.0e-5)\n",
    "band_offset = np.float32(-0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dbcccdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = f\"data/inputs/{MISSION}_{AOI}\"\n",
    "process_dir = f\"{output_dir}/true_colour\"\n",
    "items_file = f\"{output_dir}/items.json\"\n",
    "items_exist = os.path.exists(items_file)\n",
    "print(items_file)\n",
    "items_exist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6362e994",
   "metadata": {},
   "source": [
    "Querying and processing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6566af8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not items_exist:\n",
    "    query = get_search_query(\n",
    "        amery_rock,\n",
    "        start_date=\"2013-01-01T00:00:00\",\n",
    "        end_date=\"2017-01-01T00:00:00\",\n",
    "        platform=[\"LANDSAT_8\"],\n",
    "        collection_category=None,\n",
    "        collections=None,\n",
    "        cloud_cover=max_cloud_cover,\n",
    "    )\n",
    "    use_pystac = False\n",
    "    server_url = \"https://landsatlook.usgs.gov/stac-server/search\"\n",
    "    display(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd30575",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not items_exist:\n",
    "    items = query_stac_server(\n",
    "        query,\n",
    "        server_url,\n",
    "        use_pystac=use_pystac,\n",
    "        max_cloud_cover=max_cloud_cover,\n",
    "    )\n",
    "    print(f\"Found {len(items)} items.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a5c21f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not items_exist and len(items) > 0:\n",
    "    scene_dict, scene_list = find_scenes_dict(\n",
    "        items.copy(),\n",
    "        one_per_month=True,\n",
    "        acceptance_list=bands + [\"thumbnail\"],\n",
    "        remove_duplicate_times=True,\n",
    "        duplicate_idx=1,\n",
    "        min_scenes_per_id=min_scenes_per_id,\n",
    "        id_filter=\"L1GT\",\n",
    "    )\n",
    "    pd.DataFrame(scene_list).to_csv(\n",
    "        f\"data/inputs/{MISSION}_{AOI}_scenes.csv\", index=False\n",
    "    )\n",
    "    path_rows = list(scene_dict.keys())\n",
    "    print(\"Found IDs: \", path_rows)\n",
    "\n",
    "    path_row_list = [\n",
    "        (i, path_row, len(scene_dict[path_row])) for i, path_row in enumerate(path_rows)\n",
    "    ]\n",
    "    pd.DataFrame(path_row_list, columns=[\"index\", \"path_row\", \"count\"]).to_csv(\n",
    "        f\"data/inputs/{MISSION}_{AOI}_scene_counts.csv\", index=False\n",
    "    )\n",
    "    print(\"Found scene counts: \", path_row_list)\n",
    "    print(\"Found scenes counts after filtering: \", len(scene_list))\n",
    "\n",
    "    items = pystac.ItemCollection(items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c67251d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_row_list = pd.read_csv(f\"data/inputs/{MISSION}_{AOI}_scene_counts.csv\")\n",
    "print(\"Found scene counts: \\n\", path_row_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f304328",
   "metadata": {},
   "outputs": [],
   "source": [
    "tile_id = \"\"\n",
    "items_file = f\"{output_dir}/items.json\"\n",
    "full_items_file = items_file\n",
    "items_file = f\"{output_dir}/items{'_' + tile_id if tile_id else ''}.json\"\n",
    "items_exist = os.path.exists(items_file)\n",
    "condition = tile_id if tile_id != \"\" else \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9842a61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not items_exist:\n",
    "    if tile_id != \"\":\n",
    "        items = pystac.ItemCollection.from_file(full_items_file)\n",
    "    scenes = pd.read_csv(f\"data/inputs/{MISSION}_{AOI}_scenes.csv\")\n",
    "    scene_list = scenes.to_dict(\"records\")\n",
    "    bands_suffixes = get_band_suffixes(scene_list[0], bands)\n",
    "    print(len(scene_list), \"scenes found in the CSV file.\")\n",
    "    scene_names = [\n",
    "        scene[\"scene_name\"] for scene in scene_list if condition in scene[\"scene_name\"]\n",
    "    ]\n",
    "    scene_ids = [\n",
    "        scene[\"scene_id\"] for scene in scene_list if condition in scene[\"scene_id\"]\n",
    "    ]\n",
    "\n",
    "    gdf = gpd.GeoDataFrame.from_features(items, \"epsg:4326\")\n",
    "    id_col = \"landsat:scene_id\"\n",
    "    item_names = list(gdf[id_col].apply(lambda x: x.split(\"/\")[-1]))\n",
    "    idx = [item_names.index(i) for i in scene_ids]\n",
    "    gdf = gdf.iloc[idx].reset_index(drop=True)\n",
    "    print(len(gdf), \"items found in the GeoDataFrame.\")\n",
    "\n",
    "    idx = [\n",
    "        i\n",
    "        for i in range(len(items.items))\n",
    "        if (\n",
    "            items.items[i].properties[\"landsat:scene_id\"] in scene_ids\n",
    "            and items.items[i].id in scene_names\n",
    "        )\n",
    "    ]\n",
    "    scene_list = [\n",
    "        scene\n",
    "        for scene in scene_list\n",
    "        if (scene[\"scene_name\"] in scene_names and scene[\"scene_id\"] in scene_ids)\n",
    "    ]\n",
    "    new_items = [items.items[i] for i in idx]\n",
    "    items.items = new_items\n",
    "    items.save_object(f\"{output_dir}/items{'_' + tile_id if tile_id else ''}.json\")\n",
    "else:\n",
    "    items = pystac.ItemCollection.from_file(items_file)\n",
    "    scene_list = []\n",
    "    features = items.to_dict()[\"features\"]\n",
    "    for feature in features:\n",
    "        s = {}\n",
    "        for b in bands:\n",
    "            if b in feature[\"assets\"]:\n",
    "                s[b] = feature[\"assets\"][b][\"href\"]\n",
    "                s[b + \"_alternate\"] = feature[\"assets\"][b][\"alternate\"][\"s3\"][\"href\"]\n",
    "        s[\"scene_name\"] = feature[\"id\"]\n",
    "        scene_list.append(s)\n",
    "    bands_suffixes = get_band_suffixes(scene_list[0], bands)\n",
    "    print(f\"Loaded {len(items.items)} items from {items_file}.\")\n",
    "# items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38516cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gdf.explore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42144b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_dir = process_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae9afbf",
   "metadata": {},
   "source": [
    "Dwonlading metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1efa30b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, meta = stream_scene(\n",
    "    items[0].assets[bands[0]].to_dict()[\"alternate\"][\"s3\"][\"href\"],\n",
    "    aws_session,\n",
    "    metadata_only=True,\n",
    ")\n",
    "resolution_ratio = [\n",
    "    meta[\"profile\"][\"transform\"].a / resolution,\n",
    "    -meta[\"profile\"][\"transform\"].e / resolution,\n",
    "]\n",
    "print(f\"Resolution ratio: {resolution_ratio}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89add72a",
   "metadata": {},
   "source": [
    "Dwonlading original files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4323fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "scene_name_map = lambda x: (x.replace(\"_SR\", \"\"))\n",
    "download_and_process_series(\n",
    "    scene_list,\n",
    "    bands,\n",
    "    bands_suffixes,\n",
    "    output_dir,\n",
    "    process_dir,\n",
    "    \"temp\",\n",
    "    aws_session=aws_session,\n",
    "    keep_original_band_scenes=True,\n",
    "    scene_name_map=scene_name_map,\n",
    "    extra_bands=None,\n",
    "    download_only=True,\n",
    "    stream_out_scale_factor=resolution_ratio,\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae67bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "scene_files = [os.path.basename(scene[\"local_path\"]) for scene in scene_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c04d56",
   "metadata": {},
   "source": [
    "Processing original files and making true colour composites for manual loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46be2e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ext = \"TIF\"\n",
    "orig_dir = f\"{output_dir}/Originals\"\n",
    "dir_list = [glob.glob(f\"{dir}/**\") for dir in glob.glob(f\"{orig_dir}/**\")]\n",
    "dir_list = [\n",
    "    [\n",
    "        list(filter(lambda x: x.endswith(f\"{idx}.{ext}\"), dir_name))[0]\n",
    "        for idx in bands_suffixes\n",
    "    ]\n",
    "    for dir_name in dir_list\n",
    "]\n",
    "process_existing_outputs(\n",
    "    dir_list,\n",
    "    output_dir,\n",
    "    scale_factor=1.0,  # resolution_ratio,\n",
    "    preserve_depth=True,  # True if you want to preserve the depth of the original dataset\n",
    "    min_max_scaling=False,  # True if you want to apply min-max scaling\n",
    "    stretch_contrast=False,\n",
    "    gamma=1.0,\n",
    "    three_channel=False,\n",
    "    remove_nans=False,\n",
    "    num_cpu=-1,\n",
    "    write_pairs=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a6501b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ext = \"TIF\"\n",
    "originals = glob.glob(f\"{output_dir}/Originals/**/*.{ext}\", recursive=True)\n",
    "originals = [f for f in originals if condition in f]\n",
    "print(len(originals), \"original scenes found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60888a1a",
   "metadata": {},
   "source": [
    "Output files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2bfd462",
   "metadata": {},
   "outputs": [],
   "source": [
    "gmed_file_odc_stac = f\"data/inputs/{MISSION}_{AOI}/geometric_median{'_' + tile_id if tile_id else ''}_odc_stac.tif\"\n",
    "gmed_file_odc = f\"data/inputs/{MISSION}_{AOI}/geometric_median{'_' + tile_id if tile_id else ''}_odc.tif\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6afa2d6",
   "metadata": {},
   "source": [
    "Loading data via odc-stac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319287eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_dir = f\"{output_dir}/Originals\"\n",
    "print(f\"Originals directory: {orig_dir}\")\n",
    "\n",
    "patch_url = lambda x: os.path.join(*([orig_dir] + x.split(\"/\")[-2:]))\n",
    "\n",
    "ds_stac = stac_load(\n",
    "    items,\n",
    "    bands=bands,\n",
    "    chunks={},  # {\"x\": 500, \"y\": 500},\n",
    "    groupby=\"id\",\n",
    "    resolution=resolution,\n",
    "    patch_url=patch_url,\n",
    "    preserve_original_order=True,\n",
    "    crs=meta[\"crs\"],\n",
    "    # bbox=amery_rock,\n",
    ")\n",
    "ds_stac[bands] = ds_stac[bands] * band_scale + band_offset\n",
    "ds_stac = ds_stac.where(ds_stac > 0)\n",
    "ds_stac"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ae3785",
   "metadata": {},
   "source": [
    "Geomedian via odc-stac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ee642a",
   "metadata": {},
   "outputs": [],
   "source": [
    "gmed_odc_stac = geomedian_with_mads(\n",
    "    ds_stac,\n",
    "    reshape_strategy=\"yxbt\",  #'yxbt' if data is larger than RAM\n",
    "    compute_mads=False,  # True if you want triple MADs\n",
    "    num_threads=gmed_n_workers,\n",
    ")\n",
    "gmed_odc_stac = gmed_odc_stac.rio.write_crs(f\"epsg:{ds_stac.rio.crs.to_epsg()}\")\n",
    "\n",
    "if os.path.exists(gmed_file_odc_stac):\n",
    "    os.remove(gmed_file_odc_stac)\n",
    "\n",
    "\n",
    "gmed_odc_stac[bands[:3]].rio.to_raster(gmed_file_odc_stac)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90cbcce1",
   "metadata": {},
   "source": [
    "Geo-referrencing input data for manual loading. Also optionally applying masking filters for removing shadow effects around edges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b0b651",
   "metadata": {},
   "outputs": [],
   "source": [
    "ext = \"TIF\"\n",
    "img_shapes = [\n",
    "    (rasterio.open(f).count, rasterio.open(f).height, rasterio.open(f).width)\n",
    "    for f in glob.glob(images_dir + f\"/*.{ext}\")\n",
    "    if os.path.basename(f) in scene_files\n",
    "]\n",
    "print(len(img_shapes), \"images found in the downsampled directory.\")\n",
    "\n",
    "transforms = [\n",
    "    rasterio.open(f).transform\n",
    "    for f in glob.glob(images_dir + f\"/*.{ext}\")\n",
    "    if os.path.basename(f) in scene_files\n",
    "]\n",
    "\n",
    "shape_diffs = np.abs(np.diff(img_shapes, axis=0))\n",
    "transform_diffs = np.abs(np.diff(transforms, axis=0))\n",
    "\n",
    "shape_condition = np.any(shape_diffs != np.array([0, 0, 0]))\n",
    "origin_condition = np.any(transform_diffs != np.zeros(9))\n",
    "shape_condition, origin_condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ba8551",
   "metadata": {},
   "outputs": [],
   "source": [
    "universal_masking = True\n",
    "cluster_masks = True\n",
    "\n",
    "images_dir = process_dir\n",
    "print(\"Images have different shapes, warping them to the same shape.\")\n",
    "warps_dir = f\"{output_dir}/warped/\"\n",
    "\n",
    "shutil.rmtree(warps_dir, ignore_errors=True)\n",
    "os.makedirs(warps_dir, exist_ok=True)\n",
    "\n",
    "imgs_list = [\n",
    "    f for f in glob.glob(images_dir + f\"/*.{ext}\") if os.path.basename(f) in scene_files\n",
    "]\n",
    "mosaic, warps, profiles = make_mosaic(\n",
    "    imgs_list,\n",
    "    return_warps=True,\n",
    "    return_profile_only=True,\n",
    "    output_type=\"uint16\",\n",
    "    universal_masking=universal_masking,\n",
    "    cluster_masks=cluster_masks,\n",
    "    nodata=0,\n",
    ")\n",
    "if universal_masking:\n",
    "    # masks = warps[1]\n",
    "    warps = warps[0]\n",
    "warp_profile = profiles[1]\n",
    "warp_profile.update(\n",
    "    blockxsize=warp_profile[\"width\"], blockysize=1, tiled=False, interleave=\"pixel\"\n",
    ")\n",
    "for i, warp in enumerate(warps):\n",
    "    warp_path = os.path.join(warps_dir, os.path.basename(imgs_list[i]))\n",
    "    if not os.path.exists(warp_path):\n",
    "        with rasterio.open(warp_path, \"w\", **warp_profile) as warp_ds:\n",
    "            for i in range(3):\n",
    "                warp_ds.write(warp[:, :, i], i + 1)\n",
    "images_dir = warps_dir\n",
    "# warps = [np.moveaxis(warp, -1, 0) for warp in warps]\n",
    "\n",
    "plt.imshow(mosaic / mosaic.max())\n",
    "mosaic = None\n",
    "warps = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a6b710",
   "metadata": {},
   "source": [
    "Manual loading of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd23a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_dir = f\"{output_dir}/warped/\"\n",
    "print(images_dir)\n",
    "ext = \"TIF\"\n",
    "times = [\n",
    "    datetime.strptime(os.path.basename(f).split(\"_\")[3][0:8], \"%Y%m%d\")\n",
    "    for f in glob.glob(images_dir + f\"/*.{ext}\")\n",
    "    if os.path.basename(f) in scene_files\n",
    "]\n",
    "files = [f\"{os.path.join(images_dir, item.id)}_PROC.{ext}\" for item in items]\n",
    "files = [f for f in files if os.path.basename(f) in scene_files]\n",
    "assert all([os.path.exists(f) for f in files]), \"Not all files exist!\"\n",
    "\n",
    "crs = meta[\n",
    "    \"crs\"\n",
    "].to_epsg()  # int(crs.split(\":\")[1])  # Extract EPSG code from CRS string\n",
    "ds = create_dataset_from_files(\n",
    "    files,\n",
    "    times,\n",
    "    crs,\n",
    "    bands,\n",
    "    band_scale=band_scale,\n",
    "    band_offset=band_offset,\n",
    "    chunks={},  # {\"x\": 500, \"y\": 500},\n",
    "    # bbox=amery_rock,\n",
    "    bbox_crs=4326,\n",
    ")\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1bc6d2c",
   "metadata": {},
   "source": [
    "Geomedian for manually loaded data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b012784f",
   "metadata": {},
   "outputs": [],
   "source": [
    "gmed_odc = geomedian_with_mads(\n",
    "    ds,\n",
    "    reshape_strategy=\"yxbt\",  #'yxbt' if data is larger than RAM\n",
    "    compute_mads=False,  # True if you want triple MADs\n",
    "    num_threads=gmed_n_workers,\n",
    ")\n",
    "gmed_odc = gmed_odc.rio.write_crs(f\"epsg:{crs}\")\n",
    "gmed_odc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0588ce49",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(gmed_file_odc):\n",
    "    os.remove(gmed_file_odc)\n",
    "gmed_odc[bands[:3]].rio.to_raster(gmed_file_odc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "681ddd9c",
   "metadata": {},
   "source": [
    "Plotting results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a4942b",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name_suffix = \"odc\"  # odc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "068bc10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "enhance = True\n",
    "\n",
    "gm_outputs = [gmed_file_odc] if file_name_suffix == \"odc\" else [gmed_file_odc_stac]\n",
    "\n",
    "images_dir = process_dir\n",
    "imgs_files = [\n",
    "    f for f in glob.glob(images_dir + f\"/*.{ext}\") if os.path.basename(f) in scene_files\n",
    "][:4]\n",
    "\n",
    "imgs = [rasterio.open(f).read() for f in imgs_files]\n",
    "\n",
    "img_samples = imgs\n",
    "to_plot = []\n",
    "\n",
    "for img in img_samples:\n",
    "    img = np.clip(flip_img(img) / 255, 0, 255).astype(\"uint8\")\n",
    "    to_plot.append(img)\n",
    "\n",
    "gm_imgs = [np.nan_to_num(flip_img(rasterio.open(f).read())) for f in gm_outputs]\n",
    "\n",
    "for img in gm_imgs:\n",
    "    out_img = np.zeros((img.shape[0], img.shape[1], 3), dtype=\"float32\")\n",
    "    for i in range(img.shape[2]):\n",
    "        out_img[:, :, i] = img[:, :, i]\n",
    "    to_plot.append(out_img)\n",
    "\n",
    "if enhance:\n",
    "    # to_plot = [apply_gamma(img, stretch_hist=True) for img in to_plot]\n",
    "    to_plot = [img / img.max() for img in to_plot]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5010ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 20), dpi=300)\n",
    "gs = GridSpec(4, 2, figure=fig)\n",
    "ax0 = fig.add_subplot(gs[0:2, 0:2])\n",
    "ax1 = fig.add_subplot(gs[2, 0])\n",
    "ax2 = fig.add_subplot(gs[2, 1])\n",
    "ax3 = fig.add_subplot(gs[3, 0])\n",
    "ax4 = fig.add_subplot(gs[3, 1])\n",
    "ax1.imshow((to_plot[0]))\n",
    "ax1.set_title(\"Image 0\")\n",
    "ax2.imshow(to_plot[1])\n",
    "ax2.set_title(\"Image 1\")\n",
    "ax3.imshow(to_plot[2])\n",
    "ax3.set_title(\"Image 2\")\n",
    "ax4.imshow(to_plot[3])\n",
    "ax4.set_title(\"Image 3\")\n",
    "ax0.imshow(to_plot[4])\n",
    "ax0.set_title(\n",
    "    f\"Geometric Median of {len(scene_files)} {MISSION} images from {AOI} AOI, {'ID: ' + tile_id if tile_id else ''}, ({file_name_suffix.replace('_', ' ')})\"\n",
    ")\n",
    "for ax in [ax0, ax1, ax2, ax3, ax4]:\n",
    "    ax.axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\n",
    "    f\"{output_dir}/geometric_median_{MISSION}_{AOI}{'_' + tile_id if tile_id else ''}_{file_name_suffix}.png\",\n",
    "    dpi=300,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3acb8bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(10, 5), dpi=300)\n",
    "im1 = np.nan_to_num(\n",
    "    flip_img(\n",
    "        rasterio.open(\"temp_dem_imgs/geometric_median_odc_stac_incorrect.tif\").read()\n",
    "    )\n",
    ")\n",
    "im2 = np.nan_to_num(\n",
    "    flip_img(\n",
    "        rasterio.open(\"temp_dem_imgs/geometric_median_odc_stac_corrected.tif\").read()\n",
    "    )\n",
    ")\n",
    "\n",
    "axes[0].imshow(im1 / im1.max())\n",
    "axes[0].set_title(\"Incorrect reflectance\")\n",
    "axes[0].axis(\"off\")\n",
    "axes[1].imshow(im2 / im2.max())\n",
    "axes[1].set_title(\"Corrected reflectance\")\n",
    "axes[1].axis(\"off\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd48224",
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.rmtree(\"temp_dask_dir\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9235a3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.rmtree(\"temp_data\", ignore_errors=True)\n",
    "ref = np.zeros((5, 5, 3), dtype=np.float32)\n",
    "tgts = [np.zeros((5, 5, 3), dtype=np.float32) for _ in range(3)]\n",
    "ref[1:4, 1:4, :] = 1.0\n",
    "tgts[2][0:3, 0:3, :] = 1.0\n",
    "plt.imshow(ref / ref.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b94785",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(tgts[2] / tgts[2].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b5723de",
   "metadata": {},
   "outputs": [],
   "source": [
    "tgts[0] = ref.copy()\n",
    "tgts[1] = ref.copy()\n",
    "profile = {\n",
    "    \"driver\": \"GTiff\",\n",
    "    \"dtype\": \"uint16\",\n",
    "    \"nodata\": 0,\n",
    "    \"width\": 5,\n",
    "    \"height\": 5,\n",
    "    \"count\": 3,\n",
    "    \"crs\": \"EPSG:3031\",\n",
    "    \"transform\": rasterio.Affine(10.0, 0.0, 1000.0, 0.0, -10.0, 1000.0),\n",
    "    \"blockxsize\": 5,\n",
    "    \"blockysize\": 5,\n",
    "    \"tiled\": False,\n",
    "    \"interleave\": \"band\",\n",
    "}\n",
    "os.makedirs(\"temp_data\", exist_ok=True)\n",
    "ref_fp = \"temp_data/ref.tif\"\n",
    "with rasterio.open(ref_fp, \"w\", **profile) as dst:\n",
    "    for i in range(0, profile[\"count\"]):\n",
    "        dst.write(ref[:, :, i], i + 1)\n",
    "\n",
    "for i, tgt in enumerate(tgts):\n",
    "    tgt_fp = f\"temp_data/tgt_{i}.tif\"\n",
    "    with rasterio.open(tgt_fp, \"w\", **profile) as dst:\n",
    "        for i in range(0, profile[\"count\"]):\n",
    "            dst.write(tgt[:, :, i], i + 1)\n",
    "paths = [ref_fp] + [f\"temp_data/tgt_{i}.tif\" for i in range(len(tgts))]\n",
    "ds = create_dataset_from_files(paths, crs=3031, remove_val=None)\n",
    "gmed = geomedian_with_mads(\n",
    "    ds,\n",
    "    reshape_strategy=\"yxbt\",  #'yxbt' if data is larger than RAM\n",
    "    compute_mads=False,  # True if you want triple MADs\n",
    ")\n",
    "gmed = gmed[[\"band_1\", \"band_2\", \"band_3\"]]\n",
    "gmed = gmed.rio.write_crs(\"epsg:3031\")\n",
    "gmed_img = gmed.to_array().to_numpy()\n",
    "plt.imshow(flip_img(np.nan_to_num(gmed_img)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b654f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gmed_img[0, :, :])\n",
    "gmed_img[gmed_img > 0.0] = 1.0\n",
    "plt.imshow(flip_img(gmed_img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb7f4f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
