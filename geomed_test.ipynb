{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042e4ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from geom_median.numpy import compute_geometric_median as gm\n",
    "import numpy as np\n",
    "from utils import *\n",
    "import dask\n",
    "import dask.distributed\n",
    "import xarray as xr\n",
    "import rioxarray as rxr\n",
    "from hdstats import nangeomedian_pcm\n",
    "import geopandas as gpd\n",
    "from odc.algo import (\n",
    "    enum_to_bool,\n",
    "    geomedian_with_mads,\n",
    "    erase_bad,\n",
    "    mask_cleanup,\n",
    "    keep_good_only,\n",
    ")\n",
    "from odc.geo import BoundingBox\n",
    "from odc.geo.xr import assign_crs\n",
    "from odc.io.cgroups import get_cpu_quota\n",
    "from odc.stac import configure_rio, stac_load\n",
    "import pystac\n",
    "import logging\n",
    "\n",
    "MISSION = \"SENTINEL-2\"  # or \"LANDSAT-8\"\n",
    "\n",
    "client = dask.distributed.Client(\n",
    "    n_workers=4, threads_per_worker=1, silence_logs=logging.ERROR\n",
    ")\n",
    "\n",
    "if MISSION == \"LANDSAT-8\":\n",
    "    aws_session = rasterio.session.AWSSession(boto3.Session(), requester_pays=True)\n",
    "    configure_rio(cloud_defaults=True, aws={\"requester_pays\": True}, client=client)\n",
    "else:\n",
    "    aws_session = rasterio.session.AWSSession(boto3.Session())\n",
    "    configure_rio(cloud_defaults=True, aws={\"aws_unsigned\": True}, client=client)\n",
    "display(client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb44a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "wa_bbox = resize_bbox(BoundingBox(*kml_to_poly(\"data/inputs_old/WA.kml\").bounds), 0.1)\n",
    "geo_1_box = resize_bbox(\n",
    "    BoundingBox(*kml_to_poly(\"data/inputs_old/geo1.kml\").bounds), 0.1\n",
    ")\n",
    "bbox_list = [\n",
    "    wa_bbox,\n",
    "    [67.45, -72.55, 67.55, -72.45],\n",
    "    geo_1_box,\n",
    "]  # WA and a small area in the Arctic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a24f9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "AOI = \"AU_TEST\"\n",
    "aoi_idx = 0\n",
    "bbox = bbox_list[aoi_idx]\n",
    "masking_band = [\"scl\"]\n",
    "measurements = [\"red\", \"green\", \"blue\"]\n",
    "mask_filters = [(\"opening\", 10), (\"dilation\", 1)]\n",
    "# crs = \"EPSG:3031\"\n",
    "resolution = 100 if MISSION == \"SENTINEL-2\" else 200\n",
    "tile_id = \"\"\n",
    "condition = tile_id if tile_id != \"\" else \"\"\n",
    "output_suffix = \"odc_loader\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dbcccdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "bands = measurements + masking_band if MISSION == \"SENTINEL-2\" else measurements\n",
    "output_dir = f\"data/inputs/{MISSION}_{AOI}\"\n",
    "items_file = f\"{output_dir}/items{'_' + tile_id if tile_id else ''}.json\"\n",
    "items_exist = os.path.exists(items_file)\n",
    "items_exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee7d389f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MISSION = \"SENTINEL-1\"\n",
    "# bands = [\"VH\", \"VV\"]\n",
    "# aus_bbox = BoundingBox(\n",
    "#     left=147.07251,\n",
    "#     bottom=-42.22120,\n",
    "#     right=147.24274,\n",
    "#     top=-42.03035,\n",
    "#     crs=\"EPSG:4326\"\n",
    "# )\n",
    "# bbox = aus_bbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6566af8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not items_exist:\n",
    "    if MISSION == \"SENTINEL-2\":\n",
    "        query = get_search_query(\n",
    "            bbox,\n",
    "            collections=[\"sentinel-2-l2a\"],\n",
    "            start_date=\"2016-01-01T00:00:00\",\n",
    "            end_date=\"2021-01-01T00:00:00\",\n",
    "            pystac_query=True,\n",
    "        )\n",
    "        use_pystac = True\n",
    "        server_url = \"https://earth-search.aws.element84.com/v1\"\n",
    "    elif MISSION == \"SENTINEL-1\":\n",
    "        query = get_search_query(\n",
    "            bbox,\n",
    "            collections=[\"ga_s1_iw_vv_vh_c0\"],\n",
    "            start_date=\"2016-01-01T00:00:00\",\n",
    "            end_date=\"2021-01-01T00:00:00\",\n",
    "            pystac_query=True,\n",
    "        )\n",
    "        use_pystac = True\n",
    "        server_url = \"https://explorer.dev.dea.ga.gov.au/stac\"\n",
    "    elif MISSION == \"LANDSAT-8\":\n",
    "        query = get_search_query(\n",
    "            bbox,\n",
    "            start_date=\"2013-01-01T00:00:00\",\n",
    "            end_date=\"2017-01-01T00:00:00\",\n",
    "            platform=[\"LANDSAT_8\"],\n",
    "            collection_category=None,\n",
    "            collections=None,\n",
    "        )\n",
    "        use_pystac = False\n",
    "        server_url = \"https://landsatlook.usgs.gov/stac-server/search\"\n",
    "    elif MISSION == \"LANDSAT-4-5\":\n",
    "        query = get_search_query(\n",
    "            bbox,\n",
    "            start_date=\"1985-01-01T00:00:00\",\n",
    "            end_date=\"2010-12-30T00:00:00\",\n",
    "            platform=[\"LANDSAT_4\", \"LANDSAT_5\"],\n",
    "            collection_category=None,\n",
    "            collections=None,\n",
    "            cloud_cover=None,\n",
    "        )\n",
    "        use_pystac = False\n",
    "        server_url = \"https://landsatlook.usgs.gov/stac-server/search\"\n",
    "\n",
    "    display(query)\n",
    "    items = query_stac_server(query, server_url, pystac=use_pystac)\n",
    "    print(f\"Found {len(items)} items.\")\n",
    "\n",
    "    scene_dict, scene_list = find_scenes_dict(\n",
    "        items,\n",
    "        one_per_month=True,\n",
    "        acceptance_list=bands + [\"thumbnail\"],\n",
    "        remove_duplicate_times=True,\n",
    "        duplicate_idx=1,\n",
    "    )\n",
    "    pd.DataFrame(scene_list).to_csv(\n",
    "        f\"data/inputs/{MISSION}_{AOI}_scenes.csv\", index=False\n",
    "    )\n",
    "    path_rows = list(scene_dict.keys())\n",
    "    print(\"Found IDs: \", path_rows)\n",
    "\n",
    "    items = pystac.ItemCollection(items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8424f035",
   "metadata": {},
   "outputs": [],
   "source": [
    "scene_list = []\n",
    "scene_dict = dict()\n",
    "for feature in items:\n",
    "    is_item = type(feature) != dict\n",
    "\n",
    "    if is_item:\n",
    "        feature = feature.to_dict()\n",
    "\n",
    "    id = feature[\"properties\"][\"title\"]\n",
    "\n",
    "    if \"landsat:scene_id\" in feature[\"properties\"]:\n",
    "        scene_id = feature[\"properties\"][\"landsat:scene_id\"]\n",
    "    else:\n",
    "        scene_id = None\n",
    "\n",
    "    assets = feature[\"assets\"]\n",
    "\n",
    "    if len(bands) > 0:\n",
    "        acceptance_condition = all([s in assets for s in bands])\n",
    "    else:\n",
    "        acceptance_condition = True\n",
    "\n",
    "    if acceptance_condition:\n",
    "        scene_dict[id] = dict(scene_id=scene_id)\n",
    "        for s in bands:\n",
    "            url = assets[s][\"href\"]\n",
    "            if \"alternate\" in assets[s]:\n",
    "                url_alternate = assets[s][\"alternate\"][\"s3\"][\"href\"]\n",
    "            else:\n",
    "                url_alternate = url\n",
    "\n",
    "            scene_dict[id][s] = url\n",
    "            scene_dict[id][f\"{s}_alternate\"] = url_alternate\n",
    "\n",
    "f0 = items[0].to_dict() if type(items[0]) != dict else items[0]\n",
    "if \"landsat:scene_id\" in f0[\"properties\"]:\n",
    "    path_rows = [k.split(\"_\")[2] for k in scene_dict]\n",
    "    time_ind = 3\n",
    "else:\n",
    "    if type(items[0]) == dict:\n",
    "        path_rows = [\"_\".join(k.split(\"_\")[3:6]) for k in scene_dict]\n",
    "    else:\n",
    "        path_rows = [\"_\".join(k.split(\"_\")[3:5])[0:15] for k in scene_dict]\n",
    "    time_ind = 2\n",
    "scene_dict_pr = {}\n",
    "for pr in path_rows:\n",
    "    temp_dict = {}\n",
    "    required_keys = [k for k in scene_dict if pr in k]\n",
    "    for k in required_keys:\n",
    "        temp_dict[k] = scene_dict[k]\n",
    "    scene_dict_pr[pr] = temp_dict\n",
    "\n",
    "# scene_dict_pr_time = {}\n",
    "# for pr in scene_dict_pr:\n",
    "#     se = pd.Series(list(scene_dict_pr[pr].keys())).astype(\"str\")\n",
    "#     g = [s.split(\"_\")[time_ind][0:6] for s in list(scene_dict_pr[pr].keys())]\n",
    "#     if len(start_end_years) != 0:\n",
    "#         years = [\n",
    "#             int(s.split(\"_\")[time_ind][0:4]) for s in list(scene_dict_pr[pr].keys())\n",
    "#         ]\n",
    "#         year_range = range(start_end_years[0], start_end_years[1] + 1)\n",
    "#         valid_idx = list(\n",
    "#             filter(lambda i: years[i] in year_range, range(len(years)))\n",
    "#         )\n",
    "#         g = [g[i] for i in range(len(g)) if i in valid_idx]\n",
    "#         se = se.iloc[valid_idx]\n",
    "#     groups = list(se.groupby(g))\n",
    "#     temp_dict_time = {}\n",
    "#     for i, t in enumerate([el[0] for el in groups]):\n",
    "#         if type(t) == tuple:\n",
    "#             t = t[0]\n",
    "#         temp_list = []\n",
    "#         if one_per_month:\n",
    "#             temp_dict = scene_dict_pr[pr][groups[i][1].iloc[0]]\n",
    "#             temp_dict[\"scene_name\"] = groups[i][1].iloc[0]\n",
    "#             temp_list.append(temp_dict)\n",
    "#         else:\n",
    "#             for k in list(groups[i][1]):\n",
    "#                 temp_dict = scene_dict_pr[pr][k]\n",
    "#                 temp_dict[\"scene_name\"] = k\n",
    "#                 temp_list.append(temp_dict)\n",
    "#         if remove_duplicate_times:\n",
    "#             if duplicate_idx == 0:\n",
    "#                 times_idx = sorted(\n",
    "#                     np.unique(\n",
    "#                         [\n",
    "#                             re.findall(r\"\\d{8}\", d[\"scene_name\"])[0]\n",
    "#                             for d in temp_list\n",
    "#                         ],\n",
    "#                         return_index=True,\n",
    "#                     )[1].tolist()\n",
    "#                 )\n",
    "#             else:\n",
    "#                 times_list = [\n",
    "#                     re.findall(r\"\\d{8}\", d[\"scene_name\"])[0] for d in temp_list\n",
    "#                 ]\n",
    "#                 unique_times = np.unique(times_list)\n",
    "#                 unique_idx_list = [\n",
    "#                     [i for i in range(len(times_list)) if times_list[i] == ut]\n",
    "#                     for ut in unique_times\n",
    "#                 ]\n",
    "#                 times_idx = []\n",
    "#                 for i, idx in enumerate(unique_idx_list):\n",
    "#                     if len(idx) < duplicate_idx + 1:\n",
    "#                         temp_idx = len(idx) - 1\n",
    "#                     else:\n",
    "#                         temp_idx = duplicate_idx\n",
    "#                     times_idx.append(idx[temp_idx])\n",
    "#             temp_list = [temp_list[idx] for idx in times_idx]\n",
    "\n",
    "#         scene_list.extend(temp_list)\n",
    "#         temp_dict_time[t] = temp_list\n",
    "#     scene_dict_pr_time[pr] = temp_dict_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4605746",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = items[0].to_dict()\n",
    "id = feature[\"id\"]\n",
    "assets = feature[\"assets\"]\n",
    "scene_dict = {}\n",
    "scene_dict[id] = dict(scene_id=None)\n",
    "for s in [\"data\"]:\n",
    "    url = assets[s][\"href\"]\n",
    "    if \"alternate\" in assets[s]:\n",
    "        url_alternate = assets[s][\"alternate\"][\"s3\"][\"href\"]\n",
    "    else:\n",
    "        url_alternate = url\n",
    "\n",
    "    scene_dict[id][s] = url\n",
    "    scene_dict[id][f\"{s}_alternate\"] = url_alternate\n",
    "path_rows = [\"_\".join(k.split(\"_\")[0:1]) for k in scene_dict]\n",
    "\n",
    "scene_dict_pr = {}\n",
    "for pr in path_rows:\n",
    "    temp_dict = {}\n",
    "    required_keys = [k for k in scene_dict if pr in k]\n",
    "    for k in required_keys:\n",
    "        temp_dict[k] = scene_dict[k]\n",
    "    scene_dict_pr[pr] = temp_dict\n",
    "path_rows, scene_dict, scene_dict_pr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8400c4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [(i, len(scene_dict[path_row])) for i, path_row in enumerate(path_rows)]\n",
    "[path_rows[i] for i in [0, 6, 7]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16863e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tile_id = \"AMP\"\n",
    "condition = tile_id if tile_id != \"\" else \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9842a61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not items_exist:\n",
    "    scenes = pd.read_csv(f\"data/inputs/{MISSION}_{AOI}_scenes.csv\")\n",
    "    scene_list = scenes.to_dict(\"records\")\n",
    "    print(len(scene_list), \"scenes found in the CSV file.\")\n",
    "    scene_names = [\n",
    "        scene[\"scene_name\"] for scene in scene_list if condition in scene[\"scene_name\"]\n",
    "    ]\n",
    "    scene_ids = None\n",
    "    if MISSION != \"SENTINEL-2\":\n",
    "        scene_ids = [\n",
    "            scene[\"scene_id\"] for scene in scene_list if condition in scene[\"scene_id\"]\n",
    "        ]\n",
    "\n",
    "    gdf = gpd.GeoDataFrame.from_features(items, \"epsg:4326\")\n",
    "    id_col = \"earthsearch:s3_path\" if MISSION == \"SENTINEL-2\" else \"landsat:scene_id\"\n",
    "    item_names = list(gdf[id_col].apply(lambda x: x.split(\"/\")[-1]))\n",
    "    checklist = scene_names if MISSION == \"SENTINEL-2\" else scene_ids\n",
    "    idx = [item_names.index(i) for i in checklist]\n",
    "    gdf = gdf.iloc[idx].reset_index(drop=True)\n",
    "    print(len(gdf), \"items found in the GeoDataFrame.\")\n",
    "\n",
    "    # gdf.explore()\n",
    "    # print(len(scene_list), \"scenes found in the CSV file.\")\n",
    "    if MISSION == \"SENTINEL-2\":\n",
    "        idx = [i for i in range(len(items.items)) if items.items[i].id in scene_names]\n",
    "    else:\n",
    "        idx = [\n",
    "            i\n",
    "            for i in range(len(items.items))\n",
    "            if (\n",
    "                items.items[i].properties[\"landsat:scene_id\"] in scene_ids\n",
    "                and items.items[i].id in scene_names\n",
    "            )\n",
    "        ]\n",
    "    new_items = [items.items[i] for i in idx]\n",
    "    items.items = new_items\n",
    "    items.save_object(f\"{output_dir}/items{'_' + tile_id if tile_id else ''}.json\")\n",
    "else:\n",
    "    items = pystac.ItemCollection.from_file(items_file)\n",
    "    print(f\"Loaded {len(items.items)} items from {items_file}.\")\n",
    "items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cac11ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "if MISSION == \"SENTINEL-2\":\n",
    "    patch_url = None\n",
    "else:\n",
    "    patch_url = lambda x: x.replace(\n",
    "        \"https://landsatlook.usgs.gov/data/\", \"s3://usgs-landsat/\"\n",
    "    )\n",
    "\n",
    "ds = stac_load(\n",
    "    items,\n",
    "    bands=bands,\n",
    "    # crs=crs,\n",
    "    chunks={},\n",
    "    # groupby=\"solar_day\",\n",
    "    resolution=resolution,\n",
    "    patch_url=patch_url,\n",
    ")\n",
    "# ds[measurements] =  ds[measurements] - 1000\n",
    "# ds[measurements] = (ds[measurements] / 256).clip(0, 255).astype(\"uint8\")\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57927c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds.scl.attrs = {\n",
    "#     \"units\": \"1\",\n",
    "#     \"nodata\": 0,\n",
    "#     \"flags_definition\": {\n",
    "#         \"qa\": {\n",
    "#             \"bits\": [0, 1, 2, 3, 4, 5, 6, 7],\n",
    "#             \"values\": {\n",
    "#                 \"0\": \"no data\",\n",
    "#                 \"1\": \"saturated or defective\",\n",
    "#                 \"2\": \"dark area pixels\",\n",
    "#                 \"3\": \"cloud shadows\",\n",
    "#                 \"4\": \"vegetation\",\n",
    "#                 \"5\": \"bare soils\",\n",
    "#                 \"6\": \"water\",\n",
    "#                 \"7\": \"unclassified\",\n",
    "#                 \"8\": \"cloud medium probability\",\n",
    "#                 \"9\": \"cloud high probability\",\n",
    "#                 \"10\": \"thin cirrus\",\n",
    "#                 \"11\": \"snow or ice\",\n",
    "#             },\n",
    "#             \"description\": \"Sen2Cor Scene Classification\",\n",
    "#         }\n",
    "#     },\n",
    "#     # \"crs\": crs,\n",
    "#     \"grid_mapping\": \"spatial_ref\",\n",
    "# }\n",
    "# pq_mask = enum_to_bool(\n",
    "#     mask=ds[\"scl\"],\n",
    "#     categories=(\n",
    "#         \"cloud high probability\",\n",
    "#         \"cloud medium probability\",\n",
    "#         \"thin cirrus\",\n",
    "#         \"cloud shadows\",\n",
    "#         # \"saturated or defective\",\n",
    "#     ),\n",
    "# )\n",
    "# # apply morphological filters (might improve cloud mask)\n",
    "# pq_mask = mask_cleanup(pq_mask, mask_filters=mask_filters)\n",
    "\n",
    "# # apply the cloud mask and drop scl layers\n",
    "# ds = erase_bad(ds, where=pq_mask)\n",
    "# ds = ds.drop_vars(\"scl\")\n",
    "\n",
    "# # remove nodata which is == 0\n",
    "# ds = ds.where(ds > 0)\n",
    "\n",
    "# # and remove any data that's above 10,000 (very dodgy)\n",
    "# ds = ds.where(ds <= 10000)\n",
    "# ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26cf7b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "s2_gm = geomedian_with_mads(\n",
    "    ds,\n",
    "    reshape_strategy=\"yxbt\",  #'yxbt' if data is larger than RAM\n",
    "    compute_mads=False,  # True if you want triple MADs\n",
    ")\n",
    "# s2_gm = s2_gm.fillna(0)  # fill NaNs with 0s\n",
    "s2_gm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e7e8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "gmed_odc = s2_gm[measurements[:3]].to_array().to_numpy()\n",
    "gmed_odc = apply_gamma(\n",
    "    flip_img((gmed_odc / 256).clip(0, 255).astype(\"uint8\")),\n",
    "    stretch_hist=True if MISSION == \"SENTINEL-2\" else False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a2a5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds = ds.fillna(0)\n",
    "ds_loaded = ds[measurements[:3]].compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d689485",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_data = np.moveaxis(ds_loaded.to_array().to_numpy(), [0, 1], [-2, -1])\n",
    "img_data = np.where(np.isnan(img_data), 0, img_data)  # replace NaNs with 0s\n",
    "img_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231732e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "gmed_pcm = nangeomedian_pcm(img_data.astype(\"float32\"), num_threads=4, eps=1e-4)\n",
    "# gmed_pcm = (gmed_pcm / 256).clip(0, 255).astype(\"uint8\")\n",
    "gmed_pcm = apply_gamma(\n",
    "    (gmed_pcm / 256).clip(0, 255).astype(\"uint8\"),\n",
    "    stretch_hist=True if MISSION == \"SENTINEL-2\" else False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c975591",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = [img_data[:, :, :, i] for i in range(img_data.shape[-1])]\n",
    "print(len(imgs), \"images loaded for geometric median computation.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda621b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "gmed_gm = gm(imgs)\n",
    "# gmrd_gm = (gmed_gm.median / 256).clip(0, 255).astype(\"uint8\")\n",
    "gmed_gm = apply_gamma(\n",
    "    (gmed_gm.median / 256).clip(0, 255).astype(\"uint8\"),\n",
    "    stretch_hist=True if MISSION == \"SENTINEL-2\" else False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddedd115",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_loaded.to_array()[:, 0, :, :].rio.to_raster(f\"{output_dir}/temp.tif\")\n",
    "profile = rasterio.open(f\"{output_dir}/temp.tif\").profile\n",
    "os.remove(f\"{output_dir}/temp.tif\")\n",
    "profile.update({\"dtype\": \"uint8\", \"nodata\": 0, \"count\": 3})\n",
    "profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d25444e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "gmed_file_pcm = f\"data/inputs/{MISSION}_{AOI}/geometric_median{'_' + tile_id if tile_id else ''}_pcm_{output_suffix}.tif\"\n",
    "if os.path.exists(gmed_file_pcm):\n",
    "    os.remove(gmed_file_pcm)\n",
    "with rasterio.open(gmed_file_pcm, \"w\", **profile) as dst:\n",
    "    for i in range(profile[\"count\"]):\n",
    "        dst.write(gmed_pcm[:, :, i], i + 1)\n",
    "\n",
    "gmed_file_gm = f\"data/inputs/{MISSION}_{AOI}/geometric_median{'_' + tile_id if tile_id else ''}_gm_{output_suffix}.tif\"\n",
    "if os.path.exists(gmed_file_gm):\n",
    "    os.remove(gmed_file_gm)\n",
    "with rasterio.open(gmed_file_gm, \"w\", **profile) as dst:\n",
    "    for i in range(profile[\"count\"]):\n",
    "        dst.write(gmed_gm[:, :, i], i + 1)\n",
    "\n",
    "gmed_file_odc = f\"data/inputs/{MISSION}_{AOI}/geometric_median{'_' + tile_id if tile_id else ''}_odc_{output_suffix}.tif\"\n",
    "if os.path.exists(gmed_file_odc):\n",
    "    os.remove(gmed_file_odc)\n",
    "with rasterio.open(gmed_file_odc, \"w\", **profile) as dst:\n",
    "    for i in range(profile[\"count\"]):\n",
    "        dst.write(gmed_odc[:, :, i], i + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d1aefc",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(4, 2, figsize=(10, 20))\n",
    "axes[2, 0].imshow(\n",
    "    apply_gamma(\n",
    "        (imgs[0] / 256).clip(0, 255).astype(\"uint8\"),\n",
    "        stretch_hist=True if MISSION == \"SENTINEL-2\" else False,\n",
    "    )\n",
    ")\n",
    "axes[2, 0].set_title(\"Image 0\")\n",
    "axes[2, 1].imshow(\n",
    "    apply_gamma(\n",
    "        (imgs[1] / 256).clip(0, 255).astype(\"uint8\"),\n",
    "        stretch_hist=True if MISSION == \"SENTINEL-2\" else False,\n",
    "    )\n",
    ")\n",
    "axes[2, 1].set_title(\"Image 1\")\n",
    "axes[3, 0].imshow(\n",
    "    apply_gamma(\n",
    "        (imgs[2] / 256).clip(0, 255).astype(\"uint8\"),\n",
    "        stretch_hist=True if MISSION == \"SENTINEL-2\" else False,\n",
    "    )\n",
    ")\n",
    "axes[3, 0].set_title(\"Image 2\")\n",
    "axes[3, 1].imshow(\n",
    "    apply_gamma(\n",
    "        (imgs[3] / 256).clip(0, 255).astype(\"uint8\"),\n",
    "        stretch_hist=True if MISSION == \"SENTINEL-2\" else False,\n",
    "    )\n",
    ")\n",
    "axes[3, 1].set_title(\"Image 3\")\n",
    "axes[0, 0].imshow(flip_img(rasterio.open(gmed_file_pcm).read()))\n",
    "axes[0, 0].set_title(f\"Geometric Median of {len(imgs)} images (hdstats)\")\n",
    "axes[0, 1].imshow(flip_img(rasterio.open(gmed_file_gm).read()))\n",
    "axes[0, 1].set_title(f\"Geometric Median of {len(imgs)} images (geom_median)\")\n",
    "axes[1, 0].imshow(flip_img(rasterio.open(gmed_file_odc).read()))\n",
    "axes[1, 0].set_title(f\"Geometric Median of {len(imgs)} images (odc)\")\n",
    "for ax in axes.flat:\n",
    "    ax.axis(\"off\")\n",
    "plt.suptitle(\n",
    "    f\"Geometric Median of {len(imgs)} {MISSION} images from {AOI} AOI, {'ID: ' + tile_id if tile_id else ''}, ({output_suffix.replace('_', ' ')})\",\n",
    "    fontsize=14,\n",
    "    y=1.01,\n",
    ")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\n",
    "    f\"{output_dir}/geometric_median_{MISSION}_{AOI}{'_' + tile_id if tile_id else ''}_{output_suffix}.png\",\n",
    "    dpi=300,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09339606",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
