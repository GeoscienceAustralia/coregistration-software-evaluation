{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042e4ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from utils import *\n",
    "import dask\n",
    "import dask.distributed\n",
    "import geopandas as gpd\n",
    "from odc.algo import geomedian_with_mads\n",
    "from odc.geo import BoundingBox\n",
    "from odc.stac import configure_rio, stac_load\n",
    "from functools import reduce\n",
    "\n",
    "dask_n_workers = os.cpu_count() - 2\n",
    "threads_per_worker = 1 # os.cpu_count()\n",
    "gmed_n_workers = 1  # os.cpu_count() - 2\n",
    "\n",
    "shutil.rmtree(\"temp_dask_dir\", ignore_errors=True)\n",
    "os.makedirs(\"temp_dask_dir\", exist_ok=True)\n",
    "\n",
    "# Increase connection and TCP timeouts\n",
    "dask.config.set({\"distributed.comm.timeouts.connect\": \"60s\"})\n",
    "dask.config.set({\"distributed.comm.timeouts.tcp\": \"300s\"})\n",
    "\n",
    "# Increase nanny timeouts (for worker management)\n",
    "dask.config.set({\"distributed.nanny.timeouts.startup\": \"300s\"})\n",
    "dask.config.set({\"distributed.nanny.timeouts.connect\": \"300s\"})\n",
    "dask.config.set({\"distributed.nanny.timeouts.terminate\": \"300s\"})\n",
    "\n",
    "client = dask.distributed.Client(\n",
    "    n_workers=dask_n_workers,\n",
    "    threads_per_worker=threads_per_worker,\n",
    "    local_directory=\"temp_dask_dir\",\n",
    ")\n",
    "\n",
    "display(client)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad42b75c",
   "metadata": {},
   "source": [
    "Specifying Mission and configuring AWS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c02548ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "MISSION = \"SENTINEL-1\"  # \"LANDSAT-8\" or \"SENTINEL-2\"\n",
    "\n",
    "if MISSION in [\"LANDSAT-8\", \"LANDSAT-9\", \"LANDSAT-4-5\"]:\n",
    "    aws_session = rasterio.session.AWSSession(boto3.Session(), requester_pays=True)\n",
    "    configure_rio(cloud_defaults=True, aws={\"requester_pays\": True}, client=client)\n",
    "else:\n",
    "    aws_session = rasterio.session.AWSSession(boto3.Session())\n",
    "    configure_rio(cloud_defaults=True, aws={\"aws_unsigned\": True}, client=client)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38d71cf5",
   "metadata": {},
   "source": [
    "AOI list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb44a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "wa_bbox = resize_bbox(BoundingBox(*kml_to_poly(\"data/inputs_old/WA.kml\").bounds), 0.1)\n",
    "tas_bbox = resize_bbox(BoundingBox(*kml_to_poly(\"data/inputs_old/TAS.kml\").bounds), 0.1)\n",
    "mount_box = resize_bbox(\n",
    "    BoundingBox(*kml_to_poly(\"data/inputs_old/geo1.kml\").bounds), 0.1\n",
    ")\n",
    "amery_rock = [67.45, -72.55, 67.55, -72.45]\n",
    "amery_shelf = [73.47, -69.66, 74.71, -69.22]\n",
    "hillary_coast = BoundingBox(*kml_to_poly(\"data/inputs_old/hillary.kml\").bounds)\n",
    "flincher_shelf = [-41, -81, -39, -79]\n",
    "inland_ice = [126.0, -90, 136, -80]\n",
    "an_shelf = [66, -71, 75, -68]\n",
    "redlands = BoundingBox(*kml_to_poly(\"data/inputs_old/Redlands.kml\").bounds)\n",
    "\n",
    "bbox_list = [\n",
    "    wa_bbox,\n",
    "    amery_rock,\n",
    "    mount_box,\n",
    "    tas_bbox,\n",
    "    amery_shelf,\n",
    "    hillary_coast,\n",
    "    flincher_shelf,\n",
    "    inland_ice,\n",
    "    an_shelf,\n",
    "    redlands,\n",
    "]\n",
    "\n",
    "aoi_dict = {\n",
    "    str(wa_bbox): \"WA\",\n",
    "    str(tas_bbox): \"TAS\",\n",
    "    str(mount_box): \"MOUNT\",\n",
    "    str(amery_rock): \"AMERY_ROCK\",\n",
    "    str(amery_shelf): \"AMERY_SHELF\",\n",
    "    str(hillary_coast): \"HILLARY_COAST\",\n",
    "    str(flincher_shelf): \"FLINCHER_SHELF\",\n",
    "    str(inland_ice): \"INLAND_ICE\",\n",
    "    str(an_shelf): \"ANTARCTIC_SHELF\",\n",
    "    str(redlands): \"REDLANDS\",\n",
    "}\n",
    "\n",
    "# Flincher and Amery shelves are high velocity ice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e7a715",
   "metadata": {},
   "source": [
    "Runtime params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a24f9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_factor = 10.0\n",
    "max_cloud_cover = 5\n",
    "min_scenes_per_id = 10 if MISSION != \"SENTINEL-1\" else 1\n",
    "\n",
    "aoi_index = 8\n",
    "bbox = bbox_list[aoi_index]\n",
    "AOI = aoi_dict[str(bbox)]\n",
    "masking_band = [\"scl\"]\n",
    "if MISSION == \"SENTINEL-1\":\n",
    "    if AOI in [\"TAS\", \"REDLANDS\"]:\n",
    "        bands = [\"VH\", \"VV\"]\n",
    "    else:\n",
    "        bands = [\"HH\"]\n",
    "else:\n",
    "    bands = [\"red\", \"green\", \"blue\"]\n",
    "mask_filters = [(\"opening\", 10), (\"dilation\", 1)]\n",
    "# crs = \"EPSG:3031\"\n",
    "resolution = 100 if MISSION in [\"SENTINEL-1\", \"SENTINEL-2\"] else 200\n",
    "output_suffix = \"manual_loader\"\n",
    "file_name_suffix = \"odc_stac\"  # odc\n",
    "aoi_suffix = \"_LARGE\"  # \"\", \"LARGE\", \"all\", \"LARGE_all\"\n",
    "\n",
    "AOI = AOI + aoi_suffix if aoi_suffix else AOI\n",
    "use_all_items = False\n",
    "\n",
    "if \"_LARGE\" in aoi_suffix:\n",
    "    if AOI.replace(aoi_suffix, \"\") in [\"AMERY_ROCK\", \"AMERY_SHELF\", \"ANTARCTIC_SHELF\"]:\n",
    "        bbox = resize_bbox(BoundingBox(*bbox), scale_factor)\n",
    "    elif AOI.replace(aoi_suffix, \"\") in [\"INLAND_ICE\", \"FLINCHER_SHELF\"]:\n",
    "        pass\n",
    "    else:\n",
    "        bbox = resize_bbox(bbox, scale_factor)\n",
    "\n",
    "if \"all\" in aoi_suffix.lower():\n",
    "    min_scenes_per_id = 1\n",
    "    print(\"Using all scenes for AOI:\", AOI, \" with min_scenes_per_id =\", min_scenes_per_id)\n",
    "\n",
    "print(MISSION, AOI, bbox, bands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dbcccdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_bands = (\n",
    "    masking_band if MISSION == \"SENTINEL-2\" else None\n",
    ")  # Only for Sentinel-2, Landsat-8 does not have SCL band\n",
    "output_dir = f\"data/inputs/{MISSION}_{AOI}\"\n",
    "process_dir = f\"{output_dir}/true_colour\"\n",
    "process_ds_dir = f\"{output_dir}/true_colour_ds\"\n",
    "ds_dir = f\"{output_dir}/downsampled\"\n",
    "items_file = f\"{output_dir}/items.json\"\n",
    "items_exist = os.path.exists(items_file)\n",
    "print(items_file)\n",
    "items_exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "706573f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_all_items and not items_exist:\n",
    "    items_files = glob.glob(f\"{output_dir}/items*.json\")\n",
    "    items_files = [f for f in items_files if f\"{output_dir}/items.json\" not in f]\n",
    "    if len(items_files) > 0:\n",
    "        items_list = [pystac.ItemCollection.from_file(f) for f in items_files]\n",
    "        items = reduce(lambda x, y: x + y, items_list)\n",
    "        items_exist = True\n",
    "        items.save_object(f\"{output_dir}/items.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6362e994",
   "metadata": {},
   "source": [
    "Querying and processing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6566af8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not items_exist:\n",
    "    if MISSION == \"SENTINEL-2\":\n",
    "        query = get_search_query(\n",
    "            bbox,\n",
    "            collections=[\"sentinel-2-l2a\"],\n",
    "            start_date=\"2016-01-01T00:00:00\",\n",
    "            end_date=\"2021-01-01T00:00:00\",\n",
    "            pystac_query=True,\n",
    "        )\n",
    "        use_pystac = True\n",
    "        server_url = \"https://earth-search.aws.element84.com/v1\"\n",
    "    elif MISSION == \"SENTINEL-1\":\n",
    "        query = get_search_query(\n",
    "            bbox,\n",
    "            collections=[\"ga_s1_iw_vv_vh_c0\", \"ga_s1_iw_hh_c0\", \"ga_s1_nrb_iw_vv_vh_0\"],\n",
    "            start_date=\"2016-01-01T00:00:00\",\n",
    "            end_date=\"2021-01-01T00:00:00\",\n",
    "            pystac_query=True,\n",
    "        )\n",
    "        use_pystac = True\n",
    "        server_url = \"https://explorer.dev.dea.ga.gov.au/stac\"\n",
    "    elif MISSION == \"LANDSAT-8\":\n",
    "        query = get_search_query(\n",
    "            bbox,\n",
    "            start_date=\"2013-01-01T00:00:00\",\n",
    "            end_date=\"2017-01-01T00:00:00\",\n",
    "            platform=[\"LANDSAT_8\"],\n",
    "            collection_category=None,\n",
    "            collections=None,\n",
    "            cloud_cover=max_cloud_cover,\n",
    "        )\n",
    "        use_pystac = False\n",
    "        server_url = \"https://landsatlook.usgs.gov/stac-server/search\"\n",
    "    elif MISSION == \"LANDSAT-4-5\":\n",
    "        query = get_search_query(\n",
    "            bbox,\n",
    "            start_date=\"1985-01-01T00:00:00\",\n",
    "            end_date=\"2010-12-30T00:00:00\",\n",
    "            platform=[\"LANDSAT_4\", \"LANDSAT_5\"],\n",
    "            collection_category=None,\n",
    "            collections=None,\n",
    "            cloud_cover=max_cloud_cover,\n",
    "        )\n",
    "        use_pystac = False\n",
    "        server_url = \"https://landsatlook.usgs.gov/stac-server/search\"\n",
    "\n",
    "    display(query)\n",
    "    items = query_stac_server(\n",
    "        query,\n",
    "        server_url,\n",
    "        use_pystac=use_pystac,\n",
    "        max_cloud_cover=max_cloud_cover if MISSION != \"SENTINEL-1\" else None,\n",
    "    )\n",
    "    print(f\"Found {len(items)} items.\")\n",
    "\n",
    "    if len(items) > 0:\n",
    "        scene_dict, scene_list = find_scenes_dict(\n",
    "            items.copy(),\n",
    "            one_per_month=False if MISSION == \"LANDSAT-4-5\" else True,\n",
    "            acceptance_list=bands + [\"thumbnail\"],\n",
    "            remove_duplicate_times=False if MISSION == \"LANDSAT-4-5\" else True,\n",
    "            duplicate_idx=1,\n",
    "            min_scenes_per_id=min_scenes_per_id,\n",
    "            id_filter=\"L1GT\" if MISSION in [\"LANDSAT-8\", \"LANDSAT-9\"] else None,\n",
    "        )\n",
    "        pd.DataFrame(scene_list).to_csv(\n",
    "            f\"data/inputs/{MISSION}_{AOI}_scenes.csv\", index=False\n",
    "        )\n",
    "        path_rows = list(scene_dict.keys())\n",
    "        print(\"Found IDs: \", path_rows)\n",
    "\n",
    "        path_row_list = [\n",
    "            (i, path_row, len(scene_dict[path_row]))\n",
    "            for i, path_row in enumerate(path_rows)\n",
    "        ]\n",
    "        pd.DataFrame(path_row_list, columns=[\"index\", \"path_row\", \"count\"]).to_csv(\n",
    "            f\"data/inputs/{MISSION}_{AOI}_scene_counts.csv\", index=False\n",
    "        )\n",
    "        print(\"Found scene counts: \", path_row_list)\n",
    "        print(\"Found scenes counts after filtering: \", len(scene_list))\n",
    "\n",
    "        items = pystac.ItemCollection(items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c67251d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_row_list = pd.read_csv(f\"data/inputs/{MISSION}_{AOI}_scene_counts.csv\")\n",
    "print(\"Found scene counts: \\n\", path_row_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f304328",
   "metadata": {},
   "outputs": [],
   "source": [
    "tile_id = \"\"\n",
    "items_file = f\"{output_dir}/items.json\"\n",
    "full_items_file = items_file\n",
    "items_file = f\"{output_dir}/items{'_' + tile_id if tile_id else ''}.json\"\n",
    "items_exist = os.path.exists(items_file)\n",
    "\n",
    "if use_all_items:\n",
    "    tile_id = \"\"\n",
    "    items_file = full_items_file\n",
    "condition = tile_id if tile_id != \"\" else \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9842a61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not items_exist:\n",
    "    if use_all_items or tile_id != \"\":\n",
    "        items = pystac.ItemCollection.from_file(full_items_file)\n",
    "    scenes = pd.read_csv(f\"data/inputs/{MISSION}_{AOI}_scenes.csv\")\n",
    "    scene_list = scenes.to_dict(\"records\")\n",
    "    bands_suffixes = get_band_suffixes(scene_list[0], bands)\n",
    "    print(len(scene_list), \"scenes found in the CSV file.\")\n",
    "    scene_names = [\n",
    "        scene[\"scene_name\"] for scene in scene_list if condition in scene[\"scene_name\"]\n",
    "    ]\n",
    "    scene_ids = None\n",
    "    if MISSION not in [\"SENTINEL-1\", \"SENTINEL-2\"]:\n",
    "        scene_ids = [\n",
    "            scene[\"scene_id\"] for scene in scene_list if condition in scene[\"scene_id\"]\n",
    "        ]\n",
    "\n",
    "    gdf = gpd.GeoDataFrame.from_features(items, \"epsg:4326\")\n",
    "    if MISSION == \"SENTINEL-2\":\n",
    "        id_col = \"earthsearch:s3_path\"\n",
    "    elif MISSION == \"SENTINEL-1\":\n",
    "        id_col = \"title\"\n",
    "    elif MISSION == \"LANDSAT-8\":\n",
    "        id_col = \"landsat:scene_id\"\n",
    "    else:\n",
    "        id_col = \"landsat:scene_id\"\n",
    "    item_names = list(gdf[id_col].apply(lambda x: x.split(\"/\")[-1]))\n",
    "    checklist = scene_names if MISSION in [\"SENTINEL-1\", \"SENTINEL-2\"] else scene_ids\n",
    "    idx = [item_names.index(i) for i in checklist]\n",
    "    gdf = gdf.iloc[idx].reset_index(drop=True)\n",
    "    print(len(gdf), \"items found in the GeoDataFrame.\")\n",
    "\n",
    "    # gdf.explore()\n",
    "    # print(len(scene_list), \"scenes found in the CSV file.\")\n",
    "    if MISSION == \"SENTINEL-2\":\n",
    "        idx = [i for i in range(len(items.items)) if items.items[i].id in scene_names]\n",
    "        scene_list = [\n",
    "            scene for scene in scene_list if scene[\"scene_name\"] in scene_names\n",
    "        ]\n",
    "    elif MISSION == \"SENTINEL-1\":\n",
    "        idx = [\n",
    "            i\n",
    "            for i in range(len(items.items))\n",
    "            if items.items[i].properties[\"title\"] in scene_names\n",
    "        ]\n",
    "        scene_list = [\n",
    "            scene for scene in scene_list if scene[\"scene_name\"] in scene_names\n",
    "        ]\n",
    "    else:\n",
    "        idx = [\n",
    "            i\n",
    "            for i in range(len(items.items))\n",
    "            if (\n",
    "                items.items[i].properties[\"landsat:scene_id\"] in scene_ids\n",
    "                and items.items[i].id in scene_names\n",
    "            )\n",
    "        ]\n",
    "        scene_list = [\n",
    "            scene\n",
    "            for scene in scene_list\n",
    "            if (scene[\"scene_name\"] in scene_names and scene[\"scene_id\"] in scene_ids)\n",
    "        ]\n",
    "    new_items = [items.items[i] for i in idx]\n",
    "    items.items = new_items\n",
    "    items.save_object(f\"{output_dir}/items{'_' + tile_id if tile_id else ''}.json\")\n",
    "else:\n",
    "    items = pystac.ItemCollection.from_file(items_file)\n",
    "    scene_list = []\n",
    "    features = items.to_dict()[\"features\"]\n",
    "    for feature in features:\n",
    "        s = {}\n",
    "        for b in bands:\n",
    "            if b in feature[\"assets\"]:\n",
    "                s[b] = feature[\"assets\"][b][\"href\"]\n",
    "                s[b + \"_alternate\"] = (\n",
    "                    s[b]\n",
    "                    if MISSION in [\"SENTINEL-1\", \"SENTINEL-2\"]\n",
    "                    else feature[\"assets\"][b][\"alternate\"][\"s3\"][\"href\"]\n",
    "                )\n",
    "        s[\"scene_name\"] = (\n",
    "            feature[\"properties\"][\"title\"] if MISSION == \"SENTINEL-1\" else feature[\"id\"]\n",
    "        )\n",
    "        scene_list.append(s)\n",
    "    bands_suffixes = get_band_suffixes(scene_list[0], bands)\n",
    "    print(f\"Loaded {len(items.items)} items from {items_file}.\")\n",
    "# items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42144b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_dir = process_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae9afbf",
   "metadata": {},
   "source": [
    "Dwonlading metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1efa30b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, meta = stream_scene_from_aws(\n",
    "    (\n",
    "        items[0].assets[bands[0]].href\n",
    "        if MISSION in [\"SENTINEL-1\", \"SENTINEL-2\"]\n",
    "        else items[0].assets[bands[0]].to_dict()[\"alternate\"][\"s3\"][\"href\"]\n",
    "    ),\n",
    "    aws_session,\n",
    "    metadata_only=True,\n",
    ")\n",
    "resolution_ratio = [\n",
    "    meta[\"profile\"][\"transform\"].a / resolution,\n",
    "    -meta[\"profile\"][\"transform\"].e / resolution,\n",
    "]\n",
    "print(f\"Resolution ratio: {resolution_ratio}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89add72a",
   "metadata": {},
   "source": [
    "Dwonlading original files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4323fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "scene_name_map = lambda x: (\n",
    "    x.replace(\"_SR\", \"\") if MISSION not in [\"SENTINEL-1\", \"SENTINEL-2\"] else x\n",
    ")\n",
    "download_and_process_series(\n",
    "    scene_list,\n",
    "    bands,\n",
    "    bands_suffixes,\n",
    "    output_dir,\n",
    "    process_dir,\n",
    "    process_ds_dir,\n",
    "    aws_session=aws_session,\n",
    "    keep_original_band_scenes=True,\n",
    "    scene_name_map=scene_name_map,\n",
    "    extra_bands=None,  # , extra_bands,\n",
    "    download_only=True,\n",
    "    stream_out_scale_factor=resolution_ratio # if MISSION != \"SENTINEL-1\" else None,\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae67bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "scene_files = [os.path.basename(scene[\"local_path\"]) for scene in scene_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c04d56",
   "metadata": {},
   "source": [
    "Processing original files and making true colour composites for manual loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46be2e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ext = \"tif\" if MISSION in [\"SENTINEL-1\", \"SENTINEL-2\"] else \"TIF\"\n",
    "orig_dir = f\"{output_dir}/Originals\"\n",
    "dir_list = [glob.glob(f\"{dir}/**\") for dir in glob.glob(f\"{orig_dir}/**\")]\n",
    "dir_list = [\n",
    "    [\n",
    "        list(filter(lambda x: x.endswith(f\"{idx}.{ext}\"), dir_name))[0]\n",
    "        for idx in bands_suffixes\n",
    "    ]\n",
    "    for dir_name in dir_list\n",
    "]\n",
    "process_existing_outputs(\n",
    "    dir_list,\n",
    "    output_dir,\n",
    "    scale_factor=1.0,  # resolution_ratio,\n",
    "    preserve_depth=True,  # True if you want to preserve the depth of the original dataset\n",
    "    min_max_scaling=False,  # True if you want to apply min-max scaling\n",
    "    stretch_contrast=True if MISSION == \"SENTINEL-1\" else False,\n",
    "    gamma=0.5 if MISSION == \"SENTINEL-1\" else 1.0,\n",
    "    three_channel=True if MISSION == \"SENTINEL-1\" else False,\n",
    "    remove_nans=True if MISSION == \"SENTINEL-1\" else False,\n",
    "    num_cpu=-1,\n",
    "    write_pairs=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a6501b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ext = \"tif\" if MISSION in [\"SENTINEL-1\", \"SENTINEL-2\"] else \"TIF\"\n",
    "originals = glob.glob(f\"{output_dir}/Originals/**/*.{ext}\", recursive=True)\n",
    "originals = [f for f in originals if condition in f]\n",
    "print(len(originals), \"original scenes found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60888a1a",
   "metadata": {},
   "source": [
    "Output files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2bfd462",
   "metadata": {},
   "outputs": [],
   "source": [
    "gmed_file_odc_stac = f\"data/inputs/{MISSION}_{AOI}/geometric_median{'_' + tile_id if tile_id else ''}_odc_stac_{output_suffix}{'_full' if use_all_items else ''}.tif\"\n",
    "gmed_file_odc = f\"data/inputs/{MISSION}_{AOI}/geometric_median{'_' + tile_id if tile_id else ''}_odc_{output_suffix}{'_full' if use_all_items else ''}.tif\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6afa2d6",
   "metadata": {},
   "source": [
    "Loading data via odc-stac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319287eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_dir = f\"{output_dir}/Originals\"\n",
    "print(f\"Originals directory: {orig_dir}\")\n",
    "\n",
    "if MISSION == \"SENTINEL-1\":\n",
    "    patch_url = lambda x: os.path.join(\n",
    "        *[orig_dir, x.split(\"/\")[-1].rsplit(\"_\", maxsplit=1)[0], x.split(\"/\")[-1]]\n",
    "    )\n",
    "else:\n",
    "    patch_url = lambda x: os.path.join(*([orig_dir] + x.split(\"/\")[-2:]))\n",
    "\n",
    "ds_stac = stac_load(\n",
    "    items,\n",
    "    bands=bands,\n",
    "    chunks={\"x\": 500, \"y\": 500},\n",
    "    groupby=\"id\",\n",
    "    resolution=resolution,\n",
    "    patch_url=patch_url,\n",
    "    preserve_original_order=True,\n",
    "    crs=meta[\"crs\"],\n",
    "    # bbox=bbox,\n",
    ")\n",
    "ds_stac = ds_stac.where(ds_stac > 0)\n",
    "ds_stac"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ae3785",
   "metadata": {},
   "source": [
    "Geomedian via odc-stac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ee642a",
   "metadata": {},
   "outputs": [],
   "source": [
    "gmed_odc_stac = geomedian_with_mads(\n",
    "    ds_stac,\n",
    "    reshape_strategy=\"yxbt\",  #'yxbt' if data is larger than RAM\n",
    "    compute_mads=False,  # True if you want triple MADs\n",
    "    num_threads=gmed_n_workers,\n",
    ")\n",
    "gmed_odc_stac = gmed_odc_stac.rio.write_crs(f\"epsg:{ds_stac.rio.crs.to_epsg()}\")\n",
    "\n",
    "if os.path.exists(gmed_file_odc_stac):\n",
    "    os.remove(gmed_file_odc_stac)\n",
    "\n",
    "if MISSION == \"SENTINEL-1\":\n",
    "    gmed_odc_stac_img = gmed_odc_stac[bands[:3]].to_array().to_numpy()\n",
    "    gmed_odc_stac_img = np.nan_to_num(gmed_odc_stac_img, nan=0)\n",
    "    gmed_odc_stac_img = apply_gamma(gmed_odc_stac_img, stretch_hist=True).astype(\n",
    "        \"uint8\"\n",
    "    )\n",
    "\n",
    "    profile = rasterio.open(\n",
    "        [\n",
    "            f\n",
    "            for f in glob.glob(images_dir + f\"/*.{ext}\")\n",
    "            if os.path.basename(f) in scene_files\n",
    "        ][0]\n",
    "    ).profile\n",
    "    profile[\"count\"] = len(bands)\n",
    "\n",
    "    with rasterio.open(gmed_file_odc_stac, \"w\", **profile) as dst:\n",
    "        for i in range(profile[\"count\"]):\n",
    "            dst.write(gmed_odc_stac_img[i, :, :], i + 1)\n",
    "else:\n",
    "    (gmed_odc_stac[bands[:3]] / 255).clip(0, 255).astype(\"uint8\").rio.to_raster(\n",
    "        gmed_file_odc_stac\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90cbcce1",
   "metadata": {},
   "source": [
    "Geo-referrencing input data for manual loading. Also optionally applying masking filters for removing shadow effects around edges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b0b651",
   "metadata": {},
   "outputs": [],
   "source": [
    "ext = \"tif\" if MISSION in [\"SENTINEL-1\", \"SENTINEL-2\"] else \"TIF\"\n",
    "img_shapes = [\n",
    "    (rasterio.open(f).count, rasterio.open(f).height, rasterio.open(f).width)\n",
    "    for f in glob.glob(images_dir + f\"/*.{ext}\")\n",
    "    if os.path.basename(f) in scene_files\n",
    "]\n",
    "print(len(img_shapes), \"images found in the downsampled directory.\")\n",
    "\n",
    "transforms = [\n",
    "    rasterio.open(f).transform\n",
    "    for f in glob.glob(images_dir + f\"/*.{ext}\")\n",
    "    if os.path.basename(f) in scene_files\n",
    "]\n",
    "\n",
    "shape_diffs = np.abs(np.diff(img_shapes, axis=0))\n",
    "transform_diffs = np.abs(np.diff(transforms, axis=0))\n",
    "\n",
    "shape_condition = np.any(shape_diffs != np.array([0, 0, 0]))\n",
    "origin_condition = np.any(transform_diffs != np.zeros(9))\n",
    "shape_condition, origin_condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ba8551",
   "metadata": {},
   "outputs": [],
   "source": [
    "universal_masking = False\n",
    "cluster_masks = False  \n",
    "force_warping = True\n",
    "\n",
    "print(force_warping, shape_condition or origin_condition or force_warping)\n",
    "\n",
    "images_dir = process_dir\n",
    "if force_warping or shape_condition or origin_condition or MISSION == \"SENTINEL-2\":\n",
    "    print(\"Images have different shapes, warping them to the same shape.\")\n",
    "    warps_dir = f\"{output_dir}/warped/\"\n",
    "    if force_warping:\n",
    "        shutil.rmtree(warps_dir, ignore_errors=True)\n",
    "    os.makedirs(warps_dir, exist_ok=True)\n",
    "    imgs_list = [\n",
    "        f\n",
    "        for f in glob.glob(images_dir + f\"/*.{ext}\")\n",
    "        if os.path.basename(f) in scene_files\n",
    "    ]\n",
    "    mosaic, warps, profiles = make_mosaic(\n",
    "        imgs_list,\n",
    "        return_warps=True,\n",
    "        return_profile_only=True,\n",
    "        output_type=\"uint16\",\n",
    "        universal_masking=universal_masking,\n",
    "        cluster_masks=cluster_masks,\n",
    "        nodata=0,\n",
    "    )\n",
    "    if universal_masking:\n",
    "        # masks = warps[1]\n",
    "        warps = warps[0]\n",
    "    warp_profile = profiles[1]\n",
    "    warp_profile.update(\n",
    "        blockxsize=warp_profile[\"width\"], blockysize=1, tiled=False, interleave=\"pixel\"\n",
    "    )\n",
    "    for i, warp in enumerate(warps):\n",
    "        warp_path = os.path.join(warps_dir, os.path.basename(imgs_list[i]))\n",
    "        if not os.path.exists(warp_path):\n",
    "            with rasterio.open(warp_path, \"w\", **warp_profile) as warp_ds:\n",
    "                for i in range(3):\n",
    "                    warp_ds.write(warp[:, :, i], i + 1)\n",
    "    images_dir = warps_dir\n",
    "    # warps = [np.moveaxis(warp, -1, 0) for warp in warps]\n",
    "\n",
    "plt.imshow(mosaic / mosaic.max())\n",
    "mosaic = None\n",
    "warps = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a6b710",
   "metadata": {},
   "source": [
    "Manual loading of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd23a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_dir = f\"{output_dir}/warped/\"\n",
    "print(images_dir)\n",
    "ext = \"tif\" if MISSION in [\"SENTINEL-1\", \"SENTINEL-2\"] else \"TIF\"\n",
    "if MISSION == \"SENTINEL-1\":\n",
    "    time_idx = 4\n",
    "elif MISSION == \"SENTINEL-2\":\n",
    "    time_idx = 2\n",
    "else:\n",
    "    time_idx = 3\n",
    "times = [\n",
    "    datetime.strptime(os.path.basename(f).split(\"_\")[time_idx][0:8], \"%Y%m%d\")\n",
    "    for f in glob.glob(images_dir + f\"/*.{ext}\")\n",
    "    if os.path.basename(f) in scene_files\n",
    "]\n",
    "files = [f\"{os.path.join(images_dir, item.id)}_PROC.{ext}\" for item in items]\n",
    "files = [f for f in files if os.path.basename(f) in scene_files]\n",
    "assert all([os.path.exists(f) for f in files]), \"Not all files exist!\"\n",
    "\n",
    "crs = meta[\n",
    "    \"crs\"\n",
    "].to_epsg()  # int(crs.split(\":\")[1])  # Extract EPSG code from CRS string\n",
    "ds = create_dataset_from_files(\n",
    "    files,\n",
    "    times,\n",
    "    crs,\n",
    "    bands,\n",
    "    chunks={},  # {\"x\": 500, \"y\": 500},\n",
    "    bbox=bbox,\n",
    "    bbox_crs=4326,\n",
    ")\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1bc6d2c",
   "metadata": {},
   "source": [
    "Geomedian for manually loaded data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b012784f",
   "metadata": {},
   "outputs": [],
   "source": [
    "gmed_odc = geomedian_with_mads(\n",
    "    ds,\n",
    "    reshape_strategy=\"yxbt\",  #'yxbt' if data is larger than RAM\n",
    "    compute_mads=False,  # True if you want triple MADs\n",
    "    num_threads=gmed_n_workers,\n",
    ")\n",
    "gmed_odc = gmed_odc.rio.write_crs(f\"epsg:{crs}\")\n",
    "gmed_odc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0588ce49",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(gmed_file_odc):\n",
    "    os.remove(gmed_file_odc)\n",
    "if MISSION == \"SENTINEL-1\":\n",
    "    gmed_odc[bands[:3]].astype(\"uint8\").rio.to_raster(gmed_file_odc)\n",
    "else:\n",
    "    (gmed_odc[bands[:3]] / 255).clip(0, 255).astype(\"uint8\").rio.to_raster(\n",
    "        gmed_file_odc\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "681ddd9c",
   "metadata": {},
   "source": [
    "Plotting results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a4942b",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name_suffix = \"odc_stac\"  # odc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "068bc10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "enhance = True\n",
    "# gm_outputs = [gmed_file_pcm, gmed_file_gm, gmed_file_odc, gmed_file_odc_stac]\n",
    "\n",
    "gm_outputs = [gmed_file_odc] if file_name_suffix == \"odc\" else [gmed_file_odc_stac]\n",
    "\n",
    "images_dir = process_dir\n",
    "imgs_files = [\n",
    "    f for f in glob.glob(images_dir + f\"/*.{ext}\") if os.path.basename(f) in scene_files\n",
    "][:4]\n",
    "\n",
    "imgs = [rasterio.open(f).read() for f in imgs_files]\n",
    "\n",
    "img_samples = imgs\n",
    "to_plot = []\n",
    "if MISSION == \"SENTINEL-1\":\n",
    "    for img in img_samples:\n",
    "        img[2, :, :] = (\n",
    "            0  # ((img[1, :, :] + img[0, :, :]) / 2).astype(\"uint8\")  # Create a 3-channel image\n",
    "        )\n",
    "        img = flip_img(img).astype(\"uint8\")\n",
    "        to_plot.append(img)\n",
    "else:\n",
    "    for img in img_samples:\n",
    "        img = np.clip(flip_img(img) / 255, 0, 255).astype(\"uint8\")\n",
    "        to_plot.append(img)\n",
    "\n",
    "gm_imgs = [flip_img(rasterio.open(f).read()).astype(\"uint8\") for f in gm_outputs]\n",
    "\n",
    "for img in gm_imgs:\n",
    "    out_img = np.zeros((img.shape[0], img.shape[1], 3), dtype=\"uint8\")\n",
    "    for i in range(img.shape[2]):\n",
    "        out_img[:, :, i] = img[:, :, i]\n",
    "    to_plot.append(out_img)\n",
    "\n",
    "if enhance:\n",
    "    # to_plot = [apply_gamma(img, stretch_hist=True) for img in to_plot]\n",
    "    to_plot = [img / img.max() for img in to_plot]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5010ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.gridspec import GridSpec\n",
    "\n",
    "fig = plt.figure(figsize=(10, 20), dpi=300, constrained_layout=True)\n",
    "gs = GridSpec(4, 2, figure=fig)\n",
    "ax0 = fig.add_subplot(gs[0:2, 0:2])\n",
    "ax1 = fig.add_subplot(gs[2, 0])\n",
    "ax2 = fig.add_subplot(gs[2, 1])\n",
    "ax3 = fig.add_subplot(gs[3, 0])\n",
    "ax4 = fig.add_subplot(gs[3, 1])\n",
    "ax1.imshow((to_plot[0]))\n",
    "ax1.set_title(\"Image 0\")\n",
    "ax2.imshow(to_plot[1])\n",
    "ax2.set_title(\"Image 1\")\n",
    "ax3.imshow(to_plot[2])\n",
    "ax3.set_title(\"Image 2\")\n",
    "ax4.imshow(to_plot[3])\n",
    "ax4.set_title(\"Image 3\")\n",
    "ax0.imshow(to_plot[4])\n",
    "ax0.set_title(\n",
    "    f\"Geometric Median of {len(scene_files)} {MISSION} images from {AOI} AOI, {'ID: ' + tile_id if tile_id else ''}, ({output_suffix.replace('_', ' ')}) ({file_name_suffix.replace('_', ' ')})\"\n",
    ")\n",
    "for ax in [ax0, ax1, ax2, ax3, ax4]:\n",
    "    ax.axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\n",
    "    f\"{output_dir}/geometric_median_{MISSION}_{AOI}{'_' + tile_id if tile_id else ''}_{file_name_suffix}_{output_suffix}.png\",\n",
    "    dpi=300,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd48224",
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.rmtree(\"temp_dask_dir\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b5723de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
