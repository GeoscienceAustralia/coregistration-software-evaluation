{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from arosics import COREG, COREG_LOCAL\n",
    "from zipfile import ZipFile\n",
    "from IPython.display import Image\n",
    "from rasterio.features import bounds, dataset_features\n",
    "import sys\n",
    "sys.path.insert(1, '../')\n",
    "from pyproj import Proj\n",
    "from utils import *\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Time series handling is limited. mainly pairwise. Need coding to loop trhough series.\n",
    "* Takes 30 secs to match two full res S2 scenes in global mode\n",
    "* Takse about 3 mins to match two full res S2 scenes with 120 grid points and running on 96 cores! (A bit concerning)\n",
    "* Also running in full res for local matching is very resource intensive!\n",
    "* Documentation not very straightforward!\n",
    "* Seems to be partially handaling the cloud cover specially for smaller images which seems to be doing good.\n",
    "* AU scenes are already co-registered mostly.\n",
    "* Local matching will fail for small overlaps.\n",
    "* window size of (500, 500) recommended. \n",
    "* overall both S1 and S2 register good over AU\n",
    "* local matching is recommended\n",
    "* seems to work better on band 2 (G) for the Antarctica\n",
    "* tricky to use on large images. works well on downsampled ones.\n",
    "* Phase correlation does not work when rotation required. It only works for translation shifts. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"../data/files_list\"\n",
    "\n",
    "S1_PRODUCTS = [\"SLC\", \"GRD\"]\n",
    "S2_PRODUCTS = [\"L1C\", \"L2A\"]\n",
    "\n",
    "s1_au_df = pd.read_csv(os.path.join(DATA_DIR, \"s1_au.csv\"), names=[\"ID\",\"Path\"])\n",
    "s1_an_df = pd.read_csv(os.path.join(DATA_DIR, \"s1_an.csv\"), names=[\"ID\",\"Path\"])\n",
    "\n",
    "s2_au_df = pd.read_csv(os.path.join(DATA_DIR, \"s2_au.csv\"), names=[\"ID\",\"Path\"])\n",
    "s2_an_df = pd.read_csv(os.path.join(DATA_DIR, \"s2_an.csv\"), names=[\"ID\",\"Path\"])\n",
    "\n",
    "s1_au_slc_dict = get_scenes_dict(s1_au_df, [\"SLC\"])\n",
    "s1_au_grd_dict = get_scenes_dict(s1_au_df, [\"GRD\"])\n",
    "\n",
    "s1_an_slc_dict = get_scenes_dict(s1_an_df, [\"SLC\"])\n",
    "s1_an_grd_dict = get_scenes_dict(s1_an_df, [\"GRD\"])\n",
    "\n",
    "s2_au_l1c_dict = get_scenes_dict(s2_au_df, [\"L1C\"], False)\n",
    "s2_au_l2a_dict = get_scenes_dict(s2_au_df, [\"L2A\"], False)\n",
    "\n",
    "s2_an_l1c_dict = get_scenes_dict(s2_an_df, [\"L1C\"], False)\n",
    "s2_an_l2a_dict = get_scenes_dict(s2_an_df, [\"L2A\"], False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.rmtree(\"../data/inputs/\", ignore_errors=True)\n",
    "# shutil.rmtree(\"../data/outputs/\", ignore_errors=True)\n",
    "os.makedirs(\"../data/inputs/\")\n",
    "os.makedirs(\"../data/outputs/\", exist_ok = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test two S2 L2A images for AN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "id = list(s2_an_l2a_dict.keys())[1]\n",
    "s2_an_l2a_secne_files = s2_an_l2a_dict[id]\n",
    "\n",
    "# get the Jan 2023 and Dec 2024 files\n",
    "s2_an_l2a_secne_pair = [s2_an_l2a_secne_files[10], s2_an_l2a_secne_files[-1]]\n",
    "\n",
    "shutil.rmtree(f\"../data/inputs/{id}/\", ignore_errors=True)\n",
    "for i, zip_file_path in enumerate(s2_an_l2a_secne_pair):\n",
    "    with ZipFile(zip_file_path) as f:\n",
    "        f.extractall(f\"../data/inputs/{id}/sub{i}\")\n",
    "ref_image_dir = os.path.join(\"../data/inputs/\", id, f\"sub{0}\")\n",
    "ref_tci_files = list(filter(lambda f: \"TCI\" in f, glob.glob(f\"{ref_image_dir}/*/GRANULE/*/IMG_DATA/**\", recursive=True)))\n",
    "ref_tci_files = list(filter(lambda f: \"L2A\" in f, ref_tci_files))\n",
    "if len(ref_tci_files) > 1:\n",
    "    ref_image = [f for f in ref_tci_files if f.endswith(\"_10m.jp2\")][0]\n",
    "else:\n",
    "    ref_image = ref_tci_files[0]\n",
    "\n",
    "tgt_image_dir = os.path.join(\"../data/inputs/\", id, f\"sub{1}\")\n",
    "tgt_tci_files = list(filter(lambda f: \"TCI\" in f, glob.glob(f\"{tgt_image_dir}/*/GRANULE/*/IMG_DATA/**\", recursive=True)))\n",
    "tgt_tci_files = list(filter(lambda f: \"L2A\" in f, tgt_tci_files))\n",
    "if len(tgt_tci_files) > 1:\n",
    "    tgt_image = [f for f in tgt_tci_files if f.endswith(\"_10m.jp2\")][0]\n",
    "else:\n",
    "    tgt_image = tgt_tci_files[0]\n",
    "\n",
    "global_output = os.path.join(\"../data/outputs/\", \"L2A_pair\", f\"{id}_global.tiff\")\n",
    "local_output = os.path.join(\"../data/outputs/\", \"L2A_pair\", f\"{id}_local.tiff\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "coreg_global = COREG(\n",
    "    im_ref=tgt_image,\n",
    "    im_tgt=ref_image,\n",
    "    path_out=global_output,\n",
    "    fmt_out=\"GTIFF\",\n",
    "    # v=True,\n",
    "    nodata=(0.0,0.0),\n",
    "    r_b4match=2,\n",
    "    s_b4match=2,\n",
    "    align_grids=True,\n",
    "    max_iter = 10,\n",
    "    max_shift = 10,\n",
    ")\n",
    "res = coreg_global.correct_shifts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "coreg_local = COREG_LOCAL(\n",
    "    im_ref=tgt_image,\n",
    "    im_tgt=ref_image,\n",
    "    grid_res=1000,\n",
    "    # max_points=200,\n",
    "    path_out=local_output,\n",
    "    fmt_out=\"GTIFF\",\n",
    "    # v=True,\n",
    "    nodata=(0.0,0.0),\n",
    "    # r_b4match=2,\n",
    "    # s_b4match=2,\n",
    "    align_grids=True,\n",
    "    max_iter = 10,\n",
    "    max_shift = 10,\n",
    "    CPUs = 8,\n",
    ")\n",
    "res = coreg_local.correct_shifts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_paths = [tgt_image, ref_image,  local_output]\n",
    "dataset_titles = [\"Reference\", \"Target\", \"Local matching\"]\n",
    "make_difference_gif(datasets_paths, \"s2_l2a_pair.gif\", dataset_titles, 0.1)\n",
    "Image(url='s2_l2a_pair.gif', width = 400, height=400) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test two AN S2 L1C secenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2_an_l1c_r031_dict = get_scenes_dict(s2_an_df, [\"L1C\", \"R031\"], False)\n",
    "id = list(s2_an_l1c_r031_dict.keys())[0]\n",
    "s2_an_l1c_secne_files = s2_an_l1c_r031_dict[id]\n",
    "\n",
    "# get the Jan 2023 and Dec 2024 files\n",
    "s2_an_l1c_secne_pair = [s2_an_l1c_secne_files[15], s2_an_l1c_secne_files[5]]\n",
    "\n",
    "shutil.rmtree(f\"../data/inputs/{id}/\", ignore_errors=True)\n",
    "for i, zip_file_path in enumerate(s2_an_l1c_secne_pair):\n",
    "    with ZipFile(zip_file_path) as f:\n",
    "        f.extractall(f\"../data/inputs/{id}/sub{i}\")\n",
    "ref_image_dir = os.path.join(\"../data/inputs/\", id, f\"sub{0}\")\n",
    "ref_tci_files = list(filter(lambda f: \"TCI\" in f, glob.glob(f\"{ref_image_dir}/*/GRANULE/*/IMG_DATA/**\", recursive=True)))\n",
    "ref_tci_files = list(filter(lambda f: \"L1C\" in f, ref_tci_files))\n",
    "if len(ref_tci_files) > 1:\n",
    "    ref_image = [f for f in ref_tci_files if f.endswith(\"_10m.jp2\")][0]\n",
    "else:\n",
    "    ref_image = ref_tci_files[0]\n",
    "\n",
    "tgt_image_dir = os.path.join(\"../data/inputs/\", id, f\"sub{1}\")\n",
    "tgt_tci_files = list(filter(lambda f: \"TCI\" in f, glob.glob(f\"{tgt_image_dir}/*/GRANULE/*/IMG_DATA/**\", recursive=True)))\n",
    "tgt_tci_files = list(filter(lambda f: \"L1C\" in f, tgt_tci_files))\n",
    "if len(tgt_tci_files) > 1:\n",
    "    tgt_image = [f for f in tgt_tci_files if f.endswith(\"_10m.jp2\")][0]\n",
    "else:\n",
    "    tgt_image = tgt_tci_files[0]\n",
    "\n",
    "local_output = os.path.join(\"../data/outputs/\", \"L1C_AN_pair\", f\"{id}_local.tiff\")\n",
    "global_output = os.path.join(\"../data/outputs/\", \"L1C_AN_pair\", f\"{id}_global.tiff\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "coreg_global = COREG(\n",
    "    im_ref=ref_image,\n",
    "    im_tgt=tgt_image,\n",
    "    path_out=global_output,\n",
    "    fmt_out=\"GTIFF\",\n",
    "    # v=True,\n",
    "    nodata=(0.0,0.0),\n",
    "    r_b4match=2,\n",
    "    s_b4match=2,\n",
    "    align_grids=True,\n",
    "    max_iter = 10,\n",
    "    max_shift = 10,\n",
    "    ws = (1500, 1500),\n",
    ")\n",
    "res = coreg_global.correct_shifts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "coreg_local = COREG_LOCAL(\n",
    "    im_ref=ref_image,\n",
    "    im_tgt=tgt_image,\n",
    "    grid_res=1000,\n",
    "    # max_points=200,\n",
    "    path_out=local_output,\n",
    "    fmt_out=\"GTIFF\",\n",
    "    # v=True,\n",
    "    nodata=(0.0,0.0),\n",
    "    r_b4match=2,\n",
    "    s_b4match=2,\n",
    "    align_grids=True,\n",
    "    max_iter = 10,\n",
    "    max_shift = 10,\n",
    "    CPUs = 8,\n",
    ")\n",
    "res = coreg_local.correct_shifts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_paths = [ref_image, tgt_image, local_output]\n",
    "datasets_titles = [\"Reference\", \"Target\", \"Local matching\"]\n",
    "make_difference_gif(datasets_paths, \"s2_l1c_an_pair.gif\", datasets_titles, 0.1)\n",
    "Image(url='s2_l1c_an_pair.gif', width = 400, height=400) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### S2 L1C and S1 RTC AN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find scenes\n",
    "s2_an_l1c_r031_dict = get_scenes_dict(s2_an_df, [\"L1C\", \"R031\"], False)\n",
    "s2_id = list(s2_an_l1c_r031_dict.keys())[0]\n",
    "s2_an_l1c_secne_files = s2_an_l1c_r031_dict[s2_id]\n",
    "\n",
    "# shutil.rmtree(f\"../data/inputs/{s2_id}/\", ignore_errors=True)\n",
    "\n",
    "# get the Jan 2023 for S2 L1C\n",
    "s2_an_l1c_scene = s2_an_l1c_secne_files[15]\n",
    "with ZipFile(s2_an_l1c_scene) as f:\n",
    "    f.extractall(f\"../data/inputs/{s2_id}/sub0\")\n",
    "\n",
    "ref_image_dir = os.path.join(\"../data/inputs/\", s2_id, f\"sub{0}\")\n",
    "ref_tci_files = list(filter(lambda f: \"TCI\" in f, glob.glob(f\"{ref_image_dir}/*/GRANULE/*/IMG_DATA/**\", recursive=True)))\n",
    "ref_tci_files = list(filter(lambda f: \"L1C\" in f, ref_tci_files))\n",
    "if len(ref_tci_files) > 1:\n",
    "    ref_image = [f for f in ref_tci_files if f.endswith(\"_10m.jp2\")][0]\n",
    "else:\n",
    "    ref_image = ref_tci_files[0]\n",
    "\n",
    "ref = rasterio.open(ref_image)\n",
    "ref_bounds = ref.bounds\n",
    "ref_crs = ref.crs\n",
    "\n",
    "ref_proj = Proj(**ref_crs.data)\n",
    "\n",
    "west, south = ref_proj(ref_bounds.left, ref_bounds.bottom, inverse = True)\n",
    "east, north = ref_proj(ref_bounds.right, ref_bounds.top, inverse = True)\n",
    "\n",
    "bbox = f\"{west},{south},{east},{north}\"\n",
    "\n",
    "os.makedirs(\"../data/asf/sub1\", exist_ok=True)\n",
    "with open(f\"../data/asf/sub1/bbox.txt\", \"w\") as f:\n",
    "    f.write(f\"{bbox}\\n\")\n",
    "    f.write(f\"{s2_id}\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_gamma(data):\n",
    "    gamma = 0.35\n",
    "    data = np.power(data, gamma)\n",
    "    data *= 255 / data.max()\n",
    "    data = data.astype(\"uint8\")\n",
    "    return data\n",
    "\n",
    "assert os.path.isfile(f\"../data/inputs/{s2_id}/sub1/rtc.txt\"), \"RTC file for the scene not ready or none-existent. Run `rtc_job_single_scene` notebook.\"\n",
    "with open(f\"../data/inputs/{s2_id}/sub1/rtc.txt\", \"r\") as f:\n",
    "    rtc_file = f.readline()\n",
    "\n",
    "with ZipFile(rtc_file) as f:\n",
    "    f.extractall(f\"../data/inputs/{s2_id}/sub1\")\n",
    "    \n",
    "tgt_image_dir = os.path.join(\"../data/inputs/\", s2_id, \"sub1\", f\"{os.path.splitext(os.path.basename(rtc_file))[0]}\")\n",
    "tgt_image = list(filter(lambda f: (\"_HH\" in f) and f.endswith(\".tif\"), glob.glob(f\"{tgt_image_dir}/*\")))[0]\n",
    "enhanced_tgt_image = tgt_image.replace(\".tif\", \"_enhanced.tif\")\n",
    "if os.path.isfile(enhanced_tgt_image):\n",
    "    os.remove(enhanced_tgt_image)\n",
    "downsample_dataset(tgt_image, 1.0, enhanced_tgt_image, apply_gamma)\n",
    "tgt_image = enhanced_tgt_image\n",
    "# repreojected_tgt_path = os.path.join(os.path.dirname(tgt_image), os.path.basename(tgt_image).replace(\".tiff\", \"-reprojected.tiff\"))\n",
    "# reproject_tif(tgt_image, repreojected_tgt_path, rasterio.open(ref_image).profile[\"crs\"])\n",
    "# tgt_image = repreojected_tgt_path\n",
    "\n",
    "local_output = os.path.join(\"../data/outputs/\", \"L1C_SLC_AN_pair\", f\"{s2_id}_local.tiff\")\n",
    "global_output = os.path.join(\"../data/outputs/\", \"L1C_SLC_AN_pair\", f\"{s2_id}_global.tiff\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "coreg_global = COREG(\n",
    "    im_ref=ref_image,\n",
    "    im_tgt=tgt_image,\n",
    "    path_out=global_output,\n",
    "    fmt_out=\"GTIFF\",\n",
    "    # v=True,\n",
    "    nodata=(0.0,0.0),\n",
    "    r_b4match=2,\n",
    "    s_b4match=1,\n",
    "    align_grids=True,\n",
    "    max_iter = 10,\n",
    "    max_shift = 25,\n",
    "    ws = (500, 500)\n",
    ")\n",
    "res = coreg_global.correct_shifts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "coreg_local = COREG_LOCAL(\n",
    "    im_ref=ref_image,\n",
    "    im_tgt=tgt_image,\n",
    "    grid_res=25,\n",
    "    # max_points=200,\n",
    "    path_out=local_output,\n",
    "    fmt_out=\"GTIFF\",\n",
    "    # v=True,\n",
    "    nodata=(0.0,0.0),\n",
    "    r_b4match=2,\n",
    "    # s_b4match=2,\n",
    "    align_grids=True,\n",
    "    max_iter = 10,\n",
    "    max_shift = 10,\n",
    "    CPUs = 8,\n",
    ")\n",
    "res = coreg_local.correct_shifts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### S2 L1C AN stack (downsampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2_an_l1c_r031_dict = get_scenes_dict(s2_an_df, [\"L1C\", \"R031\"], False)\n",
    "id = list(s2_an_l1c_r031_dict.keys())[0]\n",
    "s2_an_l1c_secne_files = s2_an_l1c_r031_dict[id]\n",
    "\n",
    "# tdf = s2_an_df[s2_an_df.ID == id]\n",
    "# tdf = tdf[tdf.Path.apply(lambda x: \"L1C\" in x)]\n",
    "# tdf = tdf[tdf.Path.apply(lambda x: \"N0511_R031\" in x)]\n",
    "# s2_an_l1c_secne_files = list(tdf.Path)\n",
    "\n",
    "shutil.rmtree(f\"../data/inputs/{id}/\", ignore_errors=True)\n",
    "\n",
    "ref_id = 15\n",
    "ref_scene = s2_an_l1c_secne_files[ref_id]\n",
    "with ZipFile(ref_scene) as f:\n",
    "        f.extractall(f\"../data/inputs/{id}/ref\")    \n",
    "ref_image_dir = os.path.join(\"../data/inputs/\", id, \"ref\")\n",
    "ref_tci_files = list(filter(lambda f: \"TCI\" in f, glob.glob(f\"{ref_image_dir}/*/GRANULE/*/IMG_DATA/**\", recursive=True)))\n",
    "ref_tci_files = list(filter(lambda f: \"L1C\" in f, ref_tci_files))\n",
    "if len(ref_tci_files) > 1:\n",
    "    ref_image = [f for f in ref_tci_files if f.endswith(\"_10m.jp2\")][0]\n",
    "else:\n",
    "    ref_image = ref_tci_files[0]\n",
    "\n",
    "downsample_dataset(ref_image, 0.1, ref_image.replace(\".jp2\", \"_ds.jp2\"))\n",
    "ref_image = ref_image.replace(\".jp2\", \"_ds.jp2\")\n",
    "\n",
    "tgt_scenes = [s2_an_l1c_secne_files[i] for i in range(0, len(s2_an_l1c_secne_files)) if i != ref_id]\n",
    "tgt_images = []\n",
    "local_outputs = []\n",
    "global_outputs = []\n",
    "for i, zip_file_path in enumerate(tgt_scenes):\n",
    "    print(f\"Extracting {i + 1} of {len(tgt_scenes)}: {zip_file_path}\")\n",
    "    with ZipFile(zip_file_path) as f:\n",
    "        f.extractall(f\"../data/inputs/{id}/tgt{i}\")\n",
    "    tgt_image_dir = os.path.join(\"../data/inputs/\", id, f\"tgt{i}\")\n",
    "    tgt_tci_files = list(filter(lambda f: \"TCI\" in f, glob.glob(f\"{tgt_image_dir}/*/GRANULE/*/IMG_DATA/**\", recursive=True)))\n",
    "    tgt_tci_files = list(filter(lambda f: \"L1C\" in f, tgt_tci_files))\n",
    "    if len(tgt_tci_files) > 1:\n",
    "        tgt_image = [f for f in tgt_tci_files if f.endswith(\"_10m.jp2\")][0]\n",
    "    else:\n",
    "        tgt_image = tgt_tci_files[0]\n",
    "    tgt_images.append(tgt_image)\n",
    "    local_outputs.append(os.path.join(\"../data/outputs/\", \"L1C_AN_Serie\", f\"{id}_local_{i}.tiff\"))\n",
    "    global_outputs.append(os.path.join(\"../data/outputs/\", \"L1C_AN_Serie\", f\"{id}_global_{i}.tiff\"))\n",
    "\n",
    "for img in tgt_images:\n",
    "     downsample_dataset(img, 0.1, img.replace(\".jp2\", \"_ds.jp2\"))\n",
    "tgt_images = [img.replace(\".jp2\", \"_ds.jp2\") for img in tgt_images]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Reference image: {ref_image}\")\n",
    "processed_tgt_images = []\n",
    "for i, tgt_image in enumerate(tgt_images):\n",
    "    print(f\"Coregistering {tgt_image}\")\n",
    "    coreg_global = COREG(\n",
    "        im_ref=ref_image,\n",
    "        im_tgt=tgt_image,\n",
    "        path_out=global_outputs[i],\n",
    "        fmt_out=\"GTIFF\",\n",
    "        # v=True,\n",
    "        nodata=(0.0,0.0),\n",
    "        r_b4match=2,\n",
    "        s_b4match=2,\n",
    "        align_grids=True,\n",
    "        max_iter = 10,\n",
    "        max_shift = 10,\n",
    "        ws = (500, 500),\n",
    "        ignore_errors=True,\n",
    "    )\n",
    "    res = coreg_global.correct_shifts()\n",
    "    if not coreg_global.success:\n",
    "        print(f\"Coregistration not successfull for {tgt_image}. Removing the corresponding output: {global_outputs[i]}\")\n",
    "        os.remove(global_outputs[i])\n",
    "    else:\n",
    "        processed_tgt_images.append(tgt_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_gif = \"../data/outputs/L1C_AN_Serie/s2_l1c_an_series_coreg_global.gif\"\n",
    "if os.path.isfile(out_gif):\n",
    "    os.remove(out_gif)\n",
    "output_tgt_images = glob.glob(\"../data/outputs/L1C_AN_Serie/*\")\n",
    "output_tgt_images = [f for f in output_tgt_images if (\"global\" in f) and f.endswith(\".tiff\")]\n",
    "fids = sorted([int(os.path.splitext(os.path.basename(tgt))[0].split(\"_\")[-1]) for tgt in output_tgt_images])\n",
    "output_tgt_images = [f\"{os.path.splitext(output_tgt_images[0])[0].rsplit(\"_\", maxsplit=1)[0]}_{id}.tiff\" for id in fids]\n",
    "datasets_paths = [ref_image] +  output_tgt_images\n",
    "datasets_titles = [\"Reference\"] + [f\"target_{id}\" for id in fids]\n",
    "make_difference_gif(datasets_paths, out_gif, datasets_titles)\n",
    "Image(filename=out_gif, width = 400, height=400) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_gif = \"../data/outputs/L1C_AN_Serie/s2_l1c_an_series_raw_global.gif\"\n",
    "if os.path.isfile(out_gif):\n",
    "    os.remove(out_gif)\n",
    "datasets_paths = [ref_image] +  processed_tgt_images\n",
    "datasets_titles = [\"Reference\"] + [f\"target_{id}\" for id in fids]\n",
    "make_difference_gif(datasets_paths, out_gif, datasets_titles)\n",
    "Image(filename=out_gif, width = 400, height=400) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_tgt_images = []\n",
    "print(f\"Reference image: {ref_image}\")\n",
    "for i, tgt_image in enumerate(tgt_images):\n",
    "    print(f\"Coregistering {tgt_image}\")\n",
    "    coreg_local = COREG_LOCAL(\n",
    "        im_ref=ref_image,\n",
    "        im_tgt=tgt_image,\n",
    "        grid_res=50,\n",
    "        # max_points=200,\n",
    "        path_out=local_outputs[i],\n",
    "        fmt_out=\"GTIFF\",\n",
    "        # v=True,\n",
    "        nodata=(0.0,0.0),\n",
    "        r_b4match=2,\n",
    "        s_b4match=2,\n",
    "        align_grids=True,\n",
    "        max_iter = 10,\n",
    "        max_shift = 10,\n",
    "        CPUs = 8,\n",
    "        ignore_errors=True,\n",
    "    )\n",
    "    res = coreg_local.correct_shifts()\n",
    "    if not coreg_local.success:\n",
    "        print(f\"Coregistration not successfull for {tgt_image}. Removing the corresponding output: {local_outputs[i]}\")\n",
    "        if os.path.isfile(local_outputs[i]):\n",
    "            os.remove(local_outputs[i])\n",
    "    else:\n",
    "        processed_tgt_images.append(tgt_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_gif = \"../data/outputs/L1C_AN_Serie/s2_l1c_an_series_coreg_local.gif\"\n",
    "if os.path.isfile(out_gif):\n",
    "    os.remove(out_gif)\n",
    "output_tgt_images = glob.glob(\"../data/outputs/L1C_AN_Serie/*\")\n",
    "output_tgt_images = [f for f in output_tgt_images if (\"local\" in f) and f.endswith(\".tiff\")]\n",
    "fids = sorted([int(os.path.splitext(os.path.basename(tgt))[0].split(\"_\")[-1]) for tgt in output_tgt_images])\n",
    "output_tgt_images = [f\"{os.path.splitext(output_tgt_images[0])[0].rsplit(\"_\", maxsplit=1)[0]}_{id}.tiff\" for id in fids]\n",
    "datasets_paths = [ref_image] +  output_tgt_images\n",
    "datasets_titles = [\"Reference\"] + [f\"target_{id}\" for id in fids]\n",
    "make_difference_gif(datasets_paths, out_gif, datasets_titles)\n",
    "Image(filename=out_gif, width = 400, height=400) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_gif = \"../data/outputs/L1C_AN_Serie/s2_l1c_an_series_raw_local.gif\"\n",
    "if os.path.isfile(out_gif):\n",
    "    os.remove(out_gif)\n",
    "datasets_paths = [ref_image] +  processed_tgt_images\n",
    "datasets_titles = [\"Reference\"] + [f\"target_{id}\" for id in fids]\n",
    "make_difference_gif(datasets_paths, out_gif, datasets_titles)\n",
    "Image(filename=out_gif, width = 400, height=400) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### S2 L1C AN 2024 N0511_R031"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2_an_l1c_r031_dict = get_scenes_dict(s2_an_df, [\"L1C\", \"R031\"], False)\n",
    "id = list(s2_an_l1c_r031_dict.keys())[0]\n",
    "\n",
    "tdf = s2_an_df[s2_an_df.ID == id]\n",
    "tdf = tdf[tdf.Path.apply(lambda x: \"L1C\" in x)]\n",
    "tdf = tdf[tdf.Path.apply(lambda x: \"N0511_R031\" in x)]\n",
    "s2_an_l1c_secne_files = list(tdf.Path)\n",
    "\n",
    "shutil.rmtree(f\"../data/inputs/{id}/\", ignore_errors=True)\n",
    "\n",
    "ref_id = 4\n",
    "ref_scene = s2_an_l1c_secne_files[ref_id]\n",
    "with ZipFile(ref_scene) as f:\n",
    "        f.extractall(f\"../data/inputs/{id}/ref\")    \n",
    "ref_image_dir = os.path.join(\"../data/inputs/\", id, \"ref\")\n",
    "ref_tci_files = list(filter(lambda f: \"TCI\" in f, glob.glob(f\"{ref_image_dir}/*/GRANULE/*/IMG_DATA/**\", recursive=True)))\n",
    "ref_tci_files = list(filter(lambda f: \"L1C\" in f, ref_tci_files))\n",
    "if len(ref_tci_files) > 1:\n",
    "    ref_image = [f for f in ref_tci_files if f.endswith(\"_10m.jp2\")][0]\n",
    "else:\n",
    "    ref_image = ref_tci_files[0]\n",
    "\n",
    "downsample_dataset(ref_image, 0.1, ref_image.replace(\".jp2\", \"_ds.jp2\"))\n",
    "ref_image = ref_image.replace(\".jp2\", \"_ds.jp2\")\n",
    "\n",
    "tgt_scenes = [s2_an_l1c_secne_files[i] for i in range(0, len(s2_an_l1c_secne_files)) if i != ref_id]\n",
    "tgt_images = []\n",
    "local_outputs = []\n",
    "global_outputs = []\n",
    "for i, zip_file_path in enumerate(tgt_scenes):\n",
    "    print(f\"Extracting {i + 1} of {len(tgt_scenes)}: {zip_file_path}\")\n",
    "    with ZipFile(zip_file_path) as f:\n",
    "        f.extractall(f\"../data/inputs/{id}/tgt{i}\")\n",
    "    tgt_image_dir = os.path.join(\"../data/inputs/\", id, f\"tgt{i}\")\n",
    "    tgt_tci_files = list(filter(lambda f: \"TCI\" in f, glob.glob(f\"{tgt_image_dir}/*/GRANULE/*/IMG_DATA/**\", recursive=True)))\n",
    "    tgt_tci_files = list(filter(lambda f: \"L1C\" in f, tgt_tci_files))\n",
    "    if len(tgt_tci_files) > 1:\n",
    "        tgt_image = [f for f in tgt_tci_files if f.endswith(\"_10m.jp2\")][0]\n",
    "    else:\n",
    "        tgt_image = tgt_tci_files[0]\n",
    "    tgt_images.append(tgt_image)\n",
    "    local_outputs.append(os.path.join(\"../data/outputs/\", \"L1C_AN_Serie\", f\"{id}_local_{i}.tiff\"))\n",
    "    global_outputs.append(os.path.join(\"../data/outputs/\", \"L1C_AN_Serie\", f\"{id}_global_{i}.tiff\"))\n",
    "\n",
    "for img in tgt_images:\n",
    "     downsample_dataset(img, 0.1, img.replace(\".jp2\", \"_ds.jp2\"))\n",
    "tgt_images = [img.replace(\".jp2\", \"_ds.jp2\") for img in tgt_images]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Reference image: {ref_image}\")\n",
    "processed_tgt_images = []\n",
    "for i, tgt_image in enumerate(tgt_images):\n",
    "    print(f\"Coregistering {tgt_image}\")\n",
    "    coreg_global = COREG(\n",
    "        im_ref=ref_image,\n",
    "        im_tgt=tgt_image,\n",
    "        path_out=global_outputs[i],\n",
    "        fmt_out=\"GTIFF\",\n",
    "        # v=True,\n",
    "        nodata=(0.0,0.0),\n",
    "        r_b4match=2,\n",
    "        s_b4match=2,\n",
    "        align_grids=True,\n",
    "        max_iter = 10,\n",
    "        max_shift = 10,\n",
    "        ws = (500, 500),\n",
    "        ignore_errors=True,\n",
    "    )\n",
    "    res = coreg_global.correct_shifts()\n",
    "    if not coreg_global.success:\n",
    "        print(f\"Coregistration not successfull for {tgt_image}. Removing the corresponding output: {global_outputs[i]}\")\n",
    "        os.remove(global_outputs[i])\n",
    "    else:\n",
    "        processed_tgt_images.append(tgt_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_gif = \"../data/outputs/L1C_AN_Serie/s2_l1c_an_series_coreg_global.gif\"\n",
    "if os.path.isfile(out_gif):\n",
    "    os.remove(out_gif)\n",
    "output_tgt_images = glob.glob(\"../data/outputs/L1C_AN_Serie/*\")\n",
    "output_tgt_images = [f for f in output_tgt_images if (\"global\" in f) and f.endswith(\".tiff\")]\n",
    "fids = sorted([int(os.path.splitext(os.path.basename(tgt))[0].split(\"_\")[-1]) for tgt in output_tgt_images])\n",
    "output_tgt_images = [f\"{os.path.splitext(output_tgt_images[0])[0].rsplit(\"_\", maxsplit=1)[0]}_{id}.tiff\" for id in fids]\n",
    "datasets_paths = [ref_image] +  output_tgt_images\n",
    "datasets_titles = [\"Reference\"] + [f\"target_{id}\" for id in fids]\n",
    "make_difference_gif(datasets_paths, out_gif, datasets_titles)\n",
    "Image(filename=out_gif, width = 400, height=400) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_gif = \"../data/outputs/L1C_AN_Serie/s2_l1c_an_series_raw_global.gif\"\n",
    "if os.path.isfile(out_gif):\n",
    "    os.remove(out_gif)\n",
    "datasets_paths = [ref_image] +  processed_tgt_images\n",
    "datasets_titles = [\"Reference\"] + [f\"target_{id}\" for id in fids]\n",
    "make_difference_gif(datasets_paths, out_gif, datasets_titles)\n",
    "Image(filename=out_gif, width = 400, height=400) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_tgt_images = []\n",
    "print(f\"Reference image: {ref_image}\")\n",
    "for i, tgt_image in enumerate(tgt_images):\n",
    "    print(f\"Coregistering {tgt_image}\")\n",
    "    coreg_local = COREG_LOCAL(\n",
    "        im_ref=ref_image,\n",
    "        im_tgt=tgt_image,\n",
    "        grid_res=50,\n",
    "        # max_points=200,\n",
    "        path_out=local_outputs[i],\n",
    "        fmt_out=\"GTIFF\",\n",
    "        # v=True,\n",
    "        nodata=(0.0,0.0),\n",
    "        r_b4match=2,\n",
    "        s_b4match=2,\n",
    "        align_grids=True,\n",
    "        max_iter = 10,\n",
    "        max_shift = 10,\n",
    "        CPUs = 8,\n",
    "        ignore_errors=True,\n",
    "    )\n",
    "    res = coreg_local.correct_shifts()\n",
    "    if not coreg_local.success:\n",
    "        print(f\"Coregistration not successfull for {tgt_image}. Removing the corresponding output: {local_outputs[i]}\")\n",
    "        if os.path.isfile(local_outputs[i]):\n",
    "            os.remove(local_outputs[i])\n",
    "    else:\n",
    "        processed_tgt_images.append(tgt_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_gif = \"../data/outputs/L1C_AN_Serie/s2_l1c_an_series_coreg_local.gif\"\n",
    "if os.path.isfile(out_gif):\n",
    "    os.remove(out_gif)\n",
    "output_tgt_images = glob.glob(\"../data/outputs/L1C_AN_Serie/*\")\n",
    "output_tgt_images = [f for f in output_tgt_images if (\"local\" in f) and f.endswith(\".tiff\")]\n",
    "fids = sorted([int(os.path.splitext(os.path.basename(tgt))[0].split(\"_\")[-1]) for tgt in output_tgt_images])\n",
    "output_tgt_images = [f\"{os.path.splitext(output_tgt_images[0])[0].rsplit(\"_\", maxsplit=1)[0]}_{id}.tiff\" for id in fids]\n",
    "datasets_paths = [ref_image] +  output_tgt_images\n",
    "datasets_titles = [\"Reference\"] + [f\"target_{id}\" for id in fids]\n",
    "make_difference_gif(datasets_paths, out_gif, datasets_titles)\n",
    "Image(filename=out_gif, width = 400, height=400) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_gif = \"../data/outputs/L1C_AN_Serie/s2_l1c_an_series_raw_local.gif\"\n",
    "if os.path.isfile(out_gif):\n",
    "    os.remove(out_gif)\n",
    "datasets_paths = [ref_image] +  processed_tgt_images\n",
    "datasets_titles = [\"Reference\"] + [f\"target_{id}\" for id in fids]\n",
    "make_difference_gif(datasets_paths, out_gif, datasets_titles)\n",
    "Image(filename=out_gif, width = 400, height=400) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Co-register an arbitrary transformed scene to a reference scene for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2_an_l1c_r031_dict = get_scenes_dict(s2_an_df, [\"L1C\", \"R031\"], False)\n",
    "id = list(s2_an_l1c_r031_dict.keys())[0]\n",
    "tdf = s2_an_df[s2_an_df.ID == id]\n",
    "tdf = tdf[tdf.Path.apply(lambda x: \"L1C\" in x)]\n",
    "tdf = tdf[tdf.Path.apply(lambda x: \"N0511_R031\" in x)]\n",
    "s2_an_l1c_secne_files = list(tdf.Path)\n",
    "ref_id = 4\n",
    "ref_scene = s2_an_l1c_secne_files[ref_id]\n",
    "\n",
    "shutil.rmtree(f\"../data/inputs/{id}/\", ignore_errors=True)\n",
    "with ZipFile(ref_scene) as f:\n",
    "        f.extractall(f\"../data/inputs/{id}/ref\")    \n",
    "ref_image_dir = os.path.join(\"../data/inputs/\", id, \"ref\")\n",
    "\n",
    "ref_tci_files = list(filter(lambda f: \"TCI\" in f, glob.glob(f\"{ref_image_dir}/*/GRANULE/*/IMG_DATA/**\", recursive=True)))\n",
    "ref_tci_files = list(filter(lambda f: \"L1C\" in f, ref_tci_files))\n",
    "if len(ref_tci_files) > 1:\n",
    "    ref_image = [f for f in ref_tci_files if f.endswith(\"_10m.jp2\")][0]\n",
    "else:\n",
    "    ref_image = ref_tci_files[0]\n",
    "\n",
    "print(f\"Reference image: {ref_image}\")\n",
    "\n",
    "params = {\n",
    "    \"translation_x\": 100.0,\n",
    "    \"translation_y\": 50.0,\n",
    "    \"rotation_angle\": 30.0,\n",
    "    \"scale\": 0.75,\n",
    "}\n",
    "\n",
    "tgt_image_dir = os.path.join(\"../data/inputs/\", id, \"tgt\")\n",
    "os.makedirs(tgt_image_dir, exist_ok=True)\n",
    "\n",
    "tgt_image = os.path.join(tgt_image_dir, \"tgt.tif\")\n",
    "warp_affine_dataset(ref_image, tgt_image, **params)\n",
    "\n",
    "_, (axb, axt) = plt.subplots(1,2, figsize=(10, 20))\n",
    "show(downsample_dataset(ref_image, 0.1)[0], ax=axb, title=\"Reference scene\")\n",
    "show(downsample_dataset(tgt_image, 0.1)[0], ax=axt, title=\"Target scene\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"data/outputs/warp_test\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "output_path = os.path.join(output_dir, \"global_coreg.tif\")\n",
    "coreg_global = COREG(\n",
    "    im_ref=ref_image,\n",
    "    im_tgt=tgt_image,\n",
    "    path_out=output_path,\n",
    "    fmt_out=\"GTIFF\",\n",
    "    # v=True,\n",
    "    nodata=(0.0,0.0),\n",
    "    r_b4match=2,\n",
    "    s_b4match=2,\n",
    "    align_grids=True,\n",
    "    max_iter = 10,\n",
    "    max_shift = 5000,\n",
    "    ws = (10000, 10000),\n",
    ")\n",
    "res = coreg_global.correct_shifts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"data/outputs/warp_test\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "output_path = os.path.join(output_dir, \"local_coreg.tif\")\n",
    "coreg_local = COREG_LOCAL(\n",
    "    im_ref=ref_image,\n",
    "    im_tgt=tgt_image,\n",
    "    grid_res=500,\n",
    "    # max_points=200,\n",
    "    path_out=output_path,\n",
    "    fmt_out=\"GTIFF\",\n",
    "    # v=True,\n",
    "    nodata=(0.0,0.0),\n",
    "    r_b4match=2,\n",
    "    s_b4match=2,\n",
    "    align_grids=True,\n",
    "    max_iter = 10,\n",
    "    max_shift = 150,\n",
    "    CPUs = 8,\n",
    ")\n",
    "res = coreg_local.correct_shifts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
