{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import rasterio\n",
    "import cv2 as cv\n",
    "import sys\n",
    "import pandas as pd\n",
    "\n",
    "sys.path.insert(1, \"../\")\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ECC works for images of the same type with very good overlap. not working with images with small overlaps (not coorectly registering for multi-sensor cases at least without pre-processing)\n",
    "* very very slow! (for original images)\n",
    "* Phase correlation is basically global co-registration in AROSICS. not working for transformation. It only does translation shifts but it is very fast. It can support multi-sensor as it could work on images with partial overlaps.\n",
    "* It seems that optical flow is doing better than phase correlation but the improvement is trivial in multi-sensor. It does much better in optical pairs. Also it is very fast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"../data/files_list\"\n",
    "\n",
    "S1_PRODUCTS = [\"SLC\", \"GRD\"]\n",
    "S2_PRODUCTS = [\"L1C\", \"L2A\"]\n",
    "\n",
    "s1_au_df = pd.read_csv(os.path.join(DATA_DIR, \"s1_au.csv\"), names=[\"ID\", \"Path\"])\n",
    "s1_an_df = pd.read_csv(os.path.join(DATA_DIR, \"s1_an.csv\"), names=[\"ID\", \"Path\"])\n",
    "\n",
    "s2_au_df = pd.read_csv(os.path.join(DATA_DIR, \"s2_au.csv\"), names=[\"ID\", \"Path\"])\n",
    "s2_an_df = pd.read_csv(os.path.join(DATA_DIR, \"s2_an.csv\"), names=[\"ID\", \"Path\"])\n",
    "\n",
    "s1_au_slc_dict = get_scenes_dict(s1_au_df, [\"SLC\"])\n",
    "s1_au_grd_dict = get_scenes_dict(s1_au_df, [\"GRD\"])\n",
    "\n",
    "s1_an_slc_dict = get_scenes_dict(s1_an_df, [\"SLC\"])\n",
    "s1_an_grd_dict = get_scenes_dict(s1_an_df, [\"GRD\"])\n",
    "\n",
    "s2_au_l1c_dict = get_scenes_dict(s2_au_df, [\"L1C\"], False)\n",
    "s2_au_l2a_dict = get_scenes_dict(s2_au_df, [\"L2A\"], False)\n",
    "\n",
    "s2_an_l1c_dict = get_scenes_dict(s2_an_df, [\"L1C\"], False)\n",
    "s2_an_l2a_dict = get_scenes_dict(s2_an_df, [\"L2A\"], False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Coregister arbitrary scenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2_an_l1c_r031_dict = get_scenes_dict(s2_an_df, [\"L1C\", \"R031\"], False)\n",
    "id = list(s2_an_l1c_r031_dict.keys())[0]\n",
    "tdf = s2_an_df[s2_an_df.ID == id]\n",
    "tdf = tdf[tdf.Path.apply(lambda x: \"L1C\" in x)]\n",
    "tdf = tdf[tdf.Path.apply(lambda x: \"N0511_R031\" in x)]\n",
    "s2_an_l1c_secne_files = list(tdf.Path)\n",
    "ref_id = 4\n",
    "ref_scene = s2_an_l1c_secne_files[ref_id]\n",
    "\n",
    "shutil.rmtree(f\"../data/inputs/{id}/\", ignore_errors=True)\n",
    "with ZipFile(ref_scene) as f:\n",
    "    f.extractall(f\"../data/inputs/{id}/ref\")\n",
    "ref_image_dir = os.path.join(\"../data/inputs/\", id, \"ref\")\n",
    "\n",
    "ref_tci_files = list(\n",
    "    filter(\n",
    "        lambda f: \"TCI\" in f,\n",
    "        glob.glob(f\"{ref_image_dir}/*/GRANULE/*/IMG_DATA/**\", recursive=True),\n",
    "    )\n",
    ")\n",
    "ref_tci_files = list(filter(lambda f: \"L1C\" in f, ref_tci_files))\n",
    "if len(ref_tci_files) > 1:\n",
    "    ref_image = [f for f in ref_tci_files if f.endswith(\"_10m.jp2\")][0]\n",
    "else:\n",
    "    ref_image = ref_tci_files[0]\n",
    "\n",
    "print(f\"Reference image: {ref_image}\")\n",
    "\n",
    "params = {\n",
    "    \"translation_x\": 5.0,\n",
    "    \"translation_y\": 10.0,\n",
    "    \"rotation_angle\": 2.5,\n",
    "    \"scale\": 1.0,\n",
    "}\n",
    "\n",
    "tgt_image_dir = os.path.join(\"../data/inputs/\", id, \"tgt\")\n",
    "os.makedirs(tgt_image_dir, exist_ok=True)\n",
    "\n",
    "tgt_image = os.path.join(tgt_image_dir, \"tgt.tif\")\n",
    "warp_affine_dataset(ref_image, tgt_image, **params)\n",
    "\n",
    "_, (axb, axt) = plt.subplots(1, 2, figsize=(10, 20))\n",
    "show(downsample_dataset(ref_image, 0.1)[0], ax=axb, title=\"Reference scene\")\n",
    "show(downsample_dataset(tgt_image, 0.1)[0], ax=axt, title=\"Target scene\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_image_ds = os.path.join(ref_image_dir, \"ref_ds.tif\")\n",
    "downsample_dataset(ref_image, 0.1, ref_image_ds)\n",
    "tgt_image_ds = os.path.join(tgt_image_dir, \"tgt_ds.tif\")\n",
    "_ = downsample_dataset(tgt_image, 0.1, tgt_image_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_img = cv.cvtColor(\n",
    "    flip_img(rasterio.open(ref_image).read().copy()), cv.COLOR_BGR2GRAY\n",
    ")\n",
    "tgt_img = cv.cvtColor(\n",
    "    flip_img(rasterio.open(tgt_image).read().copy()), cv.COLOR_BGR2GRAY\n",
    ")\n",
    "ref_img_ds = cv.cvtColor(\n",
    "    flip_img(rasterio.open(ref_image_ds).read().copy()), cv.COLOR_BGR2GRAY\n",
    ")\n",
    "tgt_img_ds = cv.cvtColor(\n",
    "    flip_img(rasterio.open(tgt_image_ds).read().copy()), cv.COLOR_BGR2GRAY\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ECC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warp_mode = cv.MOTION_HOMOGRAPHY\n",
    "warp_matrix = np.eye(3, 3, dtype=np.float32)\n",
    "number_of_iterations = 5000\n",
    "termination_eps = 1e-5\n",
    "\n",
    "criteria = (\n",
    "    cv.TERM_CRITERIA_EPS | cv.TERM_CRITERIA_COUNT,\n",
    "    number_of_iterations,\n",
    "    termination_eps,\n",
    ")\n",
    "(cc, warp_matrix) = cv.findTransformECC(\n",
    "    ref_img_ds, tgt_img_ds, warp_matrix, warp_mode, criteria\n",
    ")\n",
    "\n",
    "tgt_aligned_homography_ds = cv.warpPerspective(\n",
    "    tgt_img_ds,\n",
    "    warp_matrix,\n",
    "    (tgt_img_ds.shape[1], tgt_img_ds.shape[0]),\n",
    "    flags=cv.INTER_LINEAR + cv.WARP_INVERSE_MAP,\n",
    ")\n",
    "\n",
    "# tgt_aligned_homography = cv.warpPerspective(\n",
    "#     tgt_img,\n",
    "#     warp_matrix,\n",
    "#     (tgt_img.shape[1], tgt_img.shape[0]),\n",
    "#     flags=cv.INTER_LINEAR + cv.WARP_INVERSE_MAP,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warp_mode = cv.MOTION_AFFINE\n",
    "warp_matrix = np.eye(2, 3, dtype=np.float32)\n",
    "number_of_iterations = 5000\n",
    "termination_eps = 1e-5\n",
    "\n",
    "criteria = (\n",
    "    cv.TERM_CRITERIA_EPS | cv.TERM_CRITERIA_COUNT,\n",
    "    number_of_iterations,\n",
    "    termination_eps,\n",
    ")\n",
    "(cc, warp_matrix) = cv.findTransformECC(\n",
    "    ref_img_ds, tgt_img_ds, warp_matrix, warp_mode, criteria\n",
    ")\n",
    "\n",
    "tgt_aligned_affine_ds = cv.warpAffine(\n",
    "    tgt_img_ds,\n",
    "    warp_matrix,\n",
    "    (tgt_img_ds.shape[1], tgt_img_ds.shape[0]),\n",
    "    flags=cv.INTER_LINEAR + cv.WARP_INVERSE_MAP,\n",
    ")\n",
    "\n",
    "# tgt_aligned_affine = cv.warpAffine(\n",
    "#     tgt_img,\n",
    "#     warp_matrix,\n",
    "#     (tgt_img.shape[1], tgt_img.shape[0]),\n",
    "#     flags=cv.INTER_LINEAR + cv.WARP_INVERSE_MAP,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, axes = plt.subplots(1, 4, figsize=(15, 10))\n",
    "axes[0].imshow(ref_img_ds, cmap=\"jet\")\n",
    "axes[0].set_xlabel(\"Reference\")\n",
    "axes[1].imshow(tgt_img_ds, cmap=\"jet\")\n",
    "axes[1].set_xlabel(f\"Target, ssim:{np.round(ssim(ref_img_ds, tgt_img_ds), 3)}\")\n",
    "axes[2].imshow(tgt_aligned_homography_ds, cmap=\"jet\")\n",
    "axes[2].set_xlabel(\n",
    "    f\"Registered (hompgraphy), ssim:{np.round(ssim(ref_img_ds, tgt_aligned_homography_ds), 3)}\"\n",
    ")\n",
    "axes[3].imshow(tgt_aligned_affine_ds, cmap=\"jet\")\n",
    "axes[3].set_xlabel(\n",
    "    f\"Registered (affine), ssim:{np.round(ssim(ref_img_ds, tgt_aligned_affine_ds), 3)}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _, axes = plt.subplots(1, 4, figsize=(15, 10))\n",
    "# axes[0].imshow(ref_img, cmap=\"jet\")\n",
    "# axes[0].set_xlabel(\"Reference\")\n",
    "# axes[1].imshow(tgt_img, cmap=\"jet\")\n",
    "# axes[1].set_xlabel(f\"Target, ssim:{np.round(ssim(ref_img, tgt_img), 3)}\")\n",
    "# axes[2].imshow(tgt_aligned_homography, cmap=\"jet\")\n",
    "# axes[2].set_xlabel(\n",
    "#     f\"Registered (hompgraphy), ssim:{np.round(ssim(ref_img, tgt_aligned_homography), 3)}\"\n",
    "# )\n",
    "# axes[3].imshow(tgt_aligned_affine, cmap=\"jet\")\n",
    "# axes[3].set_xlabel(\n",
    "#     f\"Registered (affine), ssim:{np.round(ssim(ref_img, tgt_aligned_affine), 3)}\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Phase Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window = cv.createHanningWindow(ref_img_ds.shape, cv.CV_32F)\n",
    "# window = None\n",
    "((shift_x, shift_y), phase_corr_score) = cv.phaseCorrelate(\n",
    "    np.float32(tgt_img_ds), np.float32(ref_img_ds), window\n",
    ")\n",
    "tgt_shifted_ds = warp_affine_dataset(\n",
    "    tgt_img_ds, translation_x=shift_x, translation_y=shift_y\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, axes = plt.subplots(1, 3, figsize=(15, 10))\n",
    "axes[0].imshow(ref_img_ds, cmap=\"jet\")\n",
    "axes[0].set_xlabel(\"Reference\")\n",
    "axes[1].imshow(tgt_img_ds, cmap=\"jet\")\n",
    "axes[1].set_xlabel(f\"Target, ssim:{np.round(ssim(ref_img_ds, tgt_img_ds), 3)}\")\n",
    "axes[2].imshow(tgt_shifted_ds, cmap=\"jet\")\n",
    "axes[2].set_xlabel(f\"Registered, ssim:{np.round(ssim(ref_img_ds, tgt_shifted_ds), 3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# window = cv.createHanningWindow(ref_img.shape, cv.CV_32F)\n",
    "window = None\n",
    "((shift_x, shift_y), phase_corr_score) = cv.phaseCorrelate(\n",
    "    np.float32(tgt_img), np.float32(ref_img), window\n",
    ")\n",
    "tgt_shifted = warp_affine_dataset(tgt_img, translation_x=shift_x, translation_y=shift_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, axes = plt.subplots(1, 3, figsize=(15, 10))\n",
    "axes[0].imshow(ref_img, cmap=\"jet\")\n",
    "axes[0].set_xlabel(\"Reference\")\n",
    "axes[1].imshow(tgt_img, cmap=\"jet\")\n",
    "axes[1].set_xlabel(f\"Target, ssim:{np.round(ssim(ref_img, tgt_img), 3)}\")\n",
    "axes[2].imshow(tgt_shifted, cmap=\"jet\")\n",
    "axes[2].set_xlabel(f\"Registered, ssim:{np.round(ssim(ref_img, tgt_shifted), 3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Optical flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params for ShiTomasi corner detection\n",
    "feature_params = dict(\n",
    "    maxCorners=100,\n",
    "    qualityLevel=0.3,\n",
    "    minDistance=7,\n",
    "    blockSize=7,\n",
    ")\n",
    "\n",
    "# Parameters for lucas kanade optical flow\n",
    "number_of_iterations = 10\n",
    "termination_eps = 1e-5\n",
    "lk_params = dict(\n",
    "    winSize=(15, 15),\n",
    "    maxLevel=2,\n",
    "    criteria=(\n",
    "        cv.TERM_CRITERIA_EPS | cv.TERM_CRITERIA_COUNT,\n",
    "        number_of_iterations,\n",
    "        termination_eps,\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p0 = cv.goodFeaturesToTrack(ref_img_ds, mask=None, **feature_params)\n",
    "p1, st, err = cv.calcOpticalFlowPyrLK(ref_img_ds, tgt_img_ds, p0, None, **lk_params)\n",
    "ref_good = p0[st == 1].astype(np.float32)\n",
    "tgt_good = p1[st == 1].astype(np.float32)\n",
    "warp_matrix = cv.findHomography(ref_good, tgt_good, cv.RANSAC)[0]\n",
    "tgt_aligned_ds = cv.warpPerspective(\n",
    "    tgt_img_ds,\n",
    "    warp_matrix,\n",
    "    (tgt_img_ds.shape[1], tgt_img_ds.shape[0]),\n",
    "    flags=cv.INTER_LINEAR + cv.WARP_INVERSE_MAP,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, axes = plt.subplots(1, 3, figsize=(15, 10))\n",
    "axes[0].imshow(ref_img_ds, cmap=\"jet\")\n",
    "axes[0].set_xlabel(\"Reference\")\n",
    "axes[1].imshow(tgt_img_ds, cmap=\"jet\")\n",
    "axes[1].set_xlabel(f\"Target, ssim:{np.round(ssim(ref_img_ds, tgt_img_ds), 3)}\")\n",
    "axes[2].imshow(tgt_aligned_ds, cmap=\"jet\")\n",
    "axes[2].set_xlabel(f\"Registered, ssim:{np.round(ssim(ref_img_ds, tgt_aligned_ds), 3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p0 = cv.goodFeaturesToTrack(ref_img, mask=None, **feature_params)\n",
    "# p1, st, err = cv.calcOpticalFlowPyrLK(ref_img, tgt_img, p0, None, **lk_params)\n",
    "# ref_good = p0[st == 1].astype(np.float32)\n",
    "# tgt_good = p1[st == 1].astype(np.float32)\n",
    "# warp_matrix = cv.findHomography(ref_good, tgt_good, cv.RANSAC)[0]\n",
    "# tgt_aligned = cv.warpPerspective(\n",
    "#     tgt_img,\n",
    "#     warp_matrix,\n",
    "#     (tgt_img.shape[1], tgt_img.shape[0]),\n",
    "#     flags=cv.INTER_LINEAR + cv.WARP_INVERSE_MAP,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _, axes = plt.subplots(1, 3, figsize=(15, 10))\n",
    "# axes[0].imshow(ref_img, cmap=\"jet\")\n",
    "# axes[0].set_xlabel(\"Reference\")\n",
    "# axes[1].imshow(tgt_img, cmap=\"jet\")\n",
    "# axes[1].set_xlabel(f\"Target, ssim:{np.round(ssim(ref_img, tgt_img), 3)}\")\n",
    "# axes[2].imshow(tgt_aligned, cmap=\"jet\")\n",
    "# axes[2].set_xlabel(f\"Registered, ssim:{np.round(ssim(ref_img, tgt_aligned), 3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Feature matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_FEATURES = 500\n",
    "GOOD_MATCH_PERCENT = 0.15\n",
    "orb = cv.ORB_create(MAX_FEATURES)\n",
    "keypoints1, descriptors1 = orb.detectAndCompute(ref_img_ds, None)\n",
    "keypoints2, descriptors2 = orb.detectAndCompute(tgt_img_ds, None)\n",
    "\n",
    "matcher = cv.DescriptorMatcher_create(cv.DESCRIPTOR_MATCHER_BRUTEFORCE_HAMMING)\n",
    "matches = matcher.match(descriptors1, descriptors2, None)\n",
    "\n",
    "matches = sorted(matches, key=lambda x: x.distance)\n",
    "\n",
    "numGoodMatches = int(len(matches) * GOOD_MATCH_PERCENT)\n",
    "matches = matches[:numGoodMatches]\n",
    "\n",
    "imMatches = cv.drawMatches(\n",
    "    ref_img_ds, keypoints1, tgt_img_ds, keypoints2, matches, None\n",
    ")\n",
    "cv.imwrite(\"matches.jpg\", imMatches)\n",
    "\n",
    "# Extract location of good matches\n",
    "points1 = np.zeros((len(matches), 2), dtype=np.float32)\n",
    "points2 = np.zeros((len(matches), 2), dtype=np.float32)\n",
    "\n",
    "for i, match in enumerate(matches):\n",
    "    points1[i, :] = keypoints1[match.queryIdx].pt\n",
    "    points2[i, :] = keypoints2[match.trainIdx].pt\n",
    "\n",
    "# Find homography\n",
    "h, mask = cv.findHomography(points1, points2, cv.RANSAC)\n",
    "\n",
    "# Use homography\n",
    "height, width = ref_img_ds.shape\n",
    "tgt_aligned_ds = cv.warpPerspective(\n",
    "    tgt_img_ds, h, (width, height), flags=cv.INTER_LINEAR + cv.WARP_INVERSE_MAP\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, axes = plt.subplots(1, 3, figsize=(15, 10))\n",
    "axes[0].imshow(ref_img_ds, cmap=\"jet\")\n",
    "axes[0].set_xlabel(\"Reference\")\n",
    "axes[1].imshow(tgt_img_ds, cmap=\"jet\")\n",
    "axes[1].set_xlabel(f\"Target, ssim:{np.round(ssim(ref_img_ds, tgt_img_ds), 3)}\")\n",
    "axes[2].imshow(tgt_aligned_ds, cmap=\"jet\")\n",
    "axes[2].set_xlabel(f\"Registered, ssim:{np.round(ssim(ref_img_ds, tgt_aligned_ds), 3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAX_FEATURES = 500\n",
    "# GOOD_MATCH_PERCENT = 0.15\n",
    "# orb = cv.ORB_create(MAX_FEATURES)\n",
    "# keypoints1, descriptors1 = orb.detectAndCompute(ref_img, None)\n",
    "# keypoints2, descriptors2 = orb.detectAndCompute(tgt_img, None)\n",
    "\n",
    "# matcher = cv.DescriptorMatcher_create(cv.DESCRIPTOR_MATCHER_BRUTEFORCE_HAMMING)\n",
    "# matches = matcher.match(descriptors1, descriptors2, None)\n",
    "\n",
    "# matches = sorted(matches, key=lambda x:x.distance)\n",
    "\n",
    "# numGoodMatches = int(len(matches) * GOOD_MATCH_PERCENT)\n",
    "# matches = matches[:numGoodMatches]\n",
    "\n",
    "# imMatches = cv.drawMatches(ref_img, keypoints1, tgt_img, keypoints2, matches, None)\n",
    "# cv.imwrite(\"matches.jpg\", imMatches)\n",
    "\n",
    "# # Extract location of good matches\n",
    "# points1 = np.zeros((len(matches), 2), dtype=np.float32)\n",
    "# points2 = np.zeros((len(matches), 2), dtype=np.float32)\n",
    "\n",
    "# for i, match in enumerate(matches):\n",
    "#     points1[i, :] = keypoints1[match.queryIdx].pt\n",
    "#     points2[i, :] = keypoints2[match.trainIdx].pt\n",
    "\n",
    "# # Find homography\n",
    "# h, mask = cv.findHomography(points1, points2, cv.RANSAC)\n",
    "\n",
    "# # Use homography\n",
    "# height, width = ref_img.shape\n",
    "# tgt_aligned = cv.warpPerspective(tgt_img, h, (width, height), flags=cv.INTER_LINEAR + cv.WARP_INVERSE_MAP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _, axes = plt.subplots(1, 3, figsize=(15, 10))\n",
    "# axes[0].imshow(ref_img, cmap=\"jet\")\n",
    "# axes[0].set_xlabel(\"Reference\")\n",
    "# axes[1].imshow(tgt_img, cmap=\"jet\")\n",
    "# axes[1].set_xlabel(f\"Target, ssim:{np.round(ssim(ref_img, tgt_img), 3)}\")\n",
    "# axes[2].imshow(tgt_aligned, cmap=\"jet\")\n",
    "# axes[2].set_xlabel(f\"Registered, ssim:{np.round(ssim(ref_img, tgt_aligned), 3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Coregister S1 SLC (RTC) and S2 L1C "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_scene = \"../data/outputs/AROSICS/L1C_SLC_AU_pair/ref.tif\"\n",
    "tgt_scene = \"../data/outputs/AROSICS/L1C_SLC_AU_pair/tgt.tif\"\n",
    "\n",
    "downsample_dataset(ref_scene, 0.1, \"../data/outputs/OpenCV/L1C_SLC_AU/ref_ds.tif\")\n",
    "_ = downsample_dataset(tgt_scene, 0.1, \"../data/outputs/OpenCV/L1C_SLC_AU/tgt_ds.tif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_scene = \"../data/outputs/OpenCV/L1C_SLC_AU/ref_ds.tif\"\n",
    "tgt_scene = \"../data/outputs/OpenCV/L1C_SLC_AU/tgt_ds.tif\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coords, warps = find_overlap(ref_scene, tgt_scene, True, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_img = cv.cvtColor(\n",
    "    flip_img(rasterio.open(ref_scene).read().copy()), cv.COLOR_BGR2GRAY\n",
    ")\n",
    "tgt_img = cv.cvtColor(\n",
    "    flip_img(rasterio.open(tgt_scene).read().copy()), cv.COLOR_BGR2GRAY\n",
    ")\n",
    "\n",
    "ref_warp = cv.cvtColor(warps[2], cv.COLOR_BGR2GRAY)\n",
    "tgt_warp = cv.cvtColor(warps[3], cv.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ECC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warp_mode = cv.MOTION_HOMOGRAPHY\n",
    "warp_matrix = np.eye(3, 3, dtype=np.float32)\n",
    "number_of_iterations = 5000\n",
    "termination_eps = 1e-5\n",
    "\n",
    "criteria = (\n",
    "    cv.TERM_CRITERIA_EPS | cv.TERM_CRITERIA_COUNT,\n",
    "    number_of_iterations,\n",
    "    termination_eps,\n",
    ")\n",
    "(cc, warp_matrix) = cv.findTransformECC(\n",
    "    ref_warp, tgt_warp, warp_matrix, warp_mode, criteria\n",
    ")\n",
    "\n",
    "tgt_aligned_homography_ds = cv.warpPerspective(\n",
    "    tgt_warp,\n",
    "    warp_matrix,\n",
    "    (tgt_warp.shape[1], tgt_warp.shape[0]),\n",
    "    flags=cv.INTER_LINEAR + cv.WARP_INVERSE_MAP,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warp_mode = cv.MOTION_AFFINE\n",
    "warp_matrix = np.eye(2, 3, dtype=np.float32)\n",
    "number_of_iterations = 5000\n",
    "termination_eps = 1e-5\n",
    "\n",
    "criteria = (\n",
    "    cv.TERM_CRITERIA_EPS | cv.TERM_CRITERIA_COUNT,\n",
    "    number_of_iterations,\n",
    "    termination_eps,\n",
    ")\n",
    "(cc, warp_matrix) = cv.findTransformECC(\n",
    "    ref_warp, tgt_warp, warp_matrix, warp_mode, criteria\n",
    ")\n",
    "\n",
    "tgt_aligned_affine_ds = cv.warpAffine(\n",
    "    tgt_warp,\n",
    "    warp_matrix,\n",
    "    (tgt_warp.shape[1], tgt_warp.shape[0]),\n",
    "    flags=cv.INTER_LINEAR + cv.WARP_INVERSE_MAP,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, axes = plt.subplots(1, 3, figsize=(15, 10))\n",
    "axes[0].imshow(simple_mosaic([ref_warp, tgt_warp]), cmap=\"gray\")\n",
    "axes[0].set_xlabel(f\"Original, ssim:{np.round(ssim(ref_warp, tgt_warp), 3)}\")\n",
    "axes[1].imshow(simple_mosaic([ref_warp, tgt_aligned_homography_ds]), cmap=\"gray\")\n",
    "axes[1].set_xlabel(\n",
    "    f\"Registered (hompgraphy), ssim:{np.round(ssim(ref_warp, tgt_aligned_homography_ds), 3)}\"\n",
    ")\n",
    "axes[2].imshow(simple_mosaic([ref_warp, tgt_aligned_affine_ds]), cmap=\"gray\")\n",
    "axes[2].set_xlabel(\n",
    "    f\"Registered (affine), ssim:{np.round(ssim(ref_warp, tgt_aligned_affine_ds), 3)}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Phase correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# window = cv.createHanningWindow((ref_warp.shape[1], ref_warp.shape[0]), cv.CV_32F)\n",
    "window = None\n",
    "((shift_x, shift_y), phase_corr_score) = cv.phaseCorrelate(\n",
    "    np.float32(tgt_warp), np.float32(ref_warp), window\n",
    ")\n",
    "tgt_shifted = warp_affine_dataset(\n",
    "    tgt_warp, translation_x=shift_x, translation_y=shift_y\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, axes = plt.subplots(1, 2, figsize=(15, 10))\n",
    "axes[0].imshow(simple_mosaic([ref_warp, tgt_warp]), cmap=\"gray\")\n",
    "axes[0].set_xlabel(\n",
    "    f\"Original, ssim:{np.round(ssim(ref_warp, tgt_warp), 3)}, mse:{np.round(mse(ref_warp, tgt_warp), 3)}\"\n",
    ")\n",
    "axes[1].imshow(simple_mosaic([ref_warp, tgt_shifted]), cmap=\"gray\")\n",
    "axes[1].set_xlabel(\n",
    "    f\"Registered, ssim:{np.round(ssim(ref_warp, tgt_shifted), 3)}, mse:{np.round(mse(ref_warp, tgt_shifted), 3)}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Optical Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params for ShiTomasi corner detection\n",
    "feature_params = dict(\n",
    "    maxCorners=100,\n",
    "    qualityLevel=0.3,\n",
    "    minDistance=7,\n",
    "    blockSize=7,\n",
    ")\n",
    "\n",
    "# Parameters for lucas kanade optical flow\n",
    "number_of_iterations = 10\n",
    "termination_eps = 1e-5\n",
    "lk_params = dict(\n",
    "    winSize=(15, 15),\n",
    "    maxLevel=2,\n",
    "    criteria=(\n",
    "        cv.TERM_CRITERIA_EPS | cv.TERM_CRITERIA_COUNT,\n",
    "        number_of_iterations,\n",
    "        termination_eps,\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p0 = cv.goodFeaturesToTrack(ref_warp, mask=None, **feature_params)\n",
    "p1, st, err = cv.calcOpticalFlowPyrLK(ref_warp, tgt_warp, p0, None, **lk_params)\n",
    "ref_good = p0[st == 1].astype(np.float32)\n",
    "tgt_good = p1[st == 1].astype(np.float32)\n",
    "warp_matrix = cv.findHomography(ref_good, tgt_good)[0]\n",
    "tgt_aligned_ds = cv.warpPerspective(\n",
    "    tgt_warp,\n",
    "    warp_matrix,\n",
    "    (tgt_warp.shape[1], tgt_warp.shape[0]),\n",
    "    flags=cv.INTER_LINEAR + cv.WARP_INVERSE_MAP,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, axes = plt.subplots(1, 2, figsize=(15, 10))\n",
    "axes[0].imshow(simple_mosaic([ref_warp, tgt_warp]), cmap=\"gray\")\n",
    "axes[0].set_xlabel(f\"Original, ssim:{np.round(ssim(ref_warp, tgt_warp), 3)}\")\n",
    "axes[1].imshow(simple_mosaic([ref_warp, tgt_aligned_ds]), cmap=\"gray\")\n",
    "axes[1].set_xlabel(f\"Registered, ssim:{np.round(ssim(ref_warp, tgt_aligned_ds), 3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Feature matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_FEATURES = 500\n",
    "GOOD_MATCH_PERCENT = 0.15\n",
    "orb = cv.ORB_create(MAX_FEATURES)\n",
    "keypoints1, descriptors1 = orb.detectAndCompute(ref_warp, None)\n",
    "keypoints2, descriptors2 = orb.detectAndCompute(tgt_warp, None)\n",
    "\n",
    "matcher = cv.DescriptorMatcher_create(cv.DESCRIPTOR_MATCHER_BRUTEFORCE_HAMMING)\n",
    "matches = matcher.match(descriptors1, descriptors2, None)\n",
    "\n",
    "matches = sorted(matches, key=lambda x: x.distance)\n",
    "\n",
    "numGoodMatches = int(len(matches) * GOOD_MATCH_PERCENT)\n",
    "matches = matches[:numGoodMatches]\n",
    "\n",
    "imMatches = cv.drawMatches(ref_warp, keypoints1, tgt_warp, keypoints2, matches, None)\n",
    "cv.imwrite(\"matches.jpg\", imMatches)\n",
    "\n",
    "# Extract location of good matches\n",
    "points1 = np.zeros((len(matches), 2), dtype=np.float32)\n",
    "points2 = np.zeros((len(matches), 2), dtype=np.float32)\n",
    "\n",
    "for i, match in enumerate(matches):\n",
    "    points1[i, :] = keypoints1[match.queryIdx].pt\n",
    "    points2[i, :] = keypoints2[match.trainIdx].pt\n",
    "\n",
    "# Find homography\n",
    "h, mask = cv.findHomography(points1, points2, cv.RANSAC)\n",
    "\n",
    "# Use homography\n",
    "height, width = ref_warp.shape\n",
    "tgt_aligned_ds = cv.warpPerspective(\n",
    "    tgt_warp, h, (width, height), flags=cv.INTER_LINEAR + cv.WARP_INVERSE_MAP\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, axes = plt.subplots(1, 2, figsize=(15, 10))\n",
    "axes[0].imshow(simple_mosaic([ref_warp, tgt_warp]), cmap=\"gray\")\n",
    "axes[0].set_xlabel(f\"Original, ssim:{np.round(ssim(ref_warp, tgt_warp), 3)}\")\n",
    "axes[1].imshow(simple_mosaic([ref_warp, tgt_aligned_ds]), cmap=\"gray\")\n",
    "axes[1].set_xlabel(f\"Registered, ssim:{np.round(ssim(ref_warp, tgt_aligned_ds), 3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test two S2 L2A images for AN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id = list(s2_an_l2a_dict.keys())[1]\n",
    "s2_an_l2a_secne_files = s2_an_l2a_dict[id]\n",
    "\n",
    "# get the Jan 2023 and Dec 2024 files\n",
    "s2_an_l2a_secne_pair = [s2_an_l2a_secne_files[10], s2_an_l2a_secne_files[-1]]\n",
    "\n",
    "shutil.rmtree(f\"../data/inputs/{id}/\", ignore_errors=True)\n",
    "for i, zip_file_path in enumerate(s2_an_l2a_secne_pair):\n",
    "    with ZipFile(zip_file_path) as f:\n",
    "        f.extractall(f\"../data/inputs/{id}/sub{i}\")\n",
    "ref_image_dir = os.path.join(\"../data/inputs/\", id, f\"sub{0}\")\n",
    "ref_tci_files = list(\n",
    "    filter(\n",
    "        lambda f: \"TCI\" in f,\n",
    "        glob.glob(f\"{ref_image_dir}/*/GRANULE/*/IMG_DATA/**\", recursive=True),\n",
    "    )\n",
    ")\n",
    "ref_tci_files = list(filter(lambda f: \"L2A\" in f, ref_tci_files))\n",
    "if len(ref_tci_files) > 1:\n",
    "    ref_image = [f for f in ref_tci_files if f.endswith(\"_10m.jp2\")][0]\n",
    "else:\n",
    "    ref_image = ref_tci_files[0]\n",
    "\n",
    "tgt_image_dir = os.path.join(\"../data/inputs/\", id, f\"sub{1}\")\n",
    "tgt_tci_files = list(\n",
    "    filter(\n",
    "        lambda f: \"TCI\" in f,\n",
    "        glob.glob(f\"{tgt_image_dir}/*/GRANULE/*/IMG_DATA/**\", recursive=True),\n",
    "    )\n",
    ")\n",
    "tgt_tci_files = list(filter(lambda f: \"L2A\" in f, tgt_tci_files))\n",
    "if len(tgt_tci_files) > 1:\n",
    "    tgt_image = [f for f in tgt_tci_files if f.endswith(\"_10m.jp2\")][0]\n",
    "else:\n",
    "    tgt_image = tgt_tci_files[0]\n",
    "\n",
    "_, (axb, axt) = plt.subplots(1, 2, figsize=(10, 20))\n",
    "show(downsample_dataset(ref_image, 0.1)[0], ax=axb, title=\"Reference scene\")\n",
    "show(downsample_dataset(tgt_image, 0.1)[0], ax=axt, title=\"Target scene\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_image_ds = os.path.join(ref_image_dir, \"ref_ds.tif\")\n",
    "downsample_dataset(ref_image, 0.1, ref_image_ds)\n",
    "tgt_image_ds = os.path.join(tgt_image_dir, \"tgt_ds.tif\")\n",
    "_ = downsample_dataset(tgt_image, 0.1, tgt_image_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_img = cv.cvtColor(\n",
    "    flip_img(rasterio.open(ref_image).read().copy()), cv.COLOR_BGR2GRAY\n",
    ")\n",
    "tgt_img = cv.cvtColor(\n",
    "    flip_img(rasterio.open(tgt_image).read().copy()), cv.COLOR_BGR2GRAY\n",
    ")\n",
    "ref_img_ds = cv.cvtColor(\n",
    "    flip_img(rasterio.open(ref_image_ds).read().copy()), cv.COLOR_BGR2GRAY\n",
    ")\n",
    "tgt_img_ds = cv.cvtColor(\n",
    "    flip_img(rasterio.open(tgt_image_ds).read().copy()), cv.COLOR_BGR2GRAY\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ECC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warp_mode = cv.MOTION_HOMOGRAPHY\n",
    "warp_matrix = np.eye(3, 3, dtype=np.float32)\n",
    "number_of_iterations = 5000\n",
    "termination_eps = 1e-5\n",
    "\n",
    "criteria = (\n",
    "    cv.TERM_CRITERIA_EPS | cv.TERM_CRITERIA_COUNT,\n",
    "    number_of_iterations,\n",
    "    termination_eps,\n",
    ")\n",
    "(cc, warp_matrix) = cv.findTransformECC(\n",
    "    ref_img_ds, tgt_img_ds, warp_matrix, warp_mode, criteria\n",
    ")\n",
    "\n",
    "tgt_aligned_homography_ds = cv.warpPerspective(\n",
    "    tgt_img_ds,\n",
    "    warp_matrix,\n",
    "    (tgt_img_ds.shape[1], tgt_img_ds.shape[0]),\n",
    "    flags=cv.INTER_LINEAR + cv.WARP_INVERSE_MAP,\n",
    ")\n",
    "\n",
    "# tgt_aligned_homography = cv.warpPerspective(\n",
    "#     tgt_img,\n",
    "#     warp_matrix,\n",
    "#     (tgt_img.shape[1], tgt_img.shape[0]),\n",
    "#     flags=cv.INTER_LINEAR + cv.WARP_INVERSE_MAP,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warp_mode = cv.MOTION_AFFINE\n",
    "warp_matrix = np.eye(2, 3, dtype=np.float32)\n",
    "number_of_iterations = 5000\n",
    "termination_eps = 1e-5\n",
    "\n",
    "criteria = (\n",
    "    cv.TERM_CRITERIA_EPS | cv.TERM_CRITERIA_COUNT,\n",
    "    number_of_iterations,\n",
    "    termination_eps,\n",
    ")\n",
    "(cc, warp_matrix) = cv.findTransformECC(\n",
    "    ref_img_ds, tgt_img_ds, warp_matrix, warp_mode, criteria\n",
    ")\n",
    "\n",
    "tgt_aligned_affine_ds = cv.warpAffine(\n",
    "    tgt_img_ds,\n",
    "    warp_matrix,\n",
    "    (tgt_img_ds.shape[1], tgt_img_ds.shape[0]),\n",
    "    flags=cv.INTER_LINEAR + cv.WARP_INVERSE_MAP,\n",
    ")\n",
    "\n",
    "# tgt_aligned_affine = cv.warpAffine(\n",
    "#     tgt_img,\n",
    "#     warp_matrix,\n",
    "#     (tgt_img.shape[1], tgt_img.shape[0]),\n",
    "#     flags=cv.INTER_LINEAR + cv.WARP_INVERSE_MAP,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, axes = plt.subplots(1, 4, figsize=(15, 10))\n",
    "axes[0].imshow(ref_img_ds, cmap=\"jet\")\n",
    "axes[0].set_xlabel(\"Reference\")\n",
    "axes[1].imshow(tgt_img_ds, cmap=\"jet\")\n",
    "axes[1].set_xlabel(f\"Target, ssim:{np.round(ssim(ref_img_ds, tgt_img_ds), 3)}\")\n",
    "axes[2].imshow(tgt_aligned_homography_ds, cmap=\"jet\")\n",
    "axes[2].set_xlabel(\n",
    "    f\"Registered (hompgraphy), ssim:{np.round(ssim(ref_img_ds, tgt_aligned_homography_ds), 3)}\"\n",
    ")\n",
    "axes[3].imshow(tgt_aligned_affine_ds, cmap=\"jet\")\n",
    "axes[3].set_xlabel(\n",
    "    f\"Registered (affine), ssim:{np.round(ssim(ref_img_ds, tgt_aligned_affine_ds), 3)}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _, axes = plt.subplots(1, 4, figsize=(15, 10))\n",
    "# axes[0].imshow(ref_img, cmap=\"jet\")\n",
    "# axes[0].set_xlabel(\"Reference\")\n",
    "# axes[1].imshow(tgt_img, cmap=\"jet\")\n",
    "# axes[1].set_xlabel(f\"Target, ssim:{np.round(ssim(ref_img, tgt_img), 3)}\")\n",
    "# axes[2].imshow(tgt_aligned_homography, cmap=\"jet\")\n",
    "# axes[2].set_xlabel(\n",
    "#     f\"Registered (hompgraphy), ssim:{np.round(ssim(ref_img, tgt_aligned_homography), 3)}\"\n",
    "# )\n",
    "# axes[3].imshow(tgt_aligned_affine, cmap=\"jet\")\n",
    "# axes[3].set_xlabel(\n",
    "#     f\"Registered (affine), ssim:{np.round(ssim(ref_img, tgt_aligned_affine), 3)}\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### phase correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window = cv.createHanningWindow(ref_img_ds.shape, cv.CV_32F)\n",
    "# window = None\n",
    "((shift_x, shift_y), phase_corr_score) = cv.phaseCorrelate(\n",
    "    np.float32(tgt_img_ds), np.float32(ref_img_ds), window\n",
    ")\n",
    "tgt_shifted_ds = warp_affine_dataset(\n",
    "    tgt_img_ds, translation_x=shift_x, translation_y=shift_y\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, axes = plt.subplots(1, 3, figsize=(15, 10))\n",
    "axes[0].imshow(ref_img_ds, cmap=\"jet\")\n",
    "axes[0].set_xlabel(\"Reference\")\n",
    "axes[1].imshow(tgt_img_ds, cmap=\"jet\")\n",
    "axes[1].set_xlabel(f\"Target, ssim:{np.round(ssim(ref_img_ds, tgt_img_ds), 3)}\")\n",
    "axes[2].imshow(tgt_shifted_ds, cmap=\"jet\")\n",
    "axes[2].set_xlabel(f\"Registered, ssim:{np.round(ssim(ref_img_ds, tgt_shifted_ds), 3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# window = cv.createHanningWindow(ref_img.shape, cv.CV_32F)\n",
    "window = None\n",
    "((shift_x, shift_y), phase_corr_score) = cv.phaseCorrelate(\n",
    "    np.float32(tgt_img), np.float32(ref_img), window\n",
    ")\n",
    "tgt_shifted = warp_affine_dataset(tgt_img, translation_x=shift_x, translation_y=shift_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, axes = plt.subplots(1, 3, figsize=(15, 10))\n",
    "axes[0].imshow(ref_img, cmap=\"jet\")\n",
    "axes[0].set_xlabel(\"Reference\")\n",
    "axes[1].imshow(tgt_img, cmap=\"jet\")\n",
    "axes[1].set_xlabel(f\"Target, ssim:{np.round(ssim(ref_img, tgt_img), 3)}\")\n",
    "axes[2].imshow(tgt_shifted, cmap=\"jet\")\n",
    "axes[2].set_xlabel(f\"Registered, ssim:{np.round(ssim(ref_img, tgt_shifted), 3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### optical flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params for ShiTomasi corner detection\n",
    "feature_params = dict(\n",
    "    maxCorners=100,\n",
    "    qualityLevel=0.3,\n",
    "    minDistance=7,\n",
    "    blockSize=7,\n",
    ")\n",
    "\n",
    "# Parameters for lucas kanade optical flow\n",
    "number_of_iterations = 10\n",
    "termination_eps = 1e-5\n",
    "lk_params = dict(\n",
    "    winSize=(15, 15),\n",
    "    maxLevel=2,\n",
    "    criteria=(\n",
    "        cv.TERM_CRITERIA_EPS | cv.TERM_CRITERIA_COUNT,\n",
    "        number_of_iterations,\n",
    "        termination_eps,\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p0 = cv.goodFeaturesToTrack(ref_img_ds, mask=None, **feature_params)\n",
    "p1, st, err = cv.calcOpticalFlowPyrLK(ref_img_ds, tgt_img_ds, p0, None, **lk_params)\n",
    "ref_good = p0[st == 1].astype(np.float32)\n",
    "tgt_good = p1[st == 1].astype(np.float32)\n",
    "warp_matrix = cv.findHomography(ref_good, tgt_good, cv.RANSAC)[0]\n",
    "tgt_aligned_ds = cv.warpPerspective(\n",
    "    tgt_img_ds,\n",
    "    warp_matrix,\n",
    "    (tgt_img_ds.shape[1], tgt_img_ds.shape[0]),\n",
    "    flags=cv.INTER_LINEAR + cv.WARP_INVERSE_MAP,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, axes = plt.subplots(1, 3, figsize=(15, 10))\n",
    "axes[0].imshow(ref_img_ds, cmap=\"jet\")\n",
    "axes[0].set_xlabel(\"Reference\")\n",
    "axes[1].imshow(tgt_img_ds, cmap=\"jet\")\n",
    "axes[1].set_xlabel(f\"Target, ssim:{np.round(ssim(ref_img_ds, tgt_img_ds), 3)}\")\n",
    "axes[2].imshow(tgt_aligned_ds, cmap=\"jet\")\n",
    "axes[2].set_xlabel(f\"Registered, ssim:{np.round(ssim(ref_img_ds, tgt_aligned_ds), 3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### feature matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_FEATURES = 500\n",
    "GOOD_MATCH_PERCENT = 0.15\n",
    "orb = cv.ORB_create(MAX_FEATURES)\n",
    "keypoints1, descriptors1 = orb.detectAndCompute(ref_img_ds, None)\n",
    "keypoints2, descriptors2 = orb.detectAndCompute(tgt_img_ds, None)\n",
    "\n",
    "matcher = cv.DescriptorMatcher_create(cv.DESCRIPTOR_MATCHER_BRUTEFORCE_HAMMING)\n",
    "matches = matcher.match(descriptors1, descriptors2, None)\n",
    "\n",
    "matches = sorted(matches, key=lambda x: x.distance)\n",
    "\n",
    "numGoodMatches = int(len(matches) * GOOD_MATCH_PERCENT)\n",
    "matches = matches[:numGoodMatches]\n",
    "\n",
    "imMatches = cv.drawMatches(\n",
    "    ref_img_ds, keypoints1, tgt_img_ds, keypoints2, matches, None\n",
    ")\n",
    "cv.imwrite(\"matches.jpg\", imMatches)\n",
    "\n",
    "# Extract location of good matches\n",
    "points1 = np.zeros((len(matches), 2), dtype=np.float32)\n",
    "points2 = np.zeros((len(matches), 2), dtype=np.float32)\n",
    "\n",
    "for i, match in enumerate(matches):\n",
    "    points1[i, :] = keypoints1[match.queryIdx].pt\n",
    "    points2[i, :] = keypoints2[match.trainIdx].pt\n",
    "\n",
    "# Find homography\n",
    "# h, mask = cv.findHomography(points1, points2, cv.RANSAC)\n",
    "h, _ = cv.estimateAffine2D(points1, points2)\n",
    "\n",
    "# Use homography\n",
    "height, width = ref_img_ds.shape\n",
    "# tgt_aligned_ds = cv.warpPerspective(\n",
    "tgt_aligned_ds = cv.warpAffine(\n",
    "    tgt_img_ds, h, (width, height), flags=cv.INTER_LINEAR + cv.WARP_INVERSE_MAP\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, axes = plt.subplots(1, 3, figsize=(15, 10))\n",
    "axes[0].imshow(ref_img_ds, cmap=\"jet\")\n",
    "axes[0].set_xlabel(\"Reference\")\n",
    "axes[1].imshow(tgt_img_ds, cmap=\"jet\")\n",
    "axes[1].set_xlabel(f\"Target, ssim:{np.round(ssim(ref_img_ds, tgt_img_ds), 3)}\")\n",
    "axes[2].imshow(tgt_aligned_ds, cmap=\"jet\")\n",
    "axes[2].set_xlabel(f\"Registered, ssim:{np.round(ssim(ref_img_ds, tgt_aligned_ds), 3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### S1 RTC (SLC) Pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_scene = \"../data/asf/SLC_Pair/S1A_IW_20230130T192218_DVP_RTC20_G_gpufed_B6D4.zip\"\n",
    "tgt_scene = \"../data/asf/SLC_Pair/S1A_IW_20241209T191428_DVP_RTC20_G_gpufed_8B70.zip\"\n",
    "shutil.rmtree(f\"../data/inputs/25S150E-30S155E/\", ignore_errors=True)\n",
    "\n",
    "with ZipFile(ref_scene) as f:\n",
    "    f.extractall(f\"../data/inputs/25S150E-30S155E/ref\")\n",
    "ref_image_dir = os.path.join(\"../data/inputs/\", \"25S150E-30S155E\", \"ref\")\n",
    "\n",
    "with ZipFile(tgt_scene) as f:\n",
    "    f.extractall(f\"../data/inputs/25S150E-30S155E/tgt\")\n",
    "tgt_image_dir = os.path.join(\"../data/inputs/\", \"25S150E-30S155E\", \"tgt\")\n",
    "\n",
    "ref_image = list(\n",
    "    filter(\n",
    "        lambda f: (\"_rgb\" in f) and f.endswith(\".tif\"),\n",
    "        glob.glob(f\"{ref_image_dir}/*/*\"),\n",
    "    )\n",
    ")[0]\n",
    "tgt_image = list(\n",
    "    filter(\n",
    "        lambda f: (\"_rgb\" in f) and f.endswith(\".tif\"),\n",
    "        glob.glob(f\"{tgt_image_dir}/*/*\"),\n",
    "    )\n",
    ")[0]\n",
    "\n",
    "_, (axb, axt) = plt.subplots(1, 2, figsize=(10, 20))\n",
    "show(downsample_dataset(ref_image, 0.1)[0], ax=axb, title=\"Reference scene\")\n",
    "show(downsample_dataset(tgt_image, 0.1)[0], ax=axt, title=\"Target scene\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coords, warps = find_overlap(ref_image, tgt_image, True, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_img = cv.cvtColor(\n",
    "    flip_img(rasterio.open(ref_image).read().copy()), cv.COLOR_BGR2GRAY\n",
    ")\n",
    "tgt_img = cv.cvtColor(\n",
    "    flip_img(rasterio.open(tgt_image).read().copy()), cv.COLOR_BGR2GRAY\n",
    ")\n",
    "\n",
    "ref_warp = cv.cvtColor(warps[2], cv.COLOR_BGR2GRAY)\n",
    "tgt_warp = cv.cvtColor(warps[3], cv.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ECC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does not work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Phase correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# window = cv.createHanningWindow((ref_warp.shape[1], ref_warp.shape[0]), cv.CV_32F)\n",
    "window = None\n",
    "((shift_x, shift_y), phase_corr_score) = cv.phaseCorrelate(\n",
    "    np.float32(tgt_warp), np.float32(ref_warp), window\n",
    ")\n",
    "tgt_shifted = warp_affine_dataset(\n",
    "    tgt_warp, translation_x=shift_x, translation_y=shift_y\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, axes = plt.subplots(1, 2, figsize=(15, 10))\n",
    "axes[0].imshow(simple_mosaic([ref_warp, tgt_warp]), cmap=\"gray\")\n",
    "axes[0].set_xlabel(f\"Original, ssim:{np.round(ssim(ref_warp, tgt_warp), 3)}\")\n",
    "axes[1].imshow(simple_mosaic([ref_warp, tgt_shifted]), cmap=\"gray\")\n",
    "axes[1].set_xlabel(f\"Registered, ssim:{np.round(ssim(ref_warp, tgt_shifted), 3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### optical flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params for ShiTomasi corner detection\n",
    "feature_params = dict(\n",
    "    maxCorners=100,\n",
    "    qualityLevel=0.3,\n",
    "    minDistance=7,\n",
    "    blockSize=7,\n",
    ")\n",
    "\n",
    "# Parameters for lucas kanade optical flow\n",
    "number_of_iterations = 10\n",
    "termination_eps = 1e-5\n",
    "lk_params = dict(\n",
    "    winSize=(15, 15),\n",
    "    maxLevel=2,\n",
    "    criteria=(\n",
    "        cv.TERM_CRITERIA_EPS | cv.TERM_CRITERIA_COUNT,\n",
    "        number_of_iterations,\n",
    "        termination_eps,\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p0 = cv.goodFeaturesToTrack(ref_warp, mask=None, **feature_params)\n",
    "p1, st, err = cv.calcOpticalFlowPyrLK(ref_warp, tgt_warp, p0, None, **lk_params)\n",
    "ref_good = p0[st == 1].astype(np.float32)\n",
    "tgt_good = p1[st == 1].astype(np.float32)\n",
    "warp_matrix = cv.findHomography(ref_good, tgt_good)[0]\n",
    "tgt_aligned_ds = cv.warpPerspective(\n",
    "    tgt_warp,\n",
    "    warp_matrix,\n",
    "    (tgt_warp.shape[1], tgt_warp.shape[0]),\n",
    "    flags=cv.INTER_LINEAR + cv.WARP_INVERSE_MAP,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, axes = plt.subplots(1, 2, figsize=(15, 10))\n",
    "axes[0].imshow(simple_mosaic([ref_warp, tgt_warp]), cmap=\"gray\")\n",
    "axes[0].set_xlabel(f\"Original, ssim:{np.round(ssim(ref_warp, tgt_warp), 3)}\")\n",
    "axes[1].imshow(simple_mosaic([ref_warp, tgt_aligned_ds]), cmap=\"gray\")\n",
    "axes[1].set_xlabel(f\"Registered, ssim:{np.round(ssim(ref_warp, tgt_aligned_ds), 3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### feature matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_FEATURES = 500\n",
    "GOOD_MATCH_PERCENT = 0.15\n",
    "orb = cv.ORB_create(MAX_FEATURES)\n",
    "keypoints1, descriptors1 = orb.detectAndCompute(ref_warp, None)\n",
    "keypoints2, descriptors2 = orb.detectAndCompute(tgt_warp, None)\n",
    "\n",
    "matcher = cv.DescriptorMatcher_create(cv.DESCRIPTOR_MATCHER_BRUTEFORCE_HAMMING)\n",
    "matches = matcher.match(descriptors1, descriptors2, None)\n",
    "\n",
    "matches = sorted(matches, key=lambda x: x.distance)\n",
    "\n",
    "numGoodMatches = int(len(matches) * GOOD_MATCH_PERCENT)\n",
    "matches = matches[:numGoodMatches]\n",
    "\n",
    "imMatches = cv.drawMatches(ref_warp, keypoints1, tgt_warp, keypoints2, matches, None)\n",
    "cv.imwrite(\"matches.jpg\", imMatches)\n",
    "\n",
    "# Extract location of good matches\n",
    "points1 = np.zeros((len(matches), 2), dtype=np.float32)\n",
    "points2 = np.zeros((len(matches), 2), dtype=np.float32)\n",
    "\n",
    "for i, match in enumerate(matches):\n",
    "    points1[i, :] = keypoints1[match.queryIdx].pt\n",
    "    points2[i, :] = keypoints2[match.trainIdx].pt\n",
    "\n",
    "# Find homography\n",
    "h, mask = cv.findHomography(points1, points2, cv.RANSAC)\n",
    "\n",
    "# Use homography\n",
    "height, width = ref_warp.shape\n",
    "tgt_aligned_ds = cv.warpPerspective(\n",
    "    tgt_warp, h, (width, height), flags=cv.INTER_LINEAR + cv.WARP_INVERSE_MAP\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, axes = plt.subplots(1, 2, figsize=(15, 10))\n",
    "axes[0].imshow(simple_mosaic([ref_warp, tgt_warp]), cmap=\"gray\")\n",
    "axes[0].set_xlabel(f\"Original, ssim:{np.round(ssim(ref_warp, tgt_warp), 3)}\")\n",
    "axes[1].imshow(simple_mosaic([ref_warp, tgt_aligned_ds]), cmap=\"gray\")\n",
    "axes[1].set_xlabel(f\"Registered, ssim:{np.round(ssim(ref_warp, tgt_aligned_ds), 3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### S2 AN Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2_an_l1c_r031_dict = get_scenes_dict(s2_an_df, [\"L1C\", \"R031\"], False)\n",
    "id = list(s2_an_l1c_r031_dict.keys())[0]\n",
    "\n",
    "tdf = s2_an_df[s2_an_df.ID == id]\n",
    "tdf = tdf[tdf.Path.apply(lambda x: \"L1C\" in x)]\n",
    "tdf = tdf[tdf.Path.apply(lambda x: \"N0511_R031\" in x)]\n",
    "s2_an_l1c_secne_files = list(tdf.Path)\n",
    "\n",
    "shutil.rmtree(f\"../data/inputs/{id}/\", ignore_errors=True)\n",
    "\n",
    "ref_id = 4\n",
    "ref_scene = s2_an_l1c_secne_files[ref_id]\n",
    "with ZipFile(ref_scene) as f:\n",
    "    f.extractall(f\"../data/inputs/{id}/ref\")\n",
    "ref_image_dir = os.path.join(\"../data/inputs/\", id, \"ref\")\n",
    "ref_tci_files = list(\n",
    "    filter(\n",
    "        lambda f: \"TCI\" in f,\n",
    "        glob.glob(f\"{ref_image_dir}/*/GRANULE/*/IMG_DATA/**\", recursive=True),\n",
    "    )\n",
    ")\n",
    "ref_tci_files = list(filter(lambda f: \"L1C\" in f, ref_tci_files))\n",
    "if len(ref_tci_files) > 1:\n",
    "    ref_image = [f for f in ref_tci_files if f.endswith(\"_10m.jp2\")][0]\n",
    "else:\n",
    "    ref_image = ref_tci_files[0]\n",
    "\n",
    "downsample_dataset(ref_image, 0.1, ref_image.replace(\".jp2\", \"_ds.jp2\"))\n",
    "ref_image = ref_image.replace(\".jp2\", \"_ds.jp2\")\n",
    "\n",
    "tgt_scenes = [\n",
    "    s2_an_l1c_secne_files[i]\n",
    "    for i in range(0, len(s2_an_l1c_secne_files))\n",
    "    if i != ref_id\n",
    "]\n",
    "tgt_images = []\n",
    "local_outputs = []\n",
    "global_outputs = []\n",
    "for i, zip_file_path in enumerate(tgt_scenes):\n",
    "    print(f\"Extracting {i + 1} of {len(tgt_scenes)}: {zip_file_path}\")\n",
    "    with ZipFile(zip_file_path) as f:\n",
    "        f.extractall(f\"../data/inputs/{id}/tgt{i}\")\n",
    "    tgt_image_dir = os.path.join(\"../data/inputs/\", id, f\"tgt{i}\")\n",
    "    tgt_tci_files = list(\n",
    "        filter(\n",
    "            lambda f: \"TCI\" in f,\n",
    "            glob.glob(f\"{tgt_image_dir}/*/GRANULE/*/IMG_DATA/**\", recursive=True),\n",
    "        )\n",
    "    )\n",
    "    tgt_tci_files = list(filter(lambda f: \"L1C\" in f, tgt_tci_files))\n",
    "    if len(tgt_tci_files) > 1:\n",
    "        tgt_image = [f for f in tgt_tci_files if f.endswith(\"_10m.jp2\")][0]\n",
    "    else:\n",
    "        tgt_image = tgt_tci_files[0]\n",
    "    tgt_images.append(tgt_image)\n",
    "\n",
    "for img in tgt_images:\n",
    "    downsample_dataset(img, 0.1, img.replace(\".jp2\", \"_ds.jp2\"))\n",
    "tgt_images = [img.replace(\".jp2\", \"_ds.jp2\") for img in tgt_images]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_img = cv.cvtColor(\n",
    "    flip_img(rasterio.open(ref_image).read().copy()), cv.COLOR_BGR2GRAY\n",
    ")\n",
    "tgt_imgs = [\n",
    "    cv.cvtColor(flip_img(rasterio.open(tgt_image).read().copy()), cv.COLOR_BGR2GRAY)\n",
    "    for tgt_image in tgt_images\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ECC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warp_mode = cv.MOTION_AFFINE\n",
    "number_of_iterations = 5000\n",
    "termination_eps = 1e-5\n",
    "\n",
    "criteria = (\n",
    "    cv.TERM_CRITERIA_EPS | cv.TERM_CRITERIA_COUNT,\n",
    "    number_of_iterations,\n",
    "    termination_eps,\n",
    ")\n",
    "\n",
    "tgt_aligned_list = []\n",
    "processed_tgt_images = []\n",
    "processed_output_images = []\n",
    "\n",
    "temp_dir = \"../data/outputs/OpenCV/AN_S2_Series/temp\"\n",
    "os.makedirs(temp_dir, exist_ok=True)\n",
    "for i, tgt_img in enumerate(tgt_imgs):\n",
    "    try:\n",
    "        warp_matrix = np.eye(2, 3, dtype=np.float32)\n",
    "        (cc, warp_matrix) = cv.findTransformECC(\n",
    "            ref_img, tgt_img, warp_matrix, warp_mode, criteria\n",
    "        )\n",
    "\n",
    "        tgt_aligned = cv.warpAffine(\n",
    "            tgt_img,\n",
    "            warp_matrix,\n",
    "            (tgt_img.shape[1], tgt_img.shape[0]),\n",
    "            flags=cv.INTER_LINEAR + cv.WARP_INVERSE_MAP,\n",
    "        )\n",
    "\n",
    "        tgt_aligned_list.append(tgt_aligned)\n",
    "\n",
    "        output_path = os.path.join(temp_dir, f\"out_{i}.tiff\")\n",
    "        processed_output_images.append(output_path)\n",
    "        processed_tgt_images.append(tgt_images[i])\n",
    "\n",
    "        profile = rasterio.open(tgt_images[i]).profile\n",
    "        with rasterio.open(output_path, \"w\", **profile) as ds:\n",
    "            for i in range(0, profile[\"count\"]):\n",
    "                ds.write(tgt_aligned, i + 1)\n",
    "    except:\n",
    "        print(f\"Algorithm did not converge for {tgt_images[i]}\")\n",
    "        tgt_aligned_list.append(np.zeros(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_gif = \"../data/outputs/OpenCV/AN_S2_Series/ecc.gif\"\n",
    "fids = [\n",
    "    int(os.path.splitext(os.path.basename(tgt))[0].split(\"_\")[-1])\n",
    "    for tgt in processed_output_images\n",
    "]\n",
    "if os.path.isfile(out_gif):\n",
    "    os.remove(out_gif)\n",
    "datasets_paths = [ref_image] + processed_output_images\n",
    "datasets_titles = [\"Reference\"] + [\n",
    "    f\"target_{id}, ssim:{np.round(ssim(ref_img, tgt_aligned_list[id]), 3)}\"\n",
    "    for id in fids\n",
    "]\n",
    "make_difference_gif(datasets_paths, out_gif, datasets_titles)\n",
    "\n",
    "out_gif = \"../data/outputs/OpenCV/AN_S2_Series/raw_ecc.gif\"\n",
    "if os.path.isfile(out_gif):\n",
    "    os.remove(out_gif)\n",
    "datasets_paths = [ref_image] + processed_tgt_images\n",
    "datasets_titles = [\"Reference\"] + [\n",
    "    f\"target_{id}, ssim:{np.round(ssim(ref_img, tgt_imgs[id]), 3)}\" for id in fids\n",
    "]\n",
    "make_difference_gif(datasets_paths, out_gif, datasets_titles)\n",
    "shutil.rmtree(temp_dir, ignore_errors=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Phase correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tgt_aligned_list = []\n",
    "processed_tgt_images = []\n",
    "processed_output_images = []\n",
    "\n",
    "temp_dir = \"../data/outputs/OpenCV/AN_S2_Series/temp\"\n",
    "os.makedirs(temp_dir, exist_ok=True)\n",
    "for i, tgt_img in enumerate(tgt_imgs):\n",
    "    try:\n",
    "        # window = cv.createHanningWindow(ref_img.shape, cv.CV_32F)\n",
    "        window = None\n",
    "        ((shift_x, shift_y), phase_corr_score) = cv.phaseCorrelate(\n",
    "            np.float32(tgt_img), np.float32(ref_img), window\n",
    "        )\n",
    "        tgt_aligned = warp_affine_dataset(\n",
    "            tgt_img, translation_x=shift_x, translation_y=shift_y\n",
    "        )\n",
    "\n",
    "        tgt_aligned_list.append(tgt_aligned)\n",
    "\n",
    "        output_path = os.path.join(temp_dir, f\"out_{i}.tiff\")\n",
    "        processed_output_images.append(output_path)\n",
    "        processed_tgt_images.append(tgt_images[i])\n",
    "\n",
    "        profile = rasterio.open(tgt_images[i]).profile\n",
    "        with rasterio.open(output_path, \"w\", **profile) as ds:\n",
    "            for i in range(0, profile[\"count\"]):\n",
    "                ds.write(tgt_aligned, i + 1)\n",
    "    except:\n",
    "        print(f\"Algorithm did not converge for {tgt_images[i]}\")\n",
    "        tgt_aligned_list.append(np.zeros(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_gif = \"../data/outputs/OpenCV/AN_S2_Series/pc.gif\"\n",
    "fids = [\n",
    "    int(os.path.splitext(os.path.basename(tgt))[0].split(\"_\")[-1])\n",
    "    for tgt in processed_output_images\n",
    "]\n",
    "if os.path.isfile(out_gif):\n",
    "    os.remove(out_gif)\n",
    "datasets_paths = [ref_image] + processed_output_images\n",
    "datasets_titles = [\"Reference\"] + [\n",
    "    f\"target_{id}, ssim:{np.round(ssim(ref_img, tgt_aligned_list[id]), 3)}\"\n",
    "    for id in fids\n",
    "]\n",
    "make_difference_gif(datasets_paths, out_gif, datasets_titles)\n",
    "\n",
    "out_gif = \"../data/outputs/OpenCV/AN_S2_Series/raw_pc.gif\"\n",
    "if os.path.isfile(out_gif):\n",
    "    os.remove(out_gif)\n",
    "datasets_paths = [ref_image] + processed_tgt_images\n",
    "datasets_titles = [\"Reference\"] + [\n",
    "    f\"target_{id}, ssim:{np.round(ssim(ref_img, tgt_imgs[id]), 3)}\" for id in fids\n",
    "]\n",
    "make_difference_gif(datasets_paths, out_gif, datasets_titles)\n",
    "shutil.rmtree(temp_dir, ignore_errors=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### optical flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params for ShiTomasi corner detection\n",
    "feature_params = dict(\n",
    "    maxCorners=100,\n",
    "    qualityLevel=0.3,\n",
    "    minDistance=7,\n",
    "    blockSize=7,\n",
    ")\n",
    "\n",
    "# Parameters for lucas kanade optical flow\n",
    "number_of_iterations = 10\n",
    "termination_eps = 1e-5\n",
    "lk_params = dict(\n",
    "    winSize=(15, 15),\n",
    "    maxLevel=2,\n",
    "    criteria=(\n",
    "        cv.TERM_CRITERIA_EPS | cv.TERM_CRITERIA_COUNT,\n",
    "        number_of_iterations,\n",
    "        termination_eps,\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tgt_aligned_list = []\n",
    "processed_tgt_images = []\n",
    "processed_output_images = []\n",
    "\n",
    "temp_dir = \"../data/outputs/OpenCV/AN_S2_Series/temp\"\n",
    "os.makedirs(temp_dir, exist_ok=True)\n",
    "for i, tgt_img in enumerate(tgt_imgs):\n",
    "    try:\n",
    "        p0 = cv.goodFeaturesToTrack(ref_img, mask=None, **feature_params)\n",
    "        p1, st, err = cv.calcOpticalFlowPyrLK(ref_img, tgt_img, p0, None, **lk_params)\n",
    "        ref_good = p0[st == 1].astype(np.float32)\n",
    "        tgt_good = p1[st == 1].astype(np.float32)\n",
    "        warp_matrix = cv.findHomography(ref_good, tgt_good, cv.RANSAC)[0]\n",
    "        tgt_aligned = cv.warpPerspective(\n",
    "            tgt_img,\n",
    "            warp_matrix,\n",
    "            (tgt_img.shape[1], tgt_img.shape[0]),\n",
    "            flags=cv.INTER_LINEAR + cv.WARP_INVERSE_MAP,\n",
    "        )\n",
    "\n",
    "        tgt_aligned_list.append(tgt_aligned)\n",
    "\n",
    "        output_path = os.path.join(temp_dir, f\"out_{i}.tiff\")\n",
    "        processed_output_images.append(output_path)\n",
    "        processed_tgt_images.append(tgt_images[i])\n",
    "\n",
    "        profile = rasterio.open(tgt_images[i]).profile\n",
    "        with rasterio.open(output_path, \"w\", **profile) as ds:\n",
    "            for i in range(0, profile[\"count\"]):\n",
    "                ds.write(tgt_aligned, i + 1)\n",
    "    except:\n",
    "        print(f\"Algorithm did not converge for {tgt_images[i]}\")\n",
    "        tgt_aligned_list.append(np.zeros(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_gif = \"../data/outputs/OpenCV/AN_S2_Series/of.gif\"\n",
    "fids = [\n",
    "    int(os.path.splitext(os.path.basename(tgt))[0].split(\"_\")[-1])\n",
    "    for tgt in processed_output_images\n",
    "]\n",
    "if os.path.isfile(out_gif):\n",
    "    os.remove(out_gif)\n",
    "datasets_paths = [ref_image] + processed_output_images\n",
    "datasets_titles = [\"Reference\"] + [\n",
    "    f\"target_{id}, ssim:{np.round(ssim(ref_img, tgt_aligned_list[id]), 3)}\"\n",
    "    for id in fids\n",
    "]\n",
    "make_difference_gif(datasets_paths, out_gif, datasets_titles)\n",
    "\n",
    "out_gif = \"../data/outputs/OpenCV/AN_S2_Series/raw_of.gif\"\n",
    "if os.path.isfile(out_gif):\n",
    "    os.remove(out_gif)\n",
    "datasets_paths = [ref_image] + processed_tgt_images\n",
    "datasets_titles = [\"Reference\"] + [\n",
    "    f\"target_{id}, ssim:{np.round(ssim(ref_img, tgt_imgs[id]), 3)}\" for id in fids\n",
    "]\n",
    "make_difference_gif(datasets_paths, out_gif, datasets_titles)\n",
    "shutil.rmtree(temp_dir, ignore_errors=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### feature matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_FEATURES = 500\n",
    "GOOD_MATCH_PERCENT = 0.15\n",
    "\n",
    "tgt_aligned_list = []\n",
    "processed_tgt_images = []\n",
    "processed_output_images = []\n",
    "\n",
    "temp_dir = \"../data/outputs/OpenCV/AN_S2_Series/temp\"\n",
    "os.makedirs(temp_dir, exist_ok=True)\n",
    "for i, tgt_img in enumerate(tgt_imgs):\n",
    "    try:\n",
    "        orb = cv.ORB_create(MAX_FEATURES)\n",
    "        keypoints1, descriptors1 = orb.detectAndCompute(ref_img, None)\n",
    "        keypoints2, descriptors2 = orb.detectAndCompute(tgt_img, None)\n",
    "\n",
    "        matcher = cv.DescriptorMatcher_create(cv.DESCRIPTOR_MATCHER_BRUTEFORCE_HAMMING)\n",
    "        matches = matcher.match(descriptors1, descriptors2, None)\n",
    "\n",
    "        matches = sorted(matches, key=lambda x: x.distance)\n",
    "\n",
    "        numGoodMatches = int(len(matches) * GOOD_MATCH_PERCENT)\n",
    "        matches = matches[:numGoodMatches]\n",
    "\n",
    "        # Extract location of good matches\n",
    "        points1 = np.zeros((len(matches), 2), dtype=np.float32)\n",
    "        points2 = np.zeros((len(matches), 2), dtype=np.float32)\n",
    "\n",
    "        for j, match in enumerate(matches):\n",
    "            points1[j, :] = keypoints1[match.queryIdx].pt\n",
    "            points2[j, :] = keypoints2[match.trainIdx].pt\n",
    "\n",
    "        # Find homography\n",
    "        h, mask = cv.findHomography(points1, points2, cv.RANSAC)\n",
    "\n",
    "        # Use homography\n",
    "        height, width = ref_img.shape\n",
    "        tgt_aligned = cv.warpPerspective(\n",
    "            tgt_img, h, (width, height), flags=cv.INTER_LINEAR + cv.WARP_INVERSE_MAP\n",
    "        )\n",
    "\n",
    "        tgt_aligned_list.append(tgt_aligned)\n",
    "\n",
    "        output_path = os.path.join(temp_dir, f\"out_{i}.tiff\")\n",
    "        processed_output_images.append(output_path)\n",
    "        processed_tgt_images.append(tgt_images[i])\n",
    "\n",
    "        profile = rasterio.open(tgt_images[i]).profile\n",
    "        with rasterio.open(output_path, \"w\", **profile) as ds:\n",
    "            for i in range(0, profile[\"count\"]):\n",
    "                ds.write(tgt_aligned, i + 1)\n",
    "    except:\n",
    "        print(f\"Algorithm did not converge for {tgt_images[i]}\")\n",
    "        tgt_aligned_list.append(np.zeros(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_gif = \"../data/outputs/OpenCV/AN_S2_Series/orb.gif\"\n",
    "fids = [\n",
    "    int(os.path.splitext(os.path.basename(tgt))[0].split(\"_\")[-1])\n",
    "    for tgt in processed_output_images\n",
    "]\n",
    "if os.path.isfile(out_gif):\n",
    "    os.remove(out_gif)\n",
    "datasets_paths = [ref_image] + processed_output_images\n",
    "datasets_titles = [\"Reference\"] + [\n",
    "    f\"target_{id}, ssim:{np.round(ssim(ref_img, tgt_aligned_list[id]), 3)}\"\n",
    "    for id in fids\n",
    "]\n",
    "make_difference_gif(datasets_paths, out_gif, datasets_titles)\n",
    "\n",
    "out_gif = \"../data/outputs/OpenCV/AN_S2_Series/raw_orb.gif\"\n",
    "if os.path.isfile(out_gif):\n",
    "    os.remove(out_gif)\n",
    "datasets_paths = [ref_image] + processed_tgt_images\n",
    "datasets_titles = [\"Reference\"] + [\n",
    "    f\"target_{id}, ssim:{np.round(ssim(ref_img, tgt_imgs[id]), 3)}\" for id in fids\n",
    "]\n",
    "make_difference_gif(datasets_paths, out_gif, datasets_titles)\n",
    "shutil.rmtree(temp_dir, ignore_errors=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### S2 L1C Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tile = \"T42DWK\"\n",
    "original_scenes = glob.glob(f\"../data/inputs/{Tile}/L1C/**\")\n",
    "ds_scenes_dir = f\"../data/outputs/AROSICS/L1C_AN_Series_{Tile}_DS\"\n",
    "os.makedirs(ds_scenes_dir, exist_ok=True)\n",
    "# for sc in original_scenes:\n",
    "#     downsample_dataset(sc, 0.1, os.path.join(ds_scenes_dir, os.path.basename(sc)))\n",
    "downsampled_scenes = [\n",
    "    fn for fn in glob.glob(f\"{ds_scenes_dir}/**\") if fn.endswith(\".jp2\")\n",
    "]\n",
    "ref_image = downsampled_scenes[1]\n",
    "tgt_images = [downsampled_scenes[0]] + downsampled_scenes[2:]\n",
    "\n",
    "ref_img = cv.cvtColor(\n",
    "    flip_img(rasterio.open(ref_image).read().copy()), cv.COLOR_BGR2GRAY\n",
    ")\n",
    "tgt_imgs = [\n",
    "    cv.cvtColor(flip_img(rasterio.open(tgt_image).read().copy()), cv.COLOR_BGR2GRAY)\n",
    "    for tgt_image in tgt_images\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coreg_method = \"of\"\n",
    "\n",
    "match coreg_method:\n",
    "    case \"ecc\":\n",
    "        warp_mode = cv.MOTION_AFFINE\n",
    "        number_of_iterations = 5000\n",
    "        termination_eps = 1e-5\n",
    "\n",
    "        params_dic = dict(\n",
    "            criteria=(\n",
    "                cv.TERM_CRITERIA_EPS | cv.TERM_CRITERIA_COUNT,\n",
    "                number_of_iterations,\n",
    "                termination_eps,\n",
    "            )\n",
    "        )\n",
    "    case \"pc\":\n",
    "        params_dic = dict(\n",
    "            # window = cv.createHanningWindow(ref_img.shape, cv.CV_32F)\n",
    "            window=None\n",
    "        )\n",
    "    case \"of\":\n",
    "        number_of_iterations = 10\n",
    "        termination_eps = 1e-5\n",
    "\n",
    "        params_dic = dict(\n",
    "            # params for ShiTomasi corner detection\n",
    "            feature_params=dict(\n",
    "                maxCorners=100,\n",
    "                qualityLevel=0.3,\n",
    "                minDistance=7,\n",
    "                blockSize=7,\n",
    "            ),\n",
    "            # Parameters for lucas kanade optical flow\n",
    "            lk_params=dict(\n",
    "                winSize=(15, 15),\n",
    "                maxLevel=2,\n",
    "                criteria=(\n",
    "                    cv.TERM_CRITERIA_EPS | cv.TERM_CRITERIA_COUNT,\n",
    "                    number_of_iterations,\n",
    "                    termination_eps,\n",
    "                ),\n",
    "            ),\n",
    "            err_threshold=25,\n",
    "        )\n",
    "    case \"orb\":\n",
    "        params_dic = dict(\n",
    "            max_features=500,\n",
    "            good_match_percent=0.15,\n",
    "        )\n",
    "\n",
    "print(\"Coreg method: \" + coreg_method)\n",
    "print(\"Params dict:\")\n",
    "print(params_dic)\n",
    "\n",
    "tgt_aligned_list = []\n",
    "processed_tgt_images = []\n",
    "processed_output_images = []\n",
    "\n",
    "temp_dir = f\"../data/outputs/OpenCV/{Tile}_AN_S2_Series/temp\"\n",
    "os.makedirs(temp_dir, exist_ok=True)\n",
    "for i, tgt_img in enumerate(tgt_imgs):\n",
    "    try:\n",
    "        match coreg_method:\n",
    "            case \"ecc\":\n",
    "                warp_matrix = np.eye(2, 3, dtype=np.float32)\n",
    "                (cc, warp_matrix) = cv.findTransformECC(\n",
    "                    ref_img, tgt_img, warp_matrix, warp_mode, params_dic[\"criteria\"]\n",
    "                )\n",
    "\n",
    "                tgt_aligned = cv.warpAffine(\n",
    "                    tgt_img,\n",
    "                    warp_matrix,\n",
    "                    (tgt_img.shape[1], tgt_img.shape[0]),\n",
    "                    flags=cv.INTER_LINEAR + cv.WARP_INVERSE_MAP,\n",
    "                )\n",
    "            case \"pc\":\n",
    "                ((shift_x, shift_y), phase_corr_score) = cv.phaseCorrelate(\n",
    "                    np.float32(tgt_img), np.float32(ref_img), params_dic[\"window\"]\n",
    "                )\n",
    "                tgt_aligned = warp_affine_dataset(\n",
    "                    tgt_img, translation_x=shift_x, translation_y=shift_y\n",
    "                )\n",
    "            case \"of\":\n",
    "                p0 = cv.goodFeaturesToTrack(\n",
    "                    ref_img, mask=None, **params_dic[\"feature_params\"]\n",
    "                )\n",
    "                p1, st, err = cv.calcOpticalFlowPyrLK(\n",
    "                    ref_img, tgt_img, p0, None, **params_dic[\"lk_params\"]\n",
    "                )\n",
    "                # ref_good = p0[st == 1].astype(np.float32)\n",
    "                # tgt_good = p1[st == 1].astype(np.float32)\n",
    "                dist = np.linalg.norm(p1[st == 1] - p0[st == 1], axis=1)\n",
    "                of_idx = np.where(np.squeeze(dist) < params_dic[\"err_threshold\"])\n",
    "                ref_good = np.squeeze(p0)[of_idx].astype(\"int\")\n",
    "                tgt_good = np.squeeze(p1)[of_idx].astype(\"int\")\n",
    "                valid_idx = np.all(\n",
    "                    (\n",
    "                        tgt_good[:, 0] >= 0,\n",
    "                        tgt_good[:, 1] >= 0,\n",
    "                        tgt_good[:, 0] < tgt_img.shape[1],\n",
    "                        tgt_good[:, 1] < tgt_img.shape[0],\n",
    "                    ),\n",
    "                    axis=0,\n",
    "                )\n",
    "                tgt_good = np.expand_dims(tgt_good[valid_idx], axis=0)\n",
    "                ref_good = np.expand_dims(ref_good[valid_idx], axis=0)\n",
    "                if (ref_good.shape[1] < 4) or (tgt_good.shape[1] < 4):\n",
    "                    print(\n",
    "                        f\"WARNING: couldn't find enough good features for target or reference. num ref features: {ref_good.shape[0]}, num tgt features = {tgt_good.shape[0]}\"\n",
    "                    )\n",
    "\n",
    "                warp_matrix = cv.findHomography(ref_good, tgt_good, cv.RANSAC)[0]\n",
    "                tgt_aligned = cv.warpPerspective(\n",
    "                    tgt_img,\n",
    "                    warp_matrix,\n",
    "                    (tgt_img.shape[1], tgt_img.shape[0]),\n",
    "                    flags=cv.INTER_LINEAR + cv.WARP_INVERSE_MAP,\n",
    "                )\n",
    "            case \"orb\":\n",
    "                orb = cv.ORB_create(params_dic[\"max_features\"])\n",
    "                keypoints1, descriptors1 = orb.detectAndCompute(ref_img, None)\n",
    "                keypoints2, descriptors2 = orb.detectAndCompute(tgt_img, None)\n",
    "\n",
    "                matcher = cv.DescriptorMatcher_create(\n",
    "                    cv.DESCRIPTOR_MATCHER_BRUTEFORCE_HAMMING\n",
    "                )\n",
    "                matches = matcher.match(descriptors1, descriptors2, None)\n",
    "\n",
    "                matches = sorted(matches, key=lambda x: x.distance)\n",
    "\n",
    "                numGoodMatches = int(len(matches) * params_dic[\"good_match_percent\"])\n",
    "                matches = matches[:numGoodMatches]\n",
    "\n",
    "                # Extract location of good matches\n",
    "                points1 = np.zeros((len(matches), 2), dtype=np.float32)\n",
    "                points2 = np.zeros((len(matches), 2), dtype=np.float32)\n",
    "\n",
    "                for j, match in enumerate(matches):\n",
    "                    points1[j, :] = keypoints1[match.queryIdx].pt\n",
    "                    points2[j, :] = keypoints2[match.trainIdx].pt\n",
    "\n",
    "                # Find homography\n",
    "                # h, mask = cv.findHomography(points1, points2, cv.RANSAC)\n",
    "                h, _ = cv.estimateAffine2D(points1, points2)\n",
    "\n",
    "                # Use homography\n",
    "                height, width = ref_img.shape\n",
    "                # tgt_aligned = cv.warpPerspective(\n",
    "                tgt_aligned = cv.warpAffine(\n",
    "                    tgt_img,\n",
    "                    h,\n",
    "                    (width, height),\n",
    "                    flags=cv.INTER_LINEAR + cv.WARP_INVERSE_MAP,\n",
    "                )\n",
    "\n",
    "        tgt_aligned_list.append(tgt_aligned)\n",
    "\n",
    "        output_path = os.path.join(temp_dir, f\"out_{i}.tiff\")\n",
    "        processed_output_images.append(output_path)\n",
    "        processed_tgt_images.append(tgt_images[i])\n",
    "\n",
    "        profile = rasterio.open(tgt_images[i]).profile\n",
    "        with rasterio.open(output_path, \"w\", **profile) as ds:\n",
    "            for i in range(0, profile[\"count\"]):\n",
    "                ds.write(tgt_aligned, i + 1)\n",
    "    except:\n",
    "        print(f\"Algorithm did not converge for {tgt_images[i]}\")\n",
    "        tgt_aligned_list.append(np.zeros(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_gif = f\"../data/outputs/OpenCV/{Tile}_AN_S2_Series/{coreg_method}.gif\"\n",
    "fids = [\n",
    "    int(os.path.splitext(os.path.basename(tgt))[0].split(\"_\")[-1])\n",
    "    for tgt in processed_output_images\n",
    "]\n",
    "target_titles = [f\"target_{id}\" for id in fids]\n",
    "\n",
    "if os.path.isfile(out_gif):\n",
    "    os.remove(out_gif)\n",
    "datasets_paths = [ref_image] + processed_output_images\n",
    "ssims_aligned = [np.round(ssim(ref_img, tgt_aligned_list[id]), 3) for id in fids]\n",
    "mse_aligned = [np.round(mse(ref_img, tgt_aligned_list[id]), 3) for id in fids]\n",
    "datasets_titles = [\"Reference\"] + [\n",
    "    f\"{target_title}, ssim:{ssim_score}, mse:{mse_score}\"\n",
    "    for target_title, ssim_score, mse_score in zip(\n",
    "        target_titles, ssims_aligned, mse_aligned\n",
    "    )\n",
    "]\n",
    "make_difference_gif(datasets_paths, out_gif, datasets_titles)\n",
    "\n",
    "out_gif = f\"../data/outputs/OpenCV/{Tile}_AN_S2_Series/raw_{coreg_method}.gif\"\n",
    "if os.path.isfile(out_gif):\n",
    "    os.remove(out_gif)\n",
    "datasets_paths = [ref_image] + processed_tgt_images\n",
    "ssims_raw = [np.round(ssim(ref_img, tgt_imgs[id]), 3) for id in fids]\n",
    "mse_raw = [np.round(mse(ref_img, tgt_imgs[id]), 3) for id in fids]\n",
    "datasets_titles = [\"Reference\"] + [\n",
    "    f\"{target_title}, ssim:{ssim_score}, mse:{mse_score}\"\n",
    "    for target_title, ssim_score, mse_score in zip(target_titles, ssims_raw, mse_raw)\n",
    "]\n",
    "make_difference_gif(datasets_paths, out_gif, datasets_titles)\n",
    "\n",
    "out_ssim = f\"../data/outputs/OpenCV/{Tile}_AN_S2_Series/{coreg_method}.csv\"\n",
    "out_ssim_df = pd.DataFrame(\n",
    "    zip(target_titles, ssims_raw, ssims_aligned, mse_raw, mse_aligned),\n",
    "    columns=[\"Title\", \"SSIM Raw\", \"SSIM Aligned\", \"MSE Raw\", \"MSE Aligned\"],\n",
    "    index=None,\n",
    ")\n",
    "out_ssim_df.to_csv(out_ssim, encoding=\"utf-8\")\n",
    "\n",
    "shutil.rmtree(temp_dir, ignore_errors=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### S2 L1C Series AN (T42CVE) (SIF/OF with PC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import rasterio\n",
    "import cv2 as cv\n",
    "import sys\n",
    "import pandas as pd\n",
    "\n",
    "sys.path.insert(1, \"../\")\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tile = \"T42DWK\"\n",
    "output_path = f\"../data/outputs/OpenCV/{Tile}_AN_S2_Series_SIF-OF_PC\"\n",
    "\n",
    "original_scenes = glob.glob(f\"../data/inputs/{Tile}/L1C/**\")\n",
    "ds_scenes_dir = f\"../data/outputs/AROSICS/L1C_AN_Series_{Tile}_DS\"\n",
    "os.makedirs(ds_scenes_dir, exist_ok=True)\n",
    "# for sc in original_scenes:\n",
    "#     downsample_dataset(sc, 0.1, os.path.join(ds_scenes_dir, os.path.basename(sc)))\n",
    "downsampled_scenes = [\n",
    "    fn for fn in glob.glob(f\"{ds_scenes_dir}/**\") if fn.endswith(\".jp2\")\n",
    "]\n",
    "ref_image = downsampled_scenes[1]\n",
    "tgt_images = [downsampled_scenes[0]] + downsampled_scenes[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_iterations = 10\n",
    "termination_eps = 1e-5\n",
    "of_params: dict = dict(\n",
    "    # params for ShiTomasi corner detection\n",
    "    feature_params=dict(\n",
    "        maxCorners=1000,\n",
    "        qualityLevel=0.3,\n",
    "        minDistance=7,\n",
    "        blockSize=7,\n",
    "    ),\n",
    "    # Parameters for lucas kanade optical flow\n",
    "    lk_params=dict(\n",
    "        winSize=(55, 55),\n",
    "        maxLevel=2,\n",
    "    ),\n",
    ")\n",
    "_, shifts = co_register(\n",
    "    ref_image,\n",
    "    tgt_images,\n",
    "    filtering_mode=\"of\",\n",
    "    output_path=output_path,\n",
    "    of_params=of_params,\n",
    "    number_of_iterations=number_of_iterations,\n",
    "    termination_eps=termination_eps,\n",
    "    enhanced_shift_method=\"corr\",\n",
    "    remove_outlilers=True,\n",
    "    corr_thresh=0.1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Landsat Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = f\"../data/outputs/OpenCV/L1GT_127111_Original\"\n",
    "# output_path = f\"../data/outputs/OpenCV/LANDSAT_8_108074\"\n",
    "original_scenes = glob.glob(f\"../data/inputs/landsat/true_color/**\")\n",
    "# original_scenes = glob.glob(f\"../data/inputs/LANDSAT_8_108074/true_color/**\")\n",
    "# downsampled_scenes = glob.glob(f\"../data/inputs/landsat/true_color_ds/**\")\n",
    "ref_image = original_scenes[0]\n",
    "tgt_images = original_scenes[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, shifts = co_register(\n",
    "    ref_image,\n",
    "    tgt_images,\n",
    "    output_path=output_path,\n",
    "    remove_outlilers=True,\n",
    "    # laplacian_kernel_size = 5,\n",
    "    return_shifted_images=True,\n",
    "    # rethrow_error=True,\n",
    "    use_overlap=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shifts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### S1 RTC Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = \"../data/outputs/OpenCV/RTC_Series\"\n",
    "enhanced_scenes = [\n",
    "    f for f in glob.glob(\"../data/outputs/AROSICS/RTC_Series/**\") if f.endswith(\".tif\")\n",
    "]\n",
    "ref_image = enhanced_scenes[0]\n",
    "tgt_images = enhanced_scenes[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_iterations = 10\n",
    "termination_eps = 1e-5\n",
    "of_params: dict = dict(\n",
    "    # params for ShiTomasi corner detection\n",
    "    feature_params=dict(\n",
    "        maxCorners=1000,\n",
    "        qualityLevel=0.3,\n",
    "        minDistance=7,\n",
    "        blockSize=7,\n",
    "    ),\n",
    "    # Parameters for lucas kanade optical flow\n",
    "    lk_params=dict(\n",
    "        winSize=(55, 55),\n",
    "        maxLevel=2,\n",
    "    ),\n",
    ")\n",
    "_, shifts = co_register(\n",
    "    ref_image,\n",
    "    tgt_images,\n",
    "    filtering_mode=\"pca_of\",\n",
    "    output_path=output_path,\n",
    "    of_params=of_params,\n",
    "    number_of_iterations=number_of_iterations,\n",
    "    termination_eps=termination_eps,\n",
    "    enhanced_shift_method=\"mean\",\n",
    "    remove_outlilers=True,\n",
    "    corr_thresh=0.1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
