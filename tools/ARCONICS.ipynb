{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from arosics import COREG, COREG_LOCAL\n",
    "from zipfile import ZipFile\n",
    "import shutil\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scenes_dict(data_df:pd.DataFrame, product:str = \"\", is_s1:bool=True) -> dict:\n",
    "    scenes_dict = {}\n",
    "    id_list = data_df.ID.unique()\n",
    "    for id in id_list:\n",
    "        filtered_df = data_df[data_df.ID == id].reset_index(drop=True)\n",
    "        if product != \"\":\n",
    "            filtered_df = filtered_df[filtered_df.Path.apply(lambda x: product in x)].reset_index(drop=True)\n",
    "\n",
    "        grouper = filtered_df.Path.apply(lambda r: os.path.split(r)[1].split(\"_\")[5 if is_s1 else 2][0:6])\n",
    "        secene_list = [list(filtered_df.groupby(grouper))[i][1].Path.iloc[0] for i in range(0, len(grouper.unique()))]\n",
    "        scenes_dict[id] = secene_list\n",
    "    return scenes_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"../data/files_list\"\n",
    "\n",
    "S1_PRODUCTS = [\"SLC\", \"GRD\"]\n",
    "S2_PRODUCTS = [\"L1C\", \"L2A\"]\n",
    "\n",
    "s1_au_df = pd.read_csv(os.path.join(DATA_DIR, \"s1_au.csv\"), names=[\"ID\",\"Path\"])\n",
    "s1_an_df = pd.read_csv(os.path.join(DATA_DIR, \"s1_an.csv\"), names=[\"ID\",\"Path\"])\n",
    "\n",
    "s2_au_df = pd.read_csv(os.path.join(DATA_DIR, \"s2_au.csv\"), names=[\"ID\",\"Path\"])\n",
    "s2_an_df = pd.read_csv(os.path.join(DATA_DIR, \"s2_an.csv\"), names=[\"ID\",\"Path\"])\n",
    "\n",
    "s1_au_slc_dict = get_scenes_dict(s1_au_df, \"SLC\")\n",
    "s1_au_grd_dict = get_scenes_dict(s1_au_df, \"GRD\")\n",
    "\n",
    "s1_an_slc_dict = get_scenes_dict(s1_an_df, \"SLC\")\n",
    "s1_an_grd_dict = get_scenes_dict(s1_an_df, \"GRD\")\n",
    "\n",
    "s2_au_l1c_dict = get_scenes_dict(s2_au_df, \"L1C\", False)\n",
    "s2_au_l2a_dict = get_scenes_dict(s2_au_df, \"L2A\", False)\n",
    "\n",
    "s2_an_l1c_dict = get_scenes_dict(s2_an_df, \"L1C\", False)\n",
    "s2_an_l2a_dict = get_scenes_dict(s2_an_df, \"L2A\", False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.rmtree(\"../data/inputs/\", ignore_errors=True)\n",
    "shutil.rmtree(\"../data/outputs/\", ignore_errors=True)\n",
    "os.makedirs(\"../data/inputs/\")\n",
    "os.makedirs(\"../data/outputs/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test two S2 L2A images for AU\n",
    "\n",
    "id = list(s2_au_l2a_dict.keys())[0]\n",
    "s2_au_l2a_secne_files = s2_au_l2a_dict[id]\n",
    "\n",
    "# get the Jan 2023 and Dec 2024 files\n",
    "s2_au_l2a_secne_pair = [s2_au_l2a_secne_files[0], s2_au_l2a_secne_files[-1]]\n",
    "\n",
    "for i, zip_file_path in enumerate(s2_au_l2a_secne_pair):\n",
    "    with ZipFile(zip_file_path) as f:\n",
    "        f.extractall(f\"../data/inputs/{id}/sub{i}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_image_dir = os.path.join(\"../data/inputs/\", id, f\"sub{0}\")\n",
    "ref_tci_files = list(filter(lambda f: \"TCI\" in f, glob.glob(f\"{ref_image_dir}/*/GRANULE/*/IMG_DATA/**\", recursive=True)))\n",
    "if len(ref_tci_files) > 1:\n",
    "    ref_image = [f for f in ref_tci_files if f.endswith(\"_10m.jp2\")][0]\n",
    "else:\n",
    "    ref_image = ref_tci_files[0]\n",
    "\n",
    "tgt_image_dir = os.path.join(\"../data/inputs/\", id, f\"sub{1}\")\n",
    "tgt_tci_files = list(filter(lambda f: \"TCI\" in f, glob.glob(f\"{tgt_image_dir}/*/GRANULE/*/IMG_DATA/**\", recursive=True)))\n",
    "if len(tgt_tci_files) > 1:\n",
    "    tgt_image = [f for f in tgt_tci_files if f.endswith(\"_10m.jp2\")][0]\n",
    "else:\n",
    "    tgt_image = tgt_tci_files[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "coreg_global = COREG(\n",
    "    im_ref=ref_image,\n",
    "    im_tgt=tgt_image,\n",
    "    path_out=os.path.join(\"../data/outputs/\", id, f\"{id}_global.tiff\"),\n",
    "    fmt_out=\"GTIFF\",\n",
    "    v=True,\n",
    "    nodata=(0.0,0.0),\n",
    "    # r_b4match=2,\n",
    "    # s_b4match=2,\n",
    "    align_grids=True,\n",
    "    max_iter = 10,\n",
    "    max_shift = 100,\n",
    ")\n",
    "res = coreg_global.correct_shifts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "coreg_local = COREG_LOCAL(\n",
    "    im_ref=ref_image,\n",
    "    im_tgt=tgt_image,\n",
    "    grid_res=2000,\n",
    "    # max_points=200,\n",
    "    path_out=os.path.join(\"../data/outputs/\", id, f\"{id}_local.tiff\"),\n",
    "    fmt_out=\"GTIFF\",\n",
    "    v=True,\n",
    "    nodata=(0.0,0.0),\n",
    "    # r_b4match=2,\n",
    "    # s_b4match=2,\n",
    "    align_grids=True,\n",
    "    max_iter = 10,\n",
    "    max_shift = 10,\n",
    ")\n",
    "res = coreg_local.correct_shifts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
